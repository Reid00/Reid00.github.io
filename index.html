<!doctype html><html lang=en dir=auto><head><meta name=generator content="Hugo 0.111.3"><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Reid's Blog</title><meta name=description content="Reid's Personal Notes -- https://github.com/Reid00"><meta name=author content="Reid"><link rel=canonical href=https://reid00.github.io/><link crossorigin=anonymous href=/assets/css/stylesheet.d7fb4cbf980fe688a21621b06a795933c4e6bb2d4070ec940667af1715d84af2.css integrity="sha256-1/tMv5gP5oiiFiGwanlZM8Tmuy1AcOyUBmevFxXYSvI=" rel="preload stylesheet" as=style><link rel=icon href=https://reid00.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://reid00.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://reid00.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://reid00.github.io/apple-touch-icon.png><link rel=mask-icon href=https://reid00.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://reid00.github.io/index.xml><link rel=alternate type=application/json href=https://reid00.github.io/index.json><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-QRR6GRNQGK"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-QRR6GRNQGK",{anonymize_ip:!1})}</script><meta property="og:title" content="Reid's Blog"><meta property="og:description" content="Reid's Personal Notes -- https://github.com/Reid00"><meta property="og:type" content="website"><meta property="og:url" content="https://reid00.github.io/"><meta property="og:image" content="https://i.loli.net/2021/09/26/3OMGXylm8HUYJ6p.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://i.loli.net/2021/09/26/3OMGXylm8HUYJ6p.png"><meta name=twitter:title content="Reid's Blog"><meta name=twitter:description content="Reid's Personal Notes -- https://github.com/Reid00"><script type=application/ld+json>{"@context":"https://schema.org","@type":"Organization","name":"Reid's Blog","url":"https://reid00.github.io/","description":"Reid\u0026#39;s Personal Notes -- https://github.com/Reid00","thumbnailUrl":"https://reid00.github.io/favicon.ico","sameAs":["https://github.com/Reid00","https://twitter.com","index.xml"]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://reid00.github.io/ accesskey=h title="Reid's Blog (Alt + H)">Reid's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://reid00.github.io/archives title=Archive><span>Archive</span></a></li><li><a href=https://reid00.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://reid00.github.io/categories/ title=Categorys><span>Categorys</span></a></li><li><a href=https://reid00.github.io/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class="first-entry home-info"><header class=entry-header><h1>Hi there 👋</h1></header><div class=entry-content><ul><li><strong>Welcome to My Blog.</strong></li><li><strong>This Blog</strong> 是我个人的一些笔记</li><li>包含Go, Python, 机器学习, KV 存储引擎的一些相关笔记, 方便以后复习</li><li>我的<a href=https://github.com/Reid00>GitHub主页</a></li></ul></div><footer class=entry-footer><div class=social-icons><a href=https://github.com/Reid00 target=_blank rel="noopener noreferrer me" title=Github><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a><a href=https://twitter.com target=_blank rel="noopener noreferrer me" title=Twitter><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M23 3a10.9 10.9.0 01-3.14 1.53 4.48 4.48.0 00-7.86 3v1A10.66 10.66.0 013 4s-4 9 5 13a11.64 11.64.0 01-7 2c9 5 20 0 20-11.5a4.5 4.5.0 00-.08-.83A7.72 7.72.0 0023 3z"/></svg></a><a href=index.xml target=_blank rel="noopener noreferrer me" title=RsS><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M4 11a9 9 0 019 9"/><path d="M4 4a16 16 0 0116 16"/><circle cx="5" cy="19" r="1"/></svg></a></div></footer></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://raw.githubusercontent.com/gohugoio/gohugoioTheme/master/static/images/hugo-logo-wide.svg alt="hugo logo"></figure><header class=entry-header><h2>Hugo搭建博客并用GitHubAction部署</h2></header><div class=entry-content><p>介绍 这是我博客 Blog 的地址 和 Github Repositroy。
本博客是用Hugo 来生成静态网站。 Hugo GitHub
并通过 GitHub Action 来自动化部署到 GitHub Pages。
搭建步骤 创建代码仓库 首先按照文档创建 GitHub Pages 站点。该仓库可见性必须是 Public。
另外创建一个仓库用来存放 Hugo 的源文件，名称随意，这里假设仓库名叫 .github.io.source。建议将仓库可见性设置成 Private 以保护好你的源代码。
创建完毕后你的账户下将存在以下两个代码仓库：
https://github.com/&lt;YourName>/&lt;YourName>.github.io (公开的)
https://github.com/&lt;YourName>/&lt;YourName>.github.io.source(私有的)
生成Hugo 网站 安装Hugo For Windows
到Github Release 下载最新版本，用hugo version 或者extended version (部分主题需要extended version 才能使用)
安装步骤参考官方提供
在C盘新建Hugo/sites 目录用于 生成hugo 项目
在C盘新建Hugo/bin 目录，用来存放上面解压后的hugo 二进制文件
添加C:\Hugo\bin 到系统环境变量中
添加完成后，在cmd 或者其他console 中输入hugo version检查 环境变量是否添加成功。
出现下面的表示成功。注意：环境变量添加成功后，记得重启console
For mac/linux
可以只用用命令下载，此处不多讲了。
Hugo 生成网站 在/c/Hugo/sites 目录下使用命令hugo new site siteName生成网站...</p></div><footer class=entry-footer><span title='2023-03-16 19:35:03 +0800 +0800'>2023-03-16</span>&nbsp;·&nbsp;7 min&nbsp;·&nbsp;Reid</footer><a class=entry-link aria-label="post link to Hugo搭建博客并用GitHubAction部署" href=https://reid00.github.io/posts/other/hugo%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%E5%B9%B6%E7%94%A8githubaction%E9%83%A8%E7%BD%B2/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://raw.githubusercontent.com/Reid00/image-host/main/20220608/image.5qakcordu0g0.webp alt="Utterances logo"></figure><header class=entry-header><h2>Utterances 给 Hugo PaperMod 主题添加评论系统</h2></header><div class=entry-content><p>安装 Utterances 首先要有一个 GitHub 仓库。如果是用 GitHub Page 托管网站就可以不需要额外创建，就用你的GitHub Page repositroy 如:.github.io 仓库, 当然也可以自己重新创建一个，用来存放评论。但是需要注意的是这个仓库必须是Public 的。 比如我的为https://github.com/Reid00/hugo-blog-talks
然后去 https://github.com/apps/utterances 安装 utterances。
在打开的页面中选择Only select repositories，并在下拉框中选择自己的博客仓库（比如我就是 Reid00/hugo-blog-talks，也可以安装到其他仓库, 也可以所有仓库，但是不推荐），然后点击 Install。 配置Hugo 复制以下代码，repo 要修改成自己的仓库，repo 为你存放评论的仓库。
1 2 3 4 5 6 7 8 &lt;script src="https://utteranc.es/client.js" repo="Reid00/hugo-blog-talks" issue-term="pathname" label="Comment" theme="github-light" crossorigin="anonymous" async> &lt;/script> 在主题配置目录下创建 layouts/partials/comments.html 文件，并添加上述内容
1 2 3 4 5 6 7 8 9 10 11 {{- /* Comments area start */ -}} {{- /* to add comments read => https://gohugo....</p></div><footer class=entry-footer><span title='2023-03-16 19:35:11 +0800 +0800'>2023-03-16</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;Reid</footer><a class=entry-link aria-label="post link to Utterances 给 Hugo PaperMod 主题添加评论系统" href=https://reid00.github.io/posts/other/utterances-%E7%BB%99-hugo-papermod-%E4%B8%BB%E9%A2%98%E6%B7%BB%E5%8A%A0%E8%AF%84%E8%AE%BA%E7%B3%BB%E7%BB%9F/></a></article><article class=post-entry><header class=entry-header><h2>集成学习之xgboost</h2></header><div class=entry-content><p>一、XGBoost和GBDT xgboost是一种集成学习算法，属于3类常用的集成方法(bagging,boosting,stacking)中的boosting算法类别。它是一个加法模型，基模型一般选择树模型，但也可以选择其它类型的模型如逻辑回归等。
xgboost属于梯度提升树(GBDT)模型这个范畴，GBDT的基本想法是让新的基模型（GBDT以CART分类回归树为基模型）去拟合前面模型的偏差，从而不断将加法模型的偏差降低。
相比于经典的GBDT，xgboost做了一些改进，从而在效果和性能上有明显的提升（划重点面试常考）。
第一，GBDT将目标函数泰勒展开到一阶，而xgboost将目标函数泰勒展开到了二阶。保留了更多有关目标函数的信息，对提升效果有帮助。
第二，GBDT是给新的基模型寻找新的拟合标签（前面加法模型的负梯度），而xgboost是给新的基模型寻找新的目标函数（目标函数关于新的基模型的二阶泰勒展开）。
第三，xgboost加入了和叶子权重的L2正则化项，因而有利于模型获得更低的方差。
**第四，xgboost增加了自动处理缺失值特征的策略。**通过把带缺失值样本分别划分到左子树或者右子树，比较两种方案下目标函数的优劣，从而自动对有缺失值的样本进行划分，无需对缺失特征进行填充预处理。
此外，xgboost还支持候选分位点切割，特征并行等，可以提升性能。
二、XGBoost原理概述 面从假设空间，目标函数，优化算法3个角度对xgboost的原理进行概括性的介绍。
1，假设空间
2，目标函数
3，优化算法
基本思想：贪心法，逐棵树进行学习，每棵树拟合之前模型的偏差。
三、第t棵树学什么？ 要完成构建xgboost模型，我们需要确定以下一些事情。
1，如何boost? 如果已经得到了前面t-1棵树构成的加法模型，如何确定第t棵树的学习目标？
2，如何生成树？已知第t棵树的学习目标的前提下，如何学习这棵树？具体又包括是否进行分裂？选择哪个特征进行分裂？选择什么分裂点位？分裂的叶子节点如何取值？
我们首先考虑如何boost的问题，顺便解决分裂的叶子节点如何取值的问题。
四、如何生成第t棵树？ xgboost采用二叉树，开始的时候，全部样本都在一个叶子节点上。然后叶子节点不断通过二分裂，逐渐生成一棵树。
xgboost使用levelwise的生成策略，即每次对同一层级的全部叶子节点尝试进行分裂。
对叶子节点分裂生成树的过程有几个基本的问题：是否要进行分裂？选择哪个特征进行分裂？在特征的什么点位进行分裂？以及分裂后新的叶子上取什么值？
叶子节点的取值问题前面已经解决了。我们重点讨论几个剩下的问题。
1，是否要进行分裂？ 根据树的剪枝策略的不同，这个问题有两种不同的处理。如果是预剪枝策略，那么只有当存在某种分裂方式使得分裂后目标函数发生下降，才会进行分裂。
但如果是后剪枝策略，则会无条件进行分裂，等树生成完成后，再从上而下检查树的各个分枝是否对目标函数下降产生正向贡献从而进行剪枝。
xgboost采用预剪枝策略，只有分裂后的增益大于0才会进行分裂。
2，选择什么特征进行分裂？
xgboost采用特征并行的方法进行计算选择要分裂的特征，即用多个线程，尝试把各个特征都作为分裂的特征，找到各个特征的最优分割点，计算根据它们分裂后产生的增益，选择增益最大的那个特征作为分裂的特征。
3，选择什么分裂点位？
xgboost选择某个特征的分裂点位的方法有两种，一种是全局扫描法，另一种是候选分位点法。 全局扫描法将所有样本该特征的取值按从小到大排列，将所有可能的分裂位置都试一遍，找到其中增益最大的那个分裂点，其计算复杂度和叶子节点上的样本特征不同的取值个数成正比。 而候选分位点法是一种近似算法，仅选择常数个（如256个）候选分裂位置，然后从候选分裂位置中找出最优的那个。
五、XGBoost算法原理小结 XGBoost（eXtreme Gradient Boosting）全名叫极端梯度提升，XGBoost是集成学习方法的王牌，在Kaggle数据挖掘比赛中，大部分获胜者用了XGBoost，XGBoost在绝大多数的回归和分类问题上表现的十分顶尖，本文较详细的介绍了XGBoost的算法原理。
目录
最优模型的构建方法
Boosting的回归思想
XGBoost的目标函数推导
XGBoost的回归树构建方法
XGBoost与GDBT的区别
最优模型的构建方法
构建最优模型的一般方法是最小化训练数据的损失函数，我们用字母 L表示，如下式：
式（1）称为经验风险最小化，训练得到的模型复杂度较高。当训练数据较小时，模型很容易出现过拟合问题。
因此，为了降低模型的复杂度，常采用下式：
其中J(f)为模型的复杂度，式（2）称为结构风险最小化，结构风险最小化的模型往往对训练数据以及未知的测试数据都有较好的预测 。
应用：决策树的生成和剪枝分别对应了经验风险最小化和结构风险最小化，XGBoost的决策树生成是结构风险最小化的结果，后续会详细介绍。
Boosting方法的回归思想
Boosting法是结合多个弱学习器给出最终的学习结果，不管任务是分类或回归，我们都用回归任务的思想来构建最优Boosting模型 。
回归思想：把每个弱学习器的输出结果当成连续值，这样做的目的是可以对每个弱学习器的结果进行累加处理，且能更好的利用损失函数来优化模型。
假设
是第 t 轮弱学习器的输出结果，
是模型的输出结果，
是实际输出结果，表达式如下：
上面两式就是加法模型，都默认弱学习器的输出结果是连续值。因为回归任务的弱学习器本身是连续值，所以不做讨论，下面详细介绍分类任务的回归思想。
分类任务的回归思想：
根据2.1式的结果，得到最终的分类器：
分类的损失函数一般选择指数函数或对数函数，这里假设损失函数为对数函数，学习器的损失函数是
若实际输出结果yi=1，则：
求（2.5）式对...</p></div><footer class=entry-footer><span title='2023-03-16 19:35:28 +0800 +0800'>2023-03-16</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;Reid</footer><a class=entry-link aria-label="post link to 集成学习之xgboost" href=https://reid00.github.io/posts/ml/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E4%B9%8Bxgboost/></a></article><article class=post-entry><header class=entry-header><h2>集成学习之AdaBoost</h2></header><div class=entry-content><p>Boosting算法的工作机制 用初始权重D(1)从数据集中训练出一个弱学习器1 根据弱学习1的学习误差率表现来更新训练样本的权重D(2)，使得之前弱学习器1学习误差率高的样本点的权重变高，使得这些误差率高的点在后面的弱学习器2中得到更多的重视。 然后基于调整权重后的训练集来训练弱学习器2 如此重复进行，直到弱学习器数达到事先指定的数目T，最终将这T个弱学习器通过集合策略进行整合，得到最终的强学习器。 现如今已经有很多的提升方法了，但最著名的就是Adaboost（适应性提升，是Adaptive Boosting的简称）和Gradient Boosting（梯度提升）。让我们先从 Adaboost 说起。
什么是AdaBoost AdaBoost是一个具有里程碑意义的算法，其中，适应性（adaptive）是指：后续的分类器为更好地支持被先前分类器分类错误的样本实例而进行调整。通过对之前分类结果不对的训练实例多加关注，使新的预测因子越来越多地聚焦于之前错误的情况。
具体说来，整个AdaBoost迭代算法就3步：
初始化训练数据的权值分布。如果有N个样本，则每一个训练样本最开始时都被赋予相同的权值：。 训练弱分类器。具体训练过程中，如果某个样本点已经被准确地分类，那么在构造下一个训练集中，它的权值就被降低；相反，如果某个样本点没有被准确地分类，那么它的权值就得到提高。然后，权值更新过的样本集被用于训练下一个分类器，整个训练过程如此迭代地进行下去。 将各个训练得到的弱分类器组合成强分类器。各个弱分类器的训练过程结束后，加大分类误差率小的弱分类器的权重，使其在最终的分类函数中起着较大的决定作用，而降低分类误差率大的弱分类器的权重，使其在最终的分类函数中起着较小的决定作用。换言之，误差率低的弱分类器在最终分类器中占的权重较大，否则较小。 加法模型与前向分布 在学习AdaBoost之前需要了解两个数学问题，这两个数学问题可以帮助我们更好地理解AdaBoost算法，并且在面试官问你算法原理时不至于发懵。下面我们就来看看加法模型与前向分布。
什么是加法模型 当别人问你“什么是加法模型”时，你应当知道：加法模型顾名思义就是把各种东西加起来求和。如果想要更严谨的定义，不妨用数学公式来表达： 这个公式看上去可能有些糊涂，如果我们套用到提升树模型中就比较容易理解一些。FM(x)表示最终生成的最好的提升树，其中M表示累加的树的个数。b(x;ym)表示一个决策树，$阿尔法m$ 表示第m个决策树的权重，ym表示决策树的参数（如叶节点的个数）。
什么是前向分布 那么什么是前向分布算法呢？在损失函数 的条件下，加法模型FM(x)成为一个经验风险极小化问题，即使得损失函数极小化： 前向分布算法就是求解这个优化问题的一个思想：因为学习的是加法模型，如果能够从前向后，每一步只学习一个基函数（一棵决策树）及其权重，利用残差逐步逼近优化问题，那么就可以简化优化的复杂度。从而得到前向分布算法为：
套用在提升树模型中进行理解就是：$fm-1(x)$是前一棵提升树（之前树的累加），在其基础上再加上一棵树$Bxi, Ym$乘上它的权重系数，用这棵树去拟合的残差!$阿尔法m$（观察值与估计值之间的差），再将这两棵树合在一起就得到了新的提升树。实际上就是让下一个基分类器去拟合当前分类器学习出来的残差。
前向分布与Adaboost损失函数优化的关系 现在了解了加法模型与前向分布。那这两个概念与Adaboost又有什么关系呢？
Adaboost可以认为其模型是加法模型、损失函数为指数函数、学习算法为前向分步算法的二类分类学习方法。我们可以使用前向分布算法作为框架，推导出Adaboost算法的损失函数优化问题的。
在Adaboost中，各个基本分类器就相当于加法模型中的基函数$fm-1(x)$，且其损失函数为指数函数$b(xi;ym)$。
即，需要优化的问题如下： 如果我们令，则上述公式可以改写成为： 因为与要么相等、要么不等。所以可以将其拆成两部分相加的形式：
算法中需要关注的内容 首先看看算法中都关注了哪些内容： 首先，我们假设训练样本为$(x1,y1), (x2, y2)…(xn, yn)$
由于AdaBoost是由一个个的弱分类器迭代训练得到一个强分类器的，因此我们有如下定义：
弱分类器表达式：$Ht(x)$ 先以二分类为例，它输出的值为1或-1，则有：$Ht(x) ∈{-1, 1}$
首先，我们假设训练样本为 由于AdaBoost是由一个个的弱分类器迭代训练得到一个强分类器的，因此我们有如下定义：
弱分类器表达式： 公式推导（通过Z最小化训练误差) Adaboost算法之所以称为十大算法之一，有一个重要原因就是它有完美的数学推导过程，其参数不是人工设定的，而是有解析解的，并且可以证明其误差上界越来越小，趋近于零；且可以推导出来。下面就来看一下公式推导。
权重公式: 首先要把模型的误差表示出来，只有用数学公式表示出来，才能够讲模型的优化。
先看第i个样本在t+1个弱学习器的权重是怎样的? 模型误差上限 模型误差上限最小化与Z 求出Z 既然最小化Zt就等同于最小化模型误差上界，那我们得先知道Zt长什么样，然后才能去最小化它。
我们在前面已经说过，为了保证所有样本的权重加起来等于1。因此需要对每个权重除以归一化系数。即Zt实际上就是t+1时刻所有样本原始权重和，也就是时刻的各点权重乘以调整幅度再累加：
求出使得Z最小的参数a AdaBoost计算步骤梳理及优缺点 理论上任何学习器都可以用于Adaboost。但一般来说，使用最广泛的Adaboost弱学习器是决策树和神经网络。对于决策树，Adaboost分类用了CART分类树，而Adaboost回归用了CART回归树。</p></div><footer class=entry-footer><span title='2023-03-16 19:35:27 +0800 +0800'>2023-03-16</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;Reid</footer><a class=entry-link aria-label="post link to 集成学习之AdaBoost" href=https://reid00.github.io/posts/ml/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E4%B9%8Badaboost/></a></article><article class=post-entry><header class=entry-header><h2>集成学习之Bagging,Boosting</h2></header><div class=entry-content><p>生成子模型的两种取样方式 那么为了造成子模型之间的差距，每个子模型只看样本中的一部分，这就涉及到两种取样方式：
放回取样：Bagging，在统计学中也被称为bootstrap。 不放回取样：Boosting 在集成学习中我们通常采用 Bagging 的方式，具体原因如下：
因为取样后放回，所以不受样本数据量的限制，允许对同一种分类器上对训练集进行进行多次采样，可以训练更多的子模型。 在 train_test_split 时，不那么强烈的依赖随机；而 Boosting的方式，会受到随机的影响； Boosting的随机问题：Pasting 的方式等同于将 500 个样本分成 5 份，每份 100 个样本，怎么分，将对子模型有较大影响，进而对集成系统的准确率有较大影响。 什么是Bagging Bagging，即bootstrap aggregating的缩写，每个训练集称为bootstrap。
Bagging是一种根据均匀概率分布从数据中重复抽样（有放回）的技术 。
Bagging能提升机器学习算法的稳定性和准确性，它可以减少模型的方差从而避免overfitting。它通常应用在决策树方法中，其实它可以应用到任何其它机器学习算法中。
Bagging方法在不稳定模型（unstable models）集合中表现比较好。这里说的不稳定的模型，即在训练数据发生微小变化时产生不同泛化行为的模型（高方差模型），如决策树和神经网络。
但是Bagging在过于简单模型集合中表现并不好，因为Bagging是从总体数据集随机选取样本来训练模型，过于简单的模型可能会产生相同的预测结果，失去了多样性。
总结一下Bagging方法：
Bagging通过降低基分类器的方差，改善了泛化误差 其性能依赖于基分类器的稳定性；如果基分类器不稳定，bagging有助于降低训练数据的随机波动导致的误差；如果稳定，则集成分类器的误差主要由基分类器的偏差引起 由于每个样本被选中的概率相同，因此bagging并不侧重于训练数据集中的任何特定实例 Bagging的使用 sklearn为Bagging提供了一个简单的API：BaggingClassifier类（回归是BaggingRegressor）。首先需要传入一个模型作为参数，可以使用决策树；然后需要传入参数n_estimator即集成多少个子模型；参数max_samples表示每次从数据集中取多少样本；参数bootstrap设置为True表示使用有放回取样Bagging，设置为False表示使用无放回取样Pasting。可以通过n_jobs参数来分配训练所需CPU核的数量，-1表示会使用所有空闲核（集成学习思路，极易并行化处理）。
bagging是不能减小模型的偏差的，因此我们要选择具有低偏差的分类器来集成，例如：没有修剪的决策树。
Bootstrap 在每个预测器被训练的子集中引入了更多的分集，所以 Bagging 结束时的偏差比 Pasting 更高，但这也意味着预测因子最终变得不相关，从而减少了集合的方差。总体而言，Bagging 通常会导致更好的模型，这就解释了为什么它通常是首选的。然而，如果你有空闲时间和 CPU 功率，可以使用交叉验证来评估 Bagging 和 Pasting 哪一个更好。
Out-of-Bag 对于Bagging来说，一些实例可能被一些分类器重复采样，但其他的有可能不会被采样。由于每个bootstrap的M个样本是有放回随机选取的，因此每个样本不被选中的概率为。当N和M都非常大时，比如N=M=10000，一个样本不被选中的概率p = 36.8%。因此一个bootstrap约包含原样本63.2%，约36.8%的样本未被选中。这些没有被采样的训练实例就叫做Out-of-Bag实例。但注意对于每一个的分类器来说，它们各自的未选中部分不是相同的。
那么这些未选中的样本有什么用呢？
因为在训练中分类器从来没有看到过Out-of-Bag实例，所以它可以在这些样本上进行预测，就不用分样本测试集和测试数据集了。
在sklearn中，可以在训练后需要创建一个BaggingClassifier时设置oob_score=True来进行自动评估。
1 2 3 4 5 bagging_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=5000, max_samples=100, bootstrap=True, oob_score=True) bagging_clf.fit(X, y) bagging_clf....</p></div><footer class=entry-footer><span title='2023-03-16 19:35:27 +0800 +0800'>2023-03-16</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;Reid</footer><a class=entry-link aria-label="post link to 集成学习之Bagging,Boosting" href=https://reid00.github.io/posts/ml/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E4%B9%8Bbaggingboosting/></a></article><article class=post-entry><header class=entry-header><h2>集成学习之GBD</h2></header><div class=entry-content><p>什么是GBDT 到底什么是梯度提升树？所谓的GBDT实际上就是：
GBDT = Gradient Descent + Boosting + Desicion Tree
与Adaboost算法类似，GBDT也是使用了前向分布算法的加法模型。只不过弱学习器限定了只能使用CART回归树模型，同时迭代思路和Adaboost也有所不同。
在Adaboost算法中，我们是利用前一轮迭代弱学习器的误差率来更新训练集的权重。而Gradient Boosting是通过算梯度（gradient）来定位模型的不足。
https://mp.weixin.qq.com/s/rmStKvdHq-BOCJo8ZuvgfQ
最常用的决策树算法: RF, Adaboost, GBDT
https://mp.weixin.qq.com/s/tUl3zhVxLfUd7o06_1Zg2g
Xgboost 的优势和原理 原理: https://www.jianshu.com/p/920592e8bcd2
​ https://www.jianshu.com/p/ac1c12f3fba1
优势: https://snaildove.github.io/2018/10/02/get-started-XGBoost/
LightGBM 详解 https://blog.csdn.net/VariableX/article/details/106242202
GBDT分类算法流程 GBDT的分类算法从思想上和GBDT的回归算法没有区别，但是由于样本输出不是连续的值，而是离散的类别，导致我们无法直接从输出类别去拟合类别输出的误差。
为了解决这个问题，主要有两个方法：
用指数损失函数，此时GBDT退化为Adaboost算法。 用类似于逻辑回归的对数似然损失函数的方法。也就是说，我们用的是类别的预测概率值和真实概率值的差来拟合损失。 下面我们用对数似然损失函数的GBDT分类。而对于对数似然损失函数，又有二元分类和多元分类的区别。
sklearn中的GBDT调参大法 https://mp.weixin.qq.com/s/756Xsy0uhnb8_rheySqLLg
Boosting重要参数 分类和回归算法的参数大致相同，不同之处会指出。
n_estimators: 弱学习器的个数。个数太小容易欠拟合，个数太大容易过拟合。默认是100，在实际调参的过程中，常常将n_estimators和参数learning_rate一起考虑。
learning_rate: 每个弱学习器的权重缩减系数，也称作步长。如果我们在强学习器的迭代公式加上了正则化项：，则通过learning_rate来控制其权重。对于同样的训练集拟合效果，较小的learning_rate意味着需要更多的弱学习器。通常用二者一起决定算法的拟合效果。所以两个参数n_estimators和learning_rate要一起调参。一般来说，可以从一个小一点的补偿开始调参，默认是1。
subsample: 不放回抽样的子采样，取值为(0,1]。如果取值为1，则全部样本都使用，等于没有使用子采样。如果取值小于1，则只有一部分样本会去做GBDT的决策树拟合。选择小于1的比例可以减少方差，即防止过拟合，但是会增加样本拟合的偏差，因此取值不能太低。推荐在[0.5, 0.8]之间，默认是1.0，即不使用子采样。
init: 初始化时的弱学习器，即。如果我们对数据有先验知识，或者之前做过一些拟合，可以用init参数提供的学习器做初始化分类回归预测。一般情况下不输入，直接用训练集样本来做样本集的初始化分类回归预测。
loss: GBDT算法中的损失函数。分类模型和回归模型的损失函数是不一样。
对于回归模型，可以使用均方误差ls，绝对损失lad，Huber损失huber和分位数损失quantile，默认使用均方误差ls。如果数据的噪音点不多，用默认的均方差ls比较好；如果噪音点较多，则推荐用抗噪音的损失函数huber；而如果需要对训练集进行分段预测，则采用quantile。 对于分类模型，可以使用对数似然损失函数deviance和指数损失函数exponential。默认是对数似然损失函数deviance。在原理篇中对这些分类损失函数有详细的介绍。一般来说，推荐使用默认的"deviance"。它对二元分离和多元分类各自都有比较好的优化。而指数损失函数等于把我们带到了Adaboost算法。 alpha: 这个参数只有回归算法有，当使用Huber损失huber和分位数损失quantile时，需要指定分位数的值。默认是0.9，如果噪音点较多，可以适当降低这个分位数的值。
弱学习器参数 GBDT使用了CART回归决策树，因此它的参数基本和决策树类似。
max_features: 划分时考虑的最大特征数，默认是"None"。默认时表示划分时考虑所有的特征数；如果是"log2"意味着划分时最多考虑个log2N特征；如果是"sqrt"或者"auto"意味着划分时最多考虑根号N个特征。如果是整数，代表考虑的特征绝对数。如果是浮点数，代表考虑特征百分比，即考虑（百分比*N）取整后的特征数。其中N为样本总特征数。一般来说，如果样本特征数不多，比如小于50，我们用默认的"None"就可以了，如果特征数非常多，可以灵活控制划分时考虑的最大特征数，以控制决策树的生成时间。 max_depth: 决策树最大深度。如果不输入，默认值是3。一般来说，数据少或者特征少的时候可以不管这个值。如果模型样本量多，特征也多的情况下，推荐限制这个最大深度，具体的取值取决于数据的分布。 min_samples_split: 内部节点再划分所需最小样本数。限制子树继续划分的条件，如果某节点的样本数少于min_samples_split，则不会继续再尝试选择最优特征来进行划分。默认是2，如果样本量数量级非常大，则增大这个值。 min_samples_leaf: 叶子节点最少样本数。限制叶子节点最少的样本数，如果某叶子节点数目小于样本数，则会和兄弟节点一起被剪枝。默认是1,可以输入最少的样本数的整数，或者最少样本数占样本总数的百分比。如果样本量不大，不需要管这个值。如果样本量数量级非常大，则推荐增大这个值。 min_weight_fraction_leaf: 叶子节点最小的样本权重和这个值限制了叶子节点所有样本权重和的最小值，如果小于这个值，则会和兄弟节点一起被剪枝。默认是0，就是不考虑权重问题。一般来说，如果我们有较多样本有缺失值，或者分类树样本的分布类别偏差很大，就会引入样本权重，这时我们就要注意这个值了。 max_leaf_nodes: 最大叶子节点数。通过限制最大叶子节点数，可以防止过拟合，默认是None，即不限制最大的叶子节点数。如果加了限制，算法会建立在最大叶子节点数内最优的决策树。如果特征不多，可以不考虑这个值，但是如果特征分成多的话，可以加以限制，具体的值可以通过交叉验证得到。 min_impurity_split: 节点划分最小不纯度。这个值限制了决策树的增长，如果某节点的不纯度(基于基尼系数，均方差)小于这个阈值，则该节点不再生成子节点。即为叶子节点 。一般不推荐改动默认值1e-7。 GBDT有很多优点：...</p></div><footer class=entry-footer><span title='2023-03-16 19:35:27 +0800 +0800'>2023-03-16</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;Reid</footer><a class=entry-link aria-label="post link to 集成学习之GBD" href=https://reid00.github.io/posts/ml/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E4%B9%8Bgbdt/></a></article><article class=post-entry><header class=entry-header><h2>逻辑回归的常见面试题总结</h2></header><div class=entry-content><p>1.简介 逻辑回归是面试当中非常喜欢问到的一个机器学习算法，因为表面上看逻辑回归形式上很简单，很好掌握，但是一问起来就容易懵逼。所以在面试的时候给大家的第一个建议不要说自己精通逻辑回归，非常容易被问倒，从而减分。下面总结了一些平常我在作为面试官面试别人和被别人面试的时候，经常遇到的一些问题。
Regression问题的常规步骤为：
寻找h函数（即假设估计的函数）； 构造J函数（损失函数）； 想办法使得J函数最小并求得回归参数（θ）； 数据拟合问题 2.正式介绍 如何凸显你是一个对逻辑回归已经非常了解的人呢。那就是用一句话概括它！逻辑回归假设数据服从伯努利分布,通过极大化似然函数的方法，运用梯度下降来求解参数，来达到将数据二分类的目的。
这里面其实包含了5个点 1：逻辑回归的假设，2：逻辑回归的损失函数，3：逻辑回归的求解方法，4：逻辑回归的目的，5:逻辑回归如何分类。这些问题是考核你对逻辑回归的基本了解。
逻辑回归的基本假设 任何的模型都是有自己的假设，在这个假设下模型才是适用的。逻辑回归的第一个基本假设是**假设数据服从伯努利分布。**伯努利分布有一个简单的例子是抛硬币，抛中为正面的概率是pp,抛中为负面的概率是1−p1−p.在逻辑回归这个模型里面是假设 hθ(x)hθ(x) 为样本为正的概率，1−hθ(x)1−hθ(x)为样本为负的概率。那么整个模型可以描述为
hθ(x;θ)=phθ(x;θ)=p
逻辑回归的第二个假设是假设样本为正的概率是
p=11+e−θTxp=11+e−θTx
所以逻辑回归的最终形式
hθ(x;θ)=11+e−θTx
逻辑回归的求解方法 由于该极大似然函数无法直接求解，我们一般通过对该函数进行梯度下降来不断逼急最优解。在这个地方其实会有个加分的项，考察你对其他优化方法的了解。因为就梯度下降本身来看的话就有随机梯度下降，批梯度下降，small batch 梯度下降三种方式，面试官可能会问这三种方式的优劣以及如何选择最合适的梯度下降方式。
简单来说 批梯度下降会获得全局最优解，缺点是在更新每个参数的时候需要遍历所有的数据，计算量会很大，并且会有很多的冗余计算，导致的结果是当数据量大的时候，每个参数的更新都会很慢。
随机梯度下降是以高方差频繁更新，优点是使得sgd（随机梯度下降）会跳到新的和潜在更好的局部最优解，缺点是使得收敛到局部最优解的过程更加的复杂。
如果使用梯度下降法(批量梯度下降法)，那么每次迭代过程中都要对 个样本进行求梯度，所以开销非常大，随机梯度下降的思想就是随机采样一个样本 来更新参数，那么计算开销就从 下降到 。
随机梯度下降虽然提高了计算效率，降低了计算开销，但是由于每次迭代只随机选择一个样本，因此随机性比较大，所以下降过程中非常曲折
可以看到多了随机两个字，随机也就是说我们用样本中的一个例子来近似我所有的样本，来调整θ，因而随机梯度下降是会带来一定的问题，因为计算得到的并不是准确的一个梯度，**对于最优化问题，凸问题，**虽然不是每次迭代得到的损失函数都向着全局最优方向， 但是大的整体的方向是向全局最优解的，最终的结果往往是在全局最优解附近。
小批量梯度下降结合了sgd和batch gd的优点，每次更新的时候使用n个样本。减少了参数更新的次数，可以达到更加稳定收敛结果，一般在深度学习当中我们采用这种方法。小批量梯度下降的开销为 其中 是批量大小。
其实这里还有一个隐藏的更加深的加分项，看你了不了解诸如Adam，动量法等优化方法。因为上述方法其实还有两个致命的问题。 第一个是如何对模型选择合适的学习率。自始至终保持同样的学习率其实不太合适。因为一开始参数刚刚开始学习的时候，此时的参数和最优解隔的比较远，需要保持一个较大的学习率尽快逼近最优解。但是学习到后面的时候，参数和最优解已经隔的比较近了，你还保持最初的学习率，容易越过最优点，在最优点附近来回振荡，通俗一点说，就很容易学过头了，跑偏了。 第二个是如何对参数选择合适的学习率。在实践中，对每个参数都保持的同样的学习率也是很不合理的。有些参数更新频繁，那么学习率可以适当小一点。有些参数更新缓慢，那么学习率就应该大一点。这里我们不展开，有空我会专门出一个专题介绍。 逻辑回归的目的 该函数的目的便是将数据二分类，提高准确率。 逻辑回归如何分类 逻辑回归作为一个回归(也就是y值是连续的)，如何应用到分类上去呢。y值确实是一个连续的变量。逻辑回归的做法是划定一个阈值，y值大于这个阈值的是一类，y值小于这个阈值的是另外一类。阈值具体如何调整根据实际情况选择。一般会选择0.5做为阈值来划分。 逻辑回归的损失函数为什么要使用极大似然函数作为损失函数？ 损失函数一般有四种，平方损失函数，对数损失函数，HingeLoss0-1损失函数，绝对值损失函数。将极大似然函数取对数以后等同于对数损失函数。在逻辑回归这个模型下，对数损失函数的训练求解参数的速度是比较快的。至于原因大家可以求出这个式子的梯度更新
这个式子的更新速度只和相关。和sigmod函数本身的梯度是无关的。这样更新的速度是可以自始至终都比较的稳定。
为什么不选平方损失函数的呢？其一是因为如果你使用平方损失函数，你会发现梯度更新的速度和sigmod函数本身的梯度是很相关的。sigmod函数在它在定义域内的梯度都不大于0.25。这样训练会非常的慢。
逻辑回归在训练的过程当中，如果有很多的特征高度相关或者说有一个特征重复了100遍，会造成怎样的影响？ 先说结论，如果在损失函数最终收敛的情况下，其实就算有很多特征高度相关也不会影响分类器的效果。
但是对特征本身来说的话，假设只有一个特征，在不考虑采样的情况下，你现在将它重复100遍。训练以后完以后，数据还是这么多，但是这个特征本身重复了100遍，实质上将原来的特征分成了100份，每一个特征都是原来特征权重值的百分之一
如果在随机采样的情况下，其实训练收敛完以后，还是可以认为这100个特征和原来那一个特征扮演的效果一样，只是可能中间很多特征的值正负相消了。
为什么我们还是会在训练的过程当中将高度相关的特征去掉？ 去掉高度相关的特征会让模型的可解释性更好 可以大大提高训练的速度。如果模型当中有很多特征高度相关的话，就算损失函数本身收敛了，但实际上参数是没有收敛的，这样会拉低训练的速度。其次是特征多了，本身就会增大训练的时间。 4.逻辑回归的优缺点总结 优点
形式简单，模型的可解释性非常好。从特征的权重可以看到不同的特征对最后结果的影响，某个特征的权重值比较高，那么这个特征最后对结果的影响会比较大。
模型效果不错。在工程上是可以接受的（作为baseline)，如果特征工程做的好，效果不会太差，并且特征工程可以大家并行开发，大大加快开发的速度。
训练速度较快。分类的时候，计算量仅仅只和特征的数目相关。并且逻辑回归的分布式优化sgd发展比较成熟，训练的速度可以通过堆机器进一步提高，这样我们可以在短时间内迭代好几个版本的模型。
资源占用小,尤其是内存。因为只需要存储各个维度的特征值，。
方便输出结果调整。逻辑回归可以很方便的得到最后的分类结果，因为输出的是每个样本的概率分数，我们可以很容易的对这些概率分数进行cutoff，也就是划分阈值(大于某个阈值的是一类，小于某个阈值的是一类)。
但是逻辑回归本身也有许多的缺点:
准确率并不是很高。因为形式非常的简单(非常类似线性模型)，很难去拟合数据的真实分布。
很难处理数据不平衡的问题。举个例子：如果我们对于一个正负样本非常不平衡的问题比如正负样本比 10000:1.我们把所有样本都预测为正也能使损失函数的值比较小。但是作为一个分类器，它对正负样本的区分能力不会很好。
处理非线性数据较麻烦。逻辑回归在不引入其他方法的情况下，只能处理线性可分的数据，或者进一步说，处理二分类的问题 。...</p></div><footer class=entry-footer><span title='2023-03-16 19:35:26 +0800 +0800'>2023-03-16</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;Reid</footer><a class=entry-link aria-label="post link to 逻辑回归的常见面试题总结" href=https://reid00.github.io/posts/ml/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E7%9A%84%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98%E6%80%BB%E7%BB%93/></a></article><article class=post-entry><header class=entry-header><h2>随机森林（回归树）模型</h2></header><div class=entry-content><p>调参 ★ 在 scikit-learn 中，Random Forest（以下简称RF）的分类类是 RandomForestClassifier，回归类是 RandomForestRegressor。
RF 需要调参的参数也包括两部分，第一部分是 Bagging 框架的参数，第二部分是 CART 决策树的参数。下面我们就对这些参数做一个介绍。
RF 框架参数 首先我们关注于 RF 的 Bagging 框架的参数。这里可以和 GBDT 对比来学习。GBDT 的框架参数比较多，重要的有最大迭代器个数，步长和子采样比例，调参起来比较费力。但是 RF 则比较简单，这是因为 bagging 框架里的各个弱学习器之间是没有依赖关系的，这减小的调参的难度。换句话说，达到同样的调参效果，RF 调参时间要比 GBDT 少一些。
下面我来看看 RF 重要的 Bagging 框架的参数，由于 RandomForestClassifier 和 RandomForestRegressor 参数绝大部分相同，这里会将它们一起讲，不同点会指出。
n_estimators：也就是弱学习器的最大迭代次数，或者说最大的弱学习器的个数。一般来说 n_estimators 太小，容易欠拟合，n_estimators 太大，计算量会太大，并且 n_estimators 到一定的数量后，再增大 n_estimators 获得的模型提升会很小，所以一般选择一个适中的数值。默认是 100 。
oob_score：即是否采用袋外样本来评估模型的好坏。默认识 False 。个人推荐设置为 True ，因为袋外分数反应了一个模型拟合后的泛化能力。
criterion: 即 CART 树做划分时对特征的评价标准。分类模型和回归模型的损失函数是不一样的。分类 RF 对应的 CART 分类树默认是基尼系数 gini ，另一个可选择的标准是信息增益。回归 RF 对应的 CART 回归树默认是均方差 mse ，另一个可以选择的标准是绝对值差 mae 。一般来说选择默认的标准就已经很好的。...</p></div><footer class=entry-footer><span title='2023-03-16 19:35:26 +0800 +0800'>2023-03-16</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;Reid</footer><a class=entry-link aria-label="post link to 随机森林（回归树）模型" href=https://reid00.github.io/posts/ml/%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E5%9B%9E%E5%BD%92%E6%A0%91%E6%A8%A1%E5%9E%8B/></a></article><article class=post-entry><header class=entry-header><h2>随机森林算法及其在特征选择中的应用</h2></header><div class=entry-content><p>随机森林算法思想 随机森林（Random Forest）使用多个CART决策树作为弱学习器，不同决策树之间没有关联。当我们进行分类任务时，新的输入样本进入，就让森林中的每一棵决策树分别进行判断和分类，每个决策树会得到一个自己的分类结果，决策树的分类结果中哪一个分类最多，那么随机森林就会把这个结果当做最终的结果。
随机森林在生成决策树的时候用随机选择的特征，即使用Bagging方法。这么做的原因是：如果训练集中的某几个特征对输出的结果有很强的预测性，那么这些特征会被每个决策树所应用，这样会导致树之间具有相关性，这样并不会减小模型的方差。
随机森林对决策树的建立做了一些改进：
随机森林不会像普通决策树一样选择最优特征进行子树的划分，而是随机选择节点上的一部分样本特征：Nsub（子集），然后在随机挑选出来的集合Nsub中，选择一个最优的特征来做决策树的左右子树划分。一般情况下，推荐子集Nsub内特征的个数为log2d个。这样进一步增强了模型的泛化能力。
如果Nsub=N，则此时随机森林的CART决策树和普通的CART决策树没有区别。Nsub越小，则模型越健壮。当然此时对于训练集的拟合程度会变差。也就是说Nsub越小，模型的方差会减小，但是偏差会增大。在实际案例中，一般会通过交叉验证调参获取一个合适的的Nsub值。
随机森林有一个缺点：不像决策树一样有很好地解释性。但是，随机森林有更好地准确性，同时也并不需要修剪随机森林。对于随机森林来说，只需要选择一个参数，生成决策树的个数。通常情况下，决策树的个数越多，性能越好，但是，计算开销同时也增大了。
随机森林建立过程 第一步：原始训练集D中有N个样本，且每个样本有W维特征。从数据集D中有放回的随机抽取x个样本（Bootstraping方法）组成训练子集Dsub，一共进行w次采样，即生成w个训练子集Dsub。
第二步：每个训练子集Dsub形成一棵决策树，形成了一共w棵决策树。而每一次未被抽到的样本则组成了w个oob（用来做预估）。
第三步：对于单个决策树，树的每个节点处从M个特征中随机挑选m（m&lt;M）个特征，按照结点不纯度最小原则进行分裂。每棵树都一直这样分裂下去，直到该节点的所有训练样例都属于同一类。在决策树的分裂过程中不需要剪枝。
第四步：根据生成的多个决策树分类器对需要进行预测的数据进行预测。根据每棵决策树的投票结果，如果是分类树的话，最后取票数最高的一个类别；如果是回归树的话，利用简单的平均得到最终结果。
随机森林算法优缺点总结及面试问题 随机森林是Bagging的一个扩展变体，是在以决策树为基学习器构建Bagging集成的基础上，进一步在决策树的训练过程中引入了随机属性选择。
随机森林简单、容易实现、计算开销小，在很多实际应用中都变现出了强大的性能，被誉为“代表集成学习技术水平的方法”。可以看出，随机森林对Bagging只做了小改动。并且，Bagging满足差异性的方法是对训练集进行采样；而随机森林不但对训练集进行随机采样，而且还随机选择特征子集，这就使最终集成的泛化性进一步提升。
随着基学习器数目的增加，随机森林通常会收敛到更低的泛化误差，并且训练效率是优于Bagging的。
总结一下随机森林的优缺点：
优点：
训练可以高度并行化，对于大数据时代的大样本训练速度有优势。个人觉得这是的最主要的优点。 由于可以随机选择决策树节点划分特征，这样在样本特征维度很高的时候，仍然能高效的训练模型。 在训练后，可以给出各个特征对于输出的重要性。 由于采用了随机采样，训练出的模型的方差小，泛化能力强。 相对于Boosting系列的Adaboost和GBDT， RF实现比较简单。 对部分特征缺失不敏感。 缺点有：
在某些噪音比较大的样本集上，RF模型容易陷入过拟合。 取值划分比较多的特征容易对RF的决策产生更大的影响，从而影响拟合的模型的效果。 下面看几个面试问题：
1、为什么要有放回的抽样？保证样本集间有重叠，若不放回，每个训练样本集及其分布都不一样，可能导致训练的各决策树差异性很大，最终多数表决无法 “求同”，即最终多数表决相当于“求同”过程。
2、为什么RF的训练效率优于bagging？因为在个体决策树的构建过程中，Bagging使用的是“确定型”决策树，bagging在选择划分属性时要对每棵树是对所有特征进行考察；而随机森林仅仅考虑一个特征子集。
3、随机森林需要剪枝吗？不需要，后剪枝是为了避免过拟合，随机森林随机选择变量与树的数量，已经避免了过拟合，没必要去剪枝了。一般rf要控制的是树的规模，而不是树的置信度，剩下的每棵树需要做的就是尽可能的在自己所对应的数据(特征)集情况下尽可能的做到最好的预测结果。剪枝的作用其实被集成方法消解了，所以用处不大。
Extra-Tree及其与RF的区别 Extra-Tree是随机森林的一个变种, 原理几乎和随机森林一模一样，可以称为：“极其随机森林”，即决策树在节点的划分上，使用随机的特征和随机的阈值。
特征和阈值提供了额外随机性，抑制了过拟合，再一次用高偏差换低方差。它还使得 Extra-Tree 比规则的随机森林更快地训练，因为在每个节点上找到每个特征的最佳阈值是生长树最耗时的任务之一。
Extra-Tree与随机森林的区别有以下两点：
对于每个决策树的训练集，随机森林采用的是随机采样bootstrap来选择采样集作为每个决策树的训练集，而Extra-Tree一般不采用随机采样，即每个决策树采用原始训练集。 在选定了划分特征后，随机森林的决策树会基于基尼系数，均方差之类的原则，选择一个最优的特征值划分点，这和传统的决策树相同。但是Extra-Tree比较的激进，他会随机的选择一个特征值来划分决策树。 从第二点可以看出，由于随机选择了特征值的划分点位，而不是最优点位，这样会导致生成的决策树的规模一般会大于随机森林所生成的决策树。也就是说，模型的方差相对于随机森林进一步减少，但是偏倚相对于随机森林进一步增大。在某些时候，Extra-Tree的泛化能力比随机森林更好。
RF评估特征重要性 在实际业务场景中，我们会关系如何在高维数据中选择对结果影响最大的前n个特征。我们可以使用PCA、LASSO等方法，当然也可以用RF算法来进行特征选择。感兴趣的话。
RF算法的有一个典型的应用：评估单个特征变量的重要性并进行特征选择。
举一个具体的应用场景：银行贷款业务中能否正确的评估企业的信用度，关系到能否有效地回收贷款。但是信用评估模型的数据特征有很多，其中不乏有很多噪音，所以需要计算出每一个特征的重要性并对这些特征进行一个排序，进而可以从所有特征中选择出重要性靠前的特征。
下面我们来看看评估特征重要性的步骤：
对于RF中的每一棵决策树，选择OOB数据计算模型的预测错误率，记为Error1。（在随机森林算法中不需要再进行交叉验证来获取测试集误差的无偏估计）
然后在OOB中所有样本的特征A上加入随机噪声，接着再次用OOB数据计算模型预测错误率，记为Error2。
若森林中有N棵树，则特征A的重要性为 求和(Error2-Error1/N)。
我们细品：在某一特征A上增加了噪音，那么就有理由相信错误率Error2要大于Error1，Error2越大说明特征A重要。
可以这么理解，小A从公司离职了，这个公司倒闭了，说明小A很重要；如果小A走了，公司没变化，说明小A也没啥用。
在sklearn中我们可以这么做：
1 2 3 4 5 6 7 8 from sklearn.cross_validation import train_test_split from sklearn.ensemble import RandomForestClassifier (处理数据) rf_clf = RandomForestClassifier(n_estimators=1000, random_state=666) rf_clf....</p></div><footer class=entry-footer><span title='2023-03-16 19:35:26 +0800 +0800'>2023-03-16</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;Reid</footer><a class=entry-link aria-label="post link to 随机森林算法及其在特征选择中的应用" href=https://reid00.github.io/posts/ml/%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E7%AE%97%E6%B3%95%E5%8F%8A%E5%85%B6%E5%9C%A8%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/></a></article><article class=post-entry><header class=entry-header><h2>生成模型vs判别模型</h2></header><div class=entry-content><p>什么是生成模型和判别模型？ 从本质上讲，生成模型和判别模型是解决分类问题的两类基本思路。首先，您得先了解，分类问题，就是给定一个数据x，要判断它对应的标签y（这么naive的东西都要解释下，求面试官此时内心的阴影面积，嘎嘎）。生成模型就是要学习x和y的联合概率分布P(x,y)，然后根据贝叶斯公式来求得条件概率P(y|x)，预测条件概率最大的y。贝叶斯公式这么简单的知识相信您也了解，我就不啰嗦了。判别模型就是直接学习条件概率分布P(y|x)。
举个栗子 例子1 假设你从来没有见过大象和猫，连听都没有听过，这时，给你看了一张大象的照片和一张猫的照片。如下所示：
然后牵来我家的大象（面试官：你家开动物园的吗？），让你判断这是大象还是猫。你咋办？
你开始回想刚刚看过的照片，大概记起来，大象和猫比起来，有个长鼻子，而眼前这个家伙也有个长鼻子，所以，你兴奋地说：“这是大象！”恭喜你答对了！
你也有可能这样做，你努力回想刚才的两张照片，然后用笔把它们画在了纸上，拿着纸和我家的大象做比较，你发现，眼前的动物更像是大象。于是，你惊喜地宣布：“这玩意是大象！”恭喜你又答对了！
在这个问题中，第一个解决问题的思路就是判别模型，因为你只记住了大象和猫之间的不同之处。第二个解决问题的思路就是生成模型，因为你实际上学习了什么是大象，什么是猫。
例子2 来来来，看一下这四个形式为(x,y)的样本。(1,0), (1,0), (2,0), (2, 1）。假设，我们想从这四个样本中，学习到如何通过x判断y的模型。用生成模型，我们要学习P(x,y)。如下所示：
我们学习到了四个概率值，它们的和是1，这就是P(x,y)。
我们也可以用判别模型，我们要学习P(y|x)，如下所示：
我们同样学习到了四个概率值，但是，这次，是每一行的两个概率值的和为1了。让我们具体来看一下，如何使用这两个模型做判断。
假设 x=1。
对于生成模型， 我们会比较：
P(x=1,y=0) = 1/2 P(x=1,y=1) = 0 我们发现P(x=1,y=0)的概率要比P(x=1,y=1)的概率大，所以，我们判断：x=1时，y=0。
对于判别模型，我们会比较：
P(y=0|x=1) = 1 P(y=1|x=1) = 0 同样，P(y=0|x=1)要比P(y=1|x=1)大，所以，我们判断：x=1时，y=0。
我们看到，虽然最后预测的结果一样，但是得出结果的逻辑却是完全不同的。两个栗子说完，你心里感到很痛快，面试官脸上也露出了赞赏的微笑，但是，他突然问了一个问题。
生成模型为啥叫生成模型 这个问题着实让你没想到，不过，聪明的你略加思考，应该就可以想到。生成模型之所以叫生成模型，是因为，它背后的思想是，x是特征，y是标签，什么样的标签就会生成什么样的特征。好比说，标签是大象，那么可能生成的特征就有大耳朵，长鼻子等等。
当我们来根据x来判断y时，我们实际上是在比较，什么样的y标签更可能生成特征x，我们预测的结果就是更可能生成x特征的y标签。
常见的生成模型和判别模型有哪些呢 生成模型
HMM
朴素贝叶斯
判别模型
逻辑回归
SVM
CRF
最近邻
一般的神经网络</p></div><footer class=entry-footer><span title='2023-03-16 19:35:25 +0800 +0800'>2023-03-16</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;Reid</footer><a class=entry-link aria-label="post link to 生成模型vs判别模型" href=https://reid00.github.io/posts/ml/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8Bvs%E5%88%A4%E5%88%AB%E6%A8%A1%E5%9E%8B/></a></article><footer class=page-footer><nav class=pagination><a class=next href=https://reid00.github.io/page/2/>Next »</a></nav></footer></main><footer class=footer><span>&copy; 2023 <a href=https://reid00.github.io/>Reid's Blog</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>