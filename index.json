[{"content":"1. SVM SVM的应用 SVM在很多诸如文本分类，图像分类，生物序列分析和生物数据挖掘，手写字符识别等领域有很多的应用，但或许你并没强烈的意识到，SVM可以成功应用的领域远远超出现在已经在开发应用了的领域。\n通常人们会从一些常用的核函数中选择（根据问题和数据的不同，选择不同的参数，实际上就是得到了不同的核函数），例如：多项式核、高斯核、线性核。\nSVM是一种二类分类模型。它的基本模型是在特征空间中寻找间隔最大化的分离超平面的线性分类器。（间隔最大是它有别于感知机）\n（1）当训练样本线性可分时，通过硬间隔最大化，学习一个线性分类器，即线性可分支持向量机；\n（2）当训练数据近似线性可分时，引入松弛变量，通过软间隔最大化，学习一个线性分类器，即线性支持向量机；\n（3）当训练数据线性不可分时，通过使用核技巧及软间隔最大化，学习非线性支持向量机。\n注：以上各SVM的数学推导应该熟悉：硬间隔最大化（几何间隔）\u0026mdash;学习的对偶问题\u0026mdash;软间隔最大化（引入松弛变量）\u0026mdash;非线性支持向量机（核技巧）。\n读者可能还是没明白核函数到底是个什么东西？我再简要概括下，即以下三点：\n实际中，我们会经常遇到线性不可分的样例，此时，我们的常用做法是把样例特征映射到高维空间中去(映射到高维空间后，相关特征便被分开了，也就达到了分类的目的)； 但进一步，如果凡是遇到线性不可分的样例，一律映射到高维空间，那么这个维度大小是会高到可怕的。那咋办呢？ 此时，核函数就隆重登场了，核函数的价值在于它虽然也是将特征进行从低维到高维的转换，但核函数绝就绝在它事先在低维上进行计算，而将实质上的分类效果表现在了高维上，避免了直接在高维空间中的复杂计算 2. SVM的一些问题 SVM为什么采用间隔最大化？ 当训练数据线性可分时，存在无穷个分离超平面可以将两类数据正确分开。\n感知机利用误分类最小策略，求得分离超平面，不过此时的解有无穷多个。\n线性可分支持向量机利用间隔最大化求得最优分离超平面，这时，解是唯一的。另一方面，此时的分隔超平面所产生的分类结果是最鲁棒的，对未知实例的泛化能力最强。\n然后应该借此阐述，几何间隔，函数间隔，及从函数间隔—\u0026gt;求解最小化1/2 ||w||^2 时的w和b。即线性可分支持向量机学习算法—最大间隔法的由来。\nSVM如何处理多分类问题？** 一般有两种做法：一种是直接法，直接在目标函数上修改，将多个分类面的参数求解合并到一个最优化问题里面。看似简单但是计算量却非常的大。\n另外一种做法是间接法：对训练器进行组合。其中比较典型的有一对一，和一对多。\n一对多，就是对每个类都训练出一个分类器，由svm是二分类，所以将此而分类器的两类设定为目标类为一类，其余类为另外一类。这样针对k个类可以训练出k个分类器，当有一个新的样本来的时候，用这k个分类器来测试，那个分类器的概率高，那么这个样本就属于哪一类。这种方法效果不太好，bias比较高。\nsvm一对一法（one-vs-one），针对任意两个类训练出一个分类器，如果有k类，一共训练出C(2,k) 个分类器，这样当有一个新的样本要来的时候，用这C(2,k) 个分类器来测试，每当被判定属于某一类的时候，该类就加一，最后票数最多的类别被认定为该样本的类。\n是否存在一组参数使SVM训练误差为0？ Y\n训练误差为0的SVM分类器一定存在吗？ 一定存在\n加入松弛变量的SVM的训练误差可以为0吗？ 如果数据中出现了离群点outliers，那么就可以使用松弛变量来解决。\n使用SMO算法训练的线性分类器并不一定能得到训练误差为0的模型。这是由 于我们的优化目标改变了，并不再是使训练误差最小。\n带核的SVM为什么能分类非线性问题? 核函数的本质是两个函数的內积，通过核函数将其隐射到高维空间，在高维空间非线性问题转化为线性问题, SVM得到超平面是高维空间的线性分类平面。其分类结果也视为低维空间的非线性分类结果, 因而带核的SVM就能分类非线性问题。\n如何选择核函数？ 如果特征的数量大到和样本数量差不多，则选用LR或者线性核的SVM； 如果特征的数量小，样本的数量正常，则选用SVM+高斯核函数； 如果特征的数量小，而样本的数量很大，则需要手工添加一些特征从而变成第一种情况。 3. LR和SVM的联系与区别 相同点 都是线性分类器。本质上都是求一个最佳分类超平面。\n都是监督学习算法\n都是判别模型。判别模型不关心数据是怎么生成的，它只关心信号之间的差别，然后用差别来简单对给定的一个信号进行分类。常见的判别模型有：KNN、SVM、LR，常见的生成模型有：朴素贝叶斯，隐马尔可夫模型。\n不同点 LR是参数模型，svm是非参数模型，linear和rbf则是针对数据线性可分和不可分的区别\n从目标函数来看，区别在于逻辑回归采用的是logistical loss，SVM采用的是hinge loss，这两个损失函数的目的都是增加对分类影响较大的数据点的权重，减少与分类关系较小的数据点的权重。\nSVM的处理方法是只考虑support vectors，也就是和分类最相关的少数点，去学习分类器。而逻辑回归通过非线性映射，大大减小了离分类平面较远的点的权重，相对提升了与分类最相关的数据点的权重。\n逻辑回归相对来说模型更简单，好理解，特别是大规模线性分类时比较方便。而SVM的理解和优化相对来说复杂一些，SVM转化为对偶问题后,分类只需要计算与少数几个支持向量的距离,这个在进行复杂核函数计算时优势很明显,能够大大简化模型和计算。\nlogic 能做的 svm能做，但可能在准确率上有问题，svm能做的logic有的做不了。\n4. 线性分类器与非线性分类器的区别以及优劣 线性和非线性是针对模型参数和输入特征来讲的；比如输入x，模型y=ax+ax^2 那么就是非线性模型，如果输入是x和X^2则模型是线性的。\n线性分类器可解释性好，计算复杂度较低，不足之处是模型的拟合效果相对弱些。\nLR,贝叶斯分类，单层感知机、线性回归\n非线性分类器效果拟合能力较强，不足之处是数据量不足容易过拟合、计算复杂度高、可解释性不好。\n决策树、RF、GBDT、多层感知机\nSVM两种都有（看线性核还是高斯核 即RBF ）\n线性核：主要用于线性可分的情形，参数少，速度快，对于一般数据，分类效果已经很理想了。\nRBF 核：主要用于线性不可分的情形，参数多，分类结果非常依赖于参数。有很多人是通过训练数据的交叉验证来寻找合适的参数，不过这个过程比较耗时。 如果 Feature 的数量很大，跟样本数量差不多，这时候选用线性核的 SVM。 如果 Feature 的数量比较小，样本数量一般，不算大也不算小，选用高斯核的 SVM。\n*为什么要转为对偶问题？（阿里面试）*\n(a) 目前处理的模型严重依赖于数据集的维度d，如果维度d太高就会严重提升运算时间；\n(b) 对偶问题事实上把SVM从依赖d个维度转变到依赖N个数据点，考虑到在最后计算时只有支持向量才有意义，所以这个计算量实际上比N小很多。\n一、是对偶问题往往更易求解（当我们寻找约束存在时的最优点的时候，约束的存在虽然减小了需要搜寻的范围，但是却使问题变得更加复杂。为了使问题变得易于处理，我们的方法是把目标函数和约束全部融入一个新的函数，即拉格朗日函数，再通过这个函数来寻找最优点。）\n二、自然引入核函数，进而推广到非线性分类问题\n参考: https://cloud.tencent.com/developer/article/1541701\n","permalink":"https://reid00.github.io/post/svm/","summary":"1. SVM SVM的应用 SVM在很多诸如文本分类，图像分类，生物序列分析和生物数据挖掘，手写字符识别等领域有很多的应用，但或许你并没强烈的意识到，S","title":"SVM"},{"content":"决策树 决策树（decision tree）是一个树结构（可以是二叉树或非二叉树）。其每个非叶节点表示一个特征属性上的测试，每个分支代表这个特征属性在某个值域上的输出，而每个叶节点存放一个类别。使用决策树进行决策的过程就是从根节点开始，测试待分类项中相应的特征属性，并按照其值选择输出分支，直到到达叶子节点，将叶子节点存放的类别作为决策结果[1]。 下面先来看一个小例子，看看决策树到底是什么概念（这个例子来源于[2]）。\n决策树的训练数据往往就是这样的表格形式，表中的前三列（ID不算）是数据样本的属性，最后一列是决策树需要做的分类结果。通过该数据，构建的决策树如下：\n有了这棵树，我们就可以对新来的用户数据进行是否可以偿还的预测了。\n决策树最重要的是决策树的构造。所谓决策树的构造就是进行属性选择度量确定各个特征属性之间的拓扑结构。构造决策树的关键步骤是分裂属性。所谓分裂属性就是在某个节点处按照某一特征属性的不同划分构造不同的分支，其目标是让各个分裂子集尽可能地“纯”。尽可能“纯”就是尽量让一个分裂子集中待分类项属于同一类别。分裂属性分为三种不同的情况[1]： 1、属性是离散值且不要求生成二叉决策树。此时用属性的每一个划分作为一个分支。 2、属性是离散值且要求生成二叉决策树。此时使用属性划分的一个子集进行测试，按照“属于此子集”和“不属于此子集”分成两个分支。 3、属性是连续值。此时确定一个值作为分裂点split_point，按照\u0026gt;split_point和\u0026lt;=split_point生成两个分支。\n决策树的属性分裂选择是”贪心“算法，也就是没有回溯的。\nID3.5 好了，接下来说一下教科书上提到最多的决策树ID3.5算法（是最基本的模型，简单实用，但是在某些场合下也有缺陷）。\n信息论中有熵（entropy）的概念，表示状态的混乱程度，熵越大越混乱。熵的变化可以看做是信息增益，决策树ID3算法的核心思想是以信息增益度量属性选择，选择分裂后信息增益最大的属性进行分裂。\n设D为用（输出）类别对训练元组进行的划分，则D的熵表示为： info(D)=−∑i=1mpilog2(pi)info(D)=−∑i=1mpilog2⁡(pi)\n其中pipi表示第i个类别在整个训练元组中出现的概率，一般来说会用这个类别的样本数量占总量的占比来作为概率的估计；熵的实际意义表示是D中元组的类标号所需要的平均信息量。熵的含义可以看我前面写的PRML ch1.6 信息论的介绍。 如果将训练元组D按属性A进行划分，则A对D划分的期望信息为： infoA(D)=∑j=1v|Dj||D|info(Dj) infoA(D)=∑j=1v|Dj||D|info(Dj) 于是，信息增益就是两者的差值： gain(A)=info(D)−infoA(D) gain(A)=info(D)−infoA(D) ID3决策树算法就用到上面的信息增益，在每次分裂的时候贪心选择信息增益最大的属性，作为本次分裂属性。每次分裂就会使得树长高一层。这样逐步生产下去，就一定可以构建一颗决策树。（基本原理就是这样，但是实际中，为了防止过拟合，以及可能遇到叶子节点类别不纯的情况，需要有一些特殊的trick，这些留到最后讲）\nOK，借鉴一下[1]中的一个小例子，来看一下信息增益的计算过程。\n这个例子是这样的：输入样本的属性有三个——日志密度（L），好友密度（F），以及是否使用真实头像（H）；样本的标记是账号是否真实yes or no。\n然后可以一次计算每一个属性的信息增益，比如日致密度的信息增益是0.276。\n同理可得H和F的信息增益为0.033和0.553。因为F具有最大的信息增益，所以第一次分裂选择F为分裂属性，分裂后的结果如下图表示：\n上面为了简便，将特征属性离散化了，其实日志密度和好友密度都是连续的属性。对于特征属性为连续值，可以如此使用ID3算法：先将D中元素按照特征属性排序，则每两个相邻元素的中间点可以看做潜在分裂点，从第一个潜在分裂点开始，分裂D并计算两个集合的期望信息，具有最小期望信息的点称为这个属性的最佳分裂点，其信息期望作为此属性的信息期望。\nC4.5 ID3有一些缺陷，就是选择的时候容易选择一些比较容易分纯净的属性，尤其在具有像ID值这样的属性，因为每个ID都对应一个类别，所以分的很纯净，ID3比较倾向找到这样的属性做分裂。\nC4.5算法定义了分裂信息，表示为： split_infoA(D)=−∑j=1v|Dj||D|log2(|Dj||D|) split_infoA(D)=−∑j=1v|Dj||D|log2⁡(|Dj||D|) 很容易理解，这个也是一个熵的定义，pi=|Dj||D|pi=|Dj||D|，可以看做是属性分裂的熵，分的越多就越混乱，熵越大。定义信息增益率： gain_ratio(A)=gain(A)split_info(A) gain_ratio(A)=gain(A)split_info(A)\nC4.5就是选择最大增益率的属性来分裂，其他类似ID3.5。\nCART CART（Classification And Regression Tree）算法既可以用于创建分类树，也可以用于创建回归树。CART算法的重要特点包含以下三个方面：\n二分(Binary Split)：在每次判断过程中，都是对样本数据进行二分。CART算法是一种二分递归分割技术，把当前样本划分为两个子样本，使得生成的每个非叶子结点都有两个分支，因此CART算法生成的决策树是结构简洁的二叉树。由于CART算法构成的是一个二叉树，它在每一步的决策时只能是“是”或者“否”，即使一个feature有多个取值，也是把数据分为两部分 单变量分割(Split Based on One Variable)：每次最优划分都是针对单个变量。 剪枝策略：CART算法的关键点，也是整个Tree-Based算法的关键步骤。剪枝过程特别重要，所以在最优决策树生成过程中占有重要地位。有研究表明，剪枝过程的重要性要比树生成过程更为重要，对于不同的划分标准生成的最大树(Maximum Tree)，在剪枝之后都能够保留最重要的属性划分，差别不大。反而是剪枝方法对于最优树的生成更为关键。 CART分类决策树 GINI指数 CART的分支标准建立在GINI指数这个概念上，GINI指数主要是度量数据划分的不纯度，是介于0~1之间的数。GINI值越小，表明样本集合的纯净度越高；GINI值越大表明样本集合的类别越杂乱\nCART分类时，使用基尼指数（Gini）来选择最好的数据分割的特征，gini描述的是纯度，与信息熵的含义相似。CART中每一次迭代都会降低GINI系数。最好的划分就是使得GINI_Gain最小的划分。\n停止条件 决策树的构建过程是一个递归的过程，所以需要确定停止条件，否则过程将不会结束。一种最直观的方式是当每个子节点只有一种类型的记录时停止，但是这样往往会使得树的节点过多，导致过拟合问题（Overfitting）。另一种可行的方法是当前节点中的记录数低于一个最小的阀值，那么就停止分割，将max(P(i))对应的分类作为当前叶节点的分类。\n过度拟合 采用上面算法生成的决策树在事件中往往会导致过度拟合。也就是该决策树对训练数据可以得到很低的错误率，但是运用到测试数据上却得到非常高的错误率。过渡拟合的原因有以下几点： •噪音数据：训练数据中存在噪音数据，决策树的某些节点有噪音数据作为分割标准，导致决策树无法代表真实数据。 •缺少代表性数据：训练数据没有包含所有具有代表性的数据，导致某一类数据无法很好的匹配，这一点可以通过观察混淆矩阵（Confusion Matrix）分析得出。 •多重比较（Mulitple Comparision）：举个列子，股票分析师预测股票涨或跌。假设分析师都是靠随机猜测，也就是他们正确的概率是0.5。每一个人预测10次，那么预测正确的次数在8次或8次以上的概率为 ，C810∗(0.5)10+C910∗(0.5)10+C1010∗(0.5)10C108∗(0.5)10+C109∗(0.5)10+C1010∗(0.5)10只有5%左右，比较低。但是如果50个分析师，每个人预测10次，选择至少一个人得到8次或以上的人作为代表，那么概率为 1−(1−0.0547)50=0.93991−(1−0.0547)50=0.9399，概率十分大，随着分析师人数的增加，概率无限接近1。但是，选出来的分析师其实是打酱油的，他对未来的预测不能做任何保证。上面这个例子就是多重比较。这一情况和决策树选取分割点类似，需要在每个变量的每一个值中选取一个作为分割的代表，所以选出一个噪音分割标准的概率是很大的。\n优化方案1：修剪枝叶 决策树过渡拟合往往是因为太过“茂盛”，也就是节点过多，所以需要裁剪（Prune Tree）枝叶。裁剪枝叶的策略对决策树正确率的影响很大。主要有两种裁剪策略。\n前置裁剪 （PrePrune：预剪枝）在构建决策树的过程时，提前停止。那么，会将切分节点的条件设置的很苛刻，导致决策树很短小。结果就是决策树无法达到最优。实践证明这中策略无法得到较好的结果。\n后置裁剪（PostPrune：后剪枝） 决策树构建好后，然后才开始裁剪。采用两种方法：1）用单一叶节点代替整个子树，叶节点的分类采用子树中最主要的分类；2）将一个字数完全替代另外一颗子树。后置裁剪有个问题就是计算效率，有些节点计算后就被裁剪了，导致有点浪费。\n剪枝可以分为两种：预剪枝(Pre-Pruning)和后剪枝(Post-Pruning),下面我们来详细学习下这两种方法： PrePrune：预剪枝，及早的停止树增长，方法可以参考见上面树停止增长的方法。 PostPrune：后剪枝，在已生成过拟合决策树上进行剪枝，可以得到简化版的剪枝决策树。\n优化方案2：K-Fold Cross Validation 首先计算出整体的决策树T，叶节点个数记作N，设i属于[1,N]。对每个i，使用K-Fold Validataion方法计算决策树，并裁剪到i个节点，计算错误率，最后求出平均错误率。（意思是说对每一个可能的i，都做K次，然后取K次的平均错误率。）这样可以用具有最小错误率对应的i作为最终决策树的大小，对原始决策树进行裁剪，得到最优决策树。\n优化方案3：Random Forest Random Forest是用训练数据随机的计算出许多决策树，形成了一个森林。然后用这个森林对未知数据进行预测，选取投票最多的分类。实践证明，此算法的错误率得到了经一步的降低。这种方法背后的原理可以用“三个臭皮匠定一个诸葛亮”这句谚语来概括。一颗树预测正确的概率可能不高，但是集体预测正确的概率却很高。RF是非常常用的分类算法，效果一般都很好。\nOK，决策树就讲到这里，商用的决策树C5.0了解不是很多；还有分类回归树CART也很常用。\n","permalink":"https://reid00.github.io/post/%E5%86%B3%E7%AD%96%E6%A0%91/","summary":"决策树 决策树（decision tree）是一个树结构（可以是二叉树或非二叉树）。其每个非叶节点表示一个特征属性上的测试，每个分支代表这个特征","title":"决策树"},{"content":"一、线性模型预测一个样本的损失量 损失量：模型对样本的预测结果和该样本对应的实际结果的差距；\n1）为什么会想到用 y = -log(x) 函数? （该函数称为 惩罚函数：预测结果与实际值的偏差越大，惩罚越大） y = 1（p ≥ 0.5）时，cost = -log(p)，p 越小，样本发生概率越小（最小为 0），则损失函数越大，分类预测值和实际值的偏差越大；相反，p 越大，样本发生概率越大（最大为 0.5），则损失函数越小，则预测值和实际值的偏差越小； y = 0（p ≤ 0.5）时，cost = -log(1-p)，p 越小，样本发生概率越小（最小为 0.5），则损失函数越大，分类预测值和实际值的偏差越大；相反，p 越大，样本发生概率越大（最大为 1），则损失函数越小，则预测值和实际值的偏差越小； 2）求一个样本的损失量 由于逻辑回归解决的是分类问题，而且是二分类，因此定义损失函数时也要有两类\n惩罚函数变形：\n惩罚函数作用：计算预测结果针对实际值的损失量；\n已知样本发生的概率 p（也可以相应求出预测值），以及该样本的实际分类结果，得出此次预测结果针对真值的损失量是多少； 二、求数据集的损失函数 模型变形，得到数据集的损失函数：数据集中的所有样本的损失值的和； 最终的损失函数模型 该模型不能优化成简单的数学表达式（或者说是正规方程解：线性回归算法找那个的fit_normal() 方法），只能使用梯度下降法求解； 该函数为凸函数，没有局部最优解，只存在全局最优解； 三、逻辑回归损失函数的梯度 损失函数： 1）σ(t) 函数的导数 2）log(σ(t)) 函数的导数 变形：\n3）log(1 - σ(t)) 函数的导数 4）对损失函数 J(θ) 的其中某一项（第 i 行，第 j 列）求导 两式相加： 5）损失函数 J(θ) 的梯度 与线性回归梯度对比\n注：两者的预测值 ý 不同； 梯度向量化处理 四、代码实现逻辑回归算法 逻辑回归算法是在线性回归算法的基础上演变的；\n1）代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 import numpy as np from .metrics import accuracy_score # accuracy_score方法：查看准确率 class LogisticRegression: def __init__(self): \u0026#34;\u0026#34;\u0026#34;初始化Logistic Regression模型\u0026#34;\u0026#34;\u0026#34; self.coef_ = None self.intercept_ = None self._theta = None def _sigmiod(self, t): \u0026#34;\u0026#34;\u0026#34;函数名首部为\u0026#39;_\u0026#39;，表明该函数为私有函数，其它模块不能调用\u0026#34;\u0026#34;\u0026#34; return 1. / (1. + np.exp(-t)) def fit(self, X_train, y_train, eta=0.01, n_iters=1e4): \u0026#34;\u0026#34;\u0026#34;根据训练数据集X_train, y_train, 使用梯度下降法训练Logistic Regression模型\u0026#34;\u0026#34;\u0026#34; assert X_train.shape[0] == y_train.shape[0], \\ \u0026#34;the size of X_train must be equal to the size of y_train\u0026#34; def J(theta, X_b, y): y_hat = self._sigmiod(X_b.dot(theta)) try: return - np.sum(y*np.log(y_hat) + (1-y)*np.log(1-y_hat)) / len(y) except: return float(\u0026#39;inf\u0026#39;) def dJ(theta, X_b, y): return X_b.T.dot(self._sigmiod(X_b.dot(theta)) - y) / len(X_b) def gradient_descent(X_b, y, initial_theta, eta, n_iters=1e4, epsilon=1e-8): theta = initial_theta cur_iter = 0 while cur_iter \u0026lt; n_iters: gradient = dJ(theta, X_b, y) last_theta = theta theta = theta - eta * gradient if (abs(J(theta, X_b, y) - J(last_theta, X_b, y)) \u0026lt; epsilon): break cur_iter += 1 return theta X_b = np.hstack([np.ones((len(X_train), 1)), X_train]) initial_theta = np.zeros(X_b.shape[1]) self._theta = gradient_descent(X_b, y_train, initial_theta, eta, n_iters) self.intercept_ = self._theta[0] self.coef_ = self._theta[1:] return self def predict_proda(self, X_predict): \u0026#34;\u0026#34;\u0026#34;给定待预测数据集X_predict，返回 X_predict 中的样本的发生的概率向量\u0026#34;\u0026#34;\u0026#34; assert self.intercept_ is not None and self.coef_ is not None, \\ \u0026#34;must fit before predict!\u0026#34; assert X_predict.shape[1] == len(self.coef_), \\ \u0026#34;the feature number of X_predict must be equal to X_train\u0026#34; X_b = np.hstack([np.ones((len(X_predict), 1)), X_predict]) return self._sigmiod(X_b.dot(self._theta)) def predict(self, X_predict): \u0026#34;\u0026#34;\u0026#34;给定待预测数据集X_predict，返回表示X_predict的分类结果的向量\u0026#34;\u0026#34;\u0026#34; assert self.intercept_ is not None and self.coef_ is not None, \\ \u0026#34;must fit before predict!\u0026#34; assert X_predict.shape[1] == len(self.coef_), \\ \u0026#34;the feature number of X_predict must be equal to X_train\u0026#34; proda = self.predict_proda(X_predict) # proda：单个待预测样本的发生概率 # proda \u0026gt;= 0.5：返回元素为布尔类型的向量； # np.array(proda \u0026gt;= 0.5, dtype=\u0026#39;int\u0026#39;)：将布尔数据类型的向量转化为元素为 int 型的数组，则该数组中的 0 和 1 代表两种不同的分类类别； return np.array(proda \u0026gt;= 0.5, dtype=\u0026#39;int\u0026#39;) def score(self, X_test, y_test): \u0026#34;\u0026#34;\u0026#34;根据测试数据集 X_test 和 y_test 确定当前模型的准确度\u0026#34;\u0026#34;\u0026#34; y_predict = self.predict(X_test) # 分类问题的化，查看标准是分类的准确度：accuracy_score(y_test, y_predict) return accuracy_score(y_test, y_predict) def __repr__(self): \u0026#34;\u0026#34;\u0026#34;实例化类之后，输出显示 LogisticRegression()\u0026#34;\u0026#34;\u0026#34; return \u0026#34;LogisticRegression()\u0026#34; 2）使用自己的算法（Jupyter NoteBook 中使用） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 import numpy as np import matplotlib.pyplot as plt from sklearn import datasets iris = datasets.load_iris() X = iris.data y = iris.target X = X[y\u0026lt;2, :2] y = y[y\u0026lt;2] from playML.train_test_split import train_test_split X_train, X_test, y_train, y_test = train_test_split(X, y, seed=666) from playML.LogisticRegression import LogisticRegression log_reg = LogisticRegression() log_reg.fit(X_train, y_train) log_reg.score(X_test, y_test) # 输出：1.0 # 查看测试数据集的样本发生的概率 log_reg.predict_proda(X_test) # 输出：array([0.92972035, 0.98664939, 0.14852024, 0.17601199, 0.0369836 , 0.0186637 , 0.04936918, 0.99669244, 0.97993941, 0.74524655, 0.04473194, 0.00339285, 0.26131273, 0.0369836 , 0.84192923, 0.79892262, 0.82890209, 0.32358166, 0.06535323, 0.20735334]) ","permalink":"https://reid00.github.io/post/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/","summary":"一、线性模型预测一个样本的损失量 损失量：模型对样本的预测结果和该样本对应的实际结果的差距； 1）为什么会想到用 y = -log(x) 函数? （该函数称为 惩罚函数","title":"逻辑回归"},{"content":"Summary 本文将从一个下山的场景开始，先提出梯度下降算法的基本思想，进而从数学上解释梯度下降算法的原理，最后实现一个简单的梯度下降算法的实例！\n梯度下降的场景假设 梯度下降法的基本思想可以类比为一个下山的过程。假设这样一个场景：一个人被困在山上，需要从山上下来(i.e. 找到山的最低点，也就是山谷)。但此时山上的浓雾很大，导致可视度很低。因此，下山的路径就无法确定，他必须利用自己周围的信息去找到下山的路径。这个时候，他就可以利用梯度下降算法来帮助自己下山。具体来说就是，以他当前的所处的位置为基准，寻找这个位置最陡峭的地方，然后朝着山的高度下降的地方走，同理，如果我们的目标是上山，也就是爬到山顶，那么此时应该是朝着最陡峭的方向往上走。然后每走一段距离，都反复采用同一个方法，最后就能成功的抵达山谷。\n我们同时可以假设这座山最陡峭的地方是无法通过肉眼立马观察出来的，而是需要一个复杂的工具来测量，同时，这个人此时正好拥有测量出最陡峭方向的能力。所以，此人每走一段距离，都需要一段时间来测量所在位置最陡峭的方向，这是比较耗时的。那么为了在太阳下山之前到达山底，就要尽可能的减少测量方向的次数。这是一个两难的选择，如果测量的频繁，可以保证下山的方向是绝对正确的，但又非常耗时，如果测量的过少，又有偏离轨道的风险。所以需要找到一个合适的测量方向的频率，来确保下山的方向不错误，同时又不至于耗时太多！\n梯度下降 首先，我们有一个可微分的函数。这个函数就代表着一座山。我们的目标就是找到这个函数的最小值，也就是山底。根据之前的场景假设，最快的下山的方式就是找到当前位置最陡峭的方向，然后沿着此方向向下走，对应到函数中，就是找到给定点的梯度 ，然后朝着梯度相反的方向，就能让函数值下降的最快！因为梯度的方向就是函数之变化最快的方向(在后面会详细解释) 所以，我们重复利用这个方法，反复求取梯度，最后就能到达局部的最小值，这就类似于我们下山的过程。而求取梯度就确定了最陡峭的方向，也就是场景中测量方向的手段。那么为什么梯度的方向就是最陡峭的方向呢？接下来，我们从微分开始讲起\n微分 看待微分的意义，可以有不同的角度，最常用的两种是：\n函数图像中，某点的切线的斜率\n函数的变化率 几个微分的例子：\n上面的例子都是单变量的微分，当一个函数有多个变量的时候，就有了多变量的微分，即分别对每个变量进行求微分\n梯度 梯度实际上就是多变量微分的一般化。 下面这个例子：\n我们可以看到，梯度就是分别对每个变量进行微分，然后用逗号分割开，梯度是用\u0026lt;\u0026gt;包括起来，说明梯度其实一个向量。\n梯度是微积分中一个很重要的概念，之前提到过梯度的意义\n在单变量的函数中，梯度其实就是函数的微分，代表着函数在某个给定点的切线的斜率 在多变量函数中，梯度是一个向量，向量有方向，梯度的方向就指出了函数在给定点的上升最快的方向 这也就说明了为什么我们需要千方百计的求取梯度！我们需要到达山底，就需要在每一步观测到此时最陡峭的地方，梯度就恰巧告诉了我们这个方向。梯度的方向是函数在给定点上升最快的方向，那么梯度的反方向就是函数在给定点下降最快的方向，这正是我们所需要的。所以我们只要沿着梯度的方向一直走，就能走到局部的最低点！\n梯度下降算法的数学解释 上面我们花了大量的篇幅介绍梯度下降算法的基本思想和场景假设，以及梯度的概念和思想。下面我们就开始从数学上解释梯度下降算法的计算过程和思想！ 此公式的意义是：J是关于Θ的一个函数，我们当前所处的位置为Θ0点，要从这个点走到J的最小值点，也就是山底。首先我们先确定前进的方向，也就是梯度的反向，然后走一段距离的步长，也就是α，走完这个段步长，就到达了Θ1这个点！\n下面就这个公式的几个常见的疑问：\nα是什么含义？ α在梯度下降算法中被称作为学习率或者步长，意味着我们可以通过α来控制每一步走的距离，以保证不要步子跨的太大扯着蛋，哈哈，其实就是不要走太快，错过了最低点。同时也要保证不要走的太慢，导致太阳下山了，还没有走到山下。所以α的选择在梯度下降法中往往是很重要的！α不能太大也不能太小，太小的话，可能导致迟迟走不到最低点，太大的话，会导致错过最低点！ 为什么要梯度要乘以一个负号？ 梯度前加一个负号，就意味着朝着梯度相反的方向前进！我们在前文提到，梯度的方向实际就是函数在此点上升最快的方向！而我们需要朝着下降最快的方向走，自然就是负的梯度的方向，所以此处需要加上负号\n梯度下降算法的实例 我们已经基本了解了梯度下降算法的计算过程，那么我们就来看几个梯度下降算法的小实例，首先从单变量的函数开始\n单变量函数的梯度下降 我们假设有一个单变量的函数\n函数的微分 初始化，起点为 学习率为 根据梯度下降的计算公式\n我们开始进行梯度下降的迭代计算过程：\nimage.png\n如图，经过四次的运算，也就是走了四步，基本就抵达了函数的最低点，也就是山底\n多变量函数的梯度下降 我们假设有一个目标函数\n现在要通过梯度下降法计算这个函数的最小值。我们通过观察就能发现最小值其实就是 (0，0)点。但是接下来，我们会从梯度下降算法开始一步步计算到这个最小值！ 我们假设初始的起点为：\n初始的学习率为：\n函数的梯度为：\n进行多次迭代：\n我们发现，已经基本靠近函数的最小值点\n梯度下降算法的实现 下面我们将用python实现一个简单的梯度下降算法。场景是一个简单的线性回归的例子：假设现在我们有一系列的点，如下图所示\n我们将用梯度下降法来拟合出这条直线！\n首先，我们需要定义一个代价函数，在此我们选用均方误差代价函数\n此公式中\nm是数据集中点的个数\n½是一个常量，这样是为了在求梯度的时候，二次方乘下来就和这里的½抵消了，自然就没有多余的常数系数，方便后续的计算，同时对结果不会有影响\ny 是数据集中每个点的真实y坐标的值\nh 是我们的预测函数，根据每一个输入x，根据Θ 计算得到预测的y值，即\n我们可以根据代价函数看到，代价函数中的变量有两个，所以是一个多变量的梯度下降问题，求解出代价函数的梯度，也就是分别对两个变量进行微分\n明确了代价函数和梯度，以及预测的函数形式。我们就可以开始编写代码了。但在这之前，需要说明一点，就是为了方便代码的编写，我们会将所有的公式都转换为矩阵的形式，python中计算矩阵是非常方便的，同时代码也会变得非常的简洁。\n为了转换为矩阵的计算，我们观察到预测函数的形式\n我们有两个变量，为了对这个公式进行矩阵化，我们可以给每一个点x增加一维，这一维的值固定为1，这一维将会乘到Θ0上。这样就方便我们统一矩阵化的计算\n然后我们将代价函数和梯度转化为矩阵向量相乘的形式\ncoding time 首先，我们需要定义数据集和学习率\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 import numpy as np # Size of the points dataset. m = 20 # Points x-coordinate and dummy value (x0, x1). X0 = np.ones((m, 1)) X1 = np.arange(1, m+1).reshape(m, 1) X = np.hstack((X0, X1)) # Points y-coordinate y = np.array([ 3, 4, 5, 5, 2, 4, 7, 8, 11, 8, 12, 11, 13, 13, 16, 17, 18, 17, 19, 21 ]).reshape(m, 1) # The Learning Rate alpha. alpha = 0.01 接下来我们以矩阵向量的形式定义代价函数和代价函数的梯度\n1 2 3 4 5 6 7 8 9 def error_function(theta, X, y): \u0026#39;\u0026#39;\u0026#39;Error function J definition.\u0026#39;\u0026#39;\u0026#39; diff = np.dot(X, theta) - y return (1./2*m) * np.dot(np.transpose(diff), diff) def gradient_function(theta, X, y): \u0026#39;\u0026#39;\u0026#39;Gradient of the function J definition.\u0026#39;\u0026#39;\u0026#39; diff = np.dot(X, theta) - y return (1./m) * np.dot(np.transpose(X), diff) 最后就是算法的核心部分，梯度下降迭代计算\n1 2 3 4 5 6 7 8 def gradient_descent(X, y, alpha): \u0026#39;\u0026#39;\u0026#39;Perform gradient descent.\u0026#39;\u0026#39;\u0026#39; theta = np.array([1, 1]).reshape(2, 1) gradient = gradient_function(theta, X, y) while not np.all(np.absolute(gradient) \u0026lt;= 1e-5): theta = theta - alpha * gradient gradient = gradient_function(theta, X, y) return theta 当梯度小于1e-5时，说明已经进入了比较平滑的状态，类似于山谷的状态，这时候再继续迭代效果也不大了，所以这个时候可以退出循环！\n完整的代码如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 import numpy as np # Size of the points dataset. m = 20 # Points x-coordinate and dummy value (x0, x1). X0 = np.ones((m, 1)) X1 = np.arange(1, m+1).reshape(m, 1) X = np.hstack((X0, X1)) # Points y-coordinate y = np.array([ 3, 4, 5, 5, 2, 4, 7, 8, 11, 8, 12, 11, 13, 13, 16, 17, 18, 17, 19, 21 ]).reshape(m, 1) # The Learning Rate alpha. alpha = 0.01 def error_function(theta, X, y): \u0026#39;\u0026#39;\u0026#39;Error function J definition.\u0026#39;\u0026#39;\u0026#39; diff = np.dot(X, theta) - y return (1./2*m) * np.dot(np.transpose(diff), diff) def gradient_function(theta, X, y): \u0026#39;\u0026#39;\u0026#39;Gradient of the function J definition.\u0026#39;\u0026#39;\u0026#39; diff = np.dot(X, theta) - y return (1./m) * np.dot(np.transpose(X), diff) def gradient_descent(X, y, alpha): \u0026#39;\u0026#39;\u0026#39;Perform gradient descent.\u0026#39;\u0026#39;\u0026#39; theta = np.array([1, 1]).reshape(2, 1) gradient = gradient_function(theta, X, y) while not np.all(np.absolute(gradient) \u0026lt;= 1e-5): theta = theta - alpha * gradient gradient = gradient_function(theta, X, y) return theta optimal = gradient_descent(X, y, alpha) print(\u0026#39;optimal:\u0026#39;, optimal) print(\u0026#39;error function:\u0026#39;, error_function(optimal, X, y)[0,0]) 运行代码，计算得到的结果如下\n所拟合出的直线如下\n小结 至此，我们就基本介绍完了梯度下降法的基本思想和算法流程，并且用python实现了一个简单的梯度下降算法拟合直线的案例！ 最后，我们回到文章开头所提出的场景假设: 这个下山的人实际上就代表了反向传播算法，下山的路径其实就代表着算法中一直在寻找的参数Θ，山上当前点的最陡峭的方向实际上就是代价函数在这一点的梯度方向，场景中观测最陡峭方向所用的工具就是微分 。在下一次观测之前的时间就是有我们算法中的学习率α所定义的。 可以看到场景假设和梯度下降算法很好的完成了对应！\n","permalink":"https://reid00.github.io/post/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E5%8E%9F%E7%90%86%E4%BB%8B%E7%BB%8D/","summary":"Summary 本文将从一个下山的场景开始，先提出梯度下降算法的基本思想，进而从数学上解释梯度下降算法的原理，最后实现一个简单的梯度下降算法的实例！ 梯度下","title":"梯度下降原理介绍"},{"content":" 称函数为效用函数 线性回归模型看起来非常简单，简单到让人怀疑其是否有研究价值以及使用价值。但实际上，线性回归模型可以说是最重要的数学模型之一，很多模型都是建立在它的基础之上，可以被称为是“模型之母”。\n1.1 什么是简单线性回归 所谓简单，是指只有一个样本特征，即只有一个自变量；所谓线性，是指方程是线性的；所谓回归，是指用方程来模拟变量之间是如何关联的。\n简单线性回归，其思想简单，实现容易（与其背后强大的数学性质相关。同时也是许多强大的非线性模型（多项式回归、逻辑回归、SVM）的基础。并且其结果具有很好的可解释性。\n1.2 一种基本推导思 我们所谓的建模过程，其实就是找到一个模型，最大程度的拟合我们的数据。 在简单线回归问题中，模型就是我们的直线方程：y = ax + b 。\n要想最大的拟合数据，本质上就是找到没有拟合的部分，也就是损失的部分尽量小，就是损失函数（loss function）（也有算法是衡量拟合的程度，称函数为效用函数（utility function））：\n因此，推导思路为：\n通过分析问题，确定问题的损失函数或者效用函数； 然后通过最优化损失函数或者效用函数，获得机器学习的模型 近乎所有参数学习算法都是这样的套路，区别是模型不同，建立的目标函数不同，优化的方式也不同。\n回到简单线性回归问题，目标：\n已知训练数据样本、 ，找到和的值，使 尽可能小\n这是一个典型的最小二乘法问题（最小化误差的平方）\n通过最小二乘法可以求出a、b的表达式：\n最小二乘法 2.1 由损失函数引出一堆“风险” 2.1.1 损失函数 在机器学习中，所有的算法模型其实都依赖于最小化或最大化某一个函数，我们称之为“目标函数”。\n最小化的这组函数被称为“损失函数”。什么是损失函数呢？\n损失函数描述了单个样本预测值和真实值之间误差的程度。用来度量模型一次预测的好坏。\n损失函数是衡量预测模型预测期望结果表现的指标。损失函数越小，模型的鲁棒性越好。。\n常用损失函数有：\n0-1损失函数：用来表述分类问题，当预测分类错误时，损失函数值为1，正确为 平方损失函数：用来描述回归问题，用来表示连续性变量，为预测值与真实值差值的平方。（误差值越大、惩罚力度越强，也就是对差值敏感）\n绝对损失函数：用在回归模型，用距离的绝对值来衡量 对数损失函数：是预测值Y和条件概率之间的衡量。事实上，该损失函数用到了极大似然估计的思想。P(Y|X)通俗的解释就是：在当前模型的基础上，对于样本X，其预测值为Y，也就是预测正确的概率。由于概率之间的同时满足需要使用乘法，为了将其转化为加法，我们将其取对数。最后由于是损失函数，所以预测正确的概率越高，其损失值应该是越小，因此再加个负号取个反。 以上损失函数是针对于单个样本的，但是一个训练数据集中存在N个样本，N个样本给出N个损失，如何进行选择呢？\n这就引出了风险函数。\n2.1.2 期望风险 期望风险是损失函数的期望，用来表达理论上模型f(X)关于联合分布P(X,Y)的平均意义下的损失。又叫期望损失/风险函数。\n2.1.3 经验风险 模型f(X)关于训练数据集的平均损失，称为经验风险或经验损失。\n其公式含义为：模型关于训练集的平均损失（每个样本的损失加起来，然后平均一下）\n经验风险最小的模型为最优模型。在训练集上最小经验风险最小，也就意味着预测值和真实值尽可能接近，模型的效果越好。公式含义为取训练样本集中对数损失函数平均值的最小。\n2.1.4 经验风险最小化和结构风险最小化 期望风险是模型关于联合分布的期望损失，经验风险是模型关于训练样本数据集的平均损失。根据大数定律，当样本容量N趋于无穷时，经验风险趋于期望风险。\n因此很自然地想到用经验风险去估计期望风险。但是由于训练样本个数有限，可能会出现过度拟合的问题，即决策函数对于训练集几乎全部拟合，但是对于测试集拟合效果过差。因此需要对其进行矫正：\n结构风险最小化：当样本容量不大的时候，经验风险最小化容易产生“过拟合”的问题，为了“减缓”过拟合问题，提出了结构风险最小理论。结构风险最小化为经验风险与复杂度同时较小。 通过公式可以看出，结构风险：在经验风险上加上一个正则化项(regularizer)，或者叫做罚项(penalty) 。正则化项是J(f)是函数的复杂度再乘一个权重系数（用以权衡经验风险和复杂度）\n2.1.5 小结 1、损失函数：单个样本预测值和真实值之间误差的程度。\n2、期望风险：是损失函数的期望，理论上模型f(X)关于联合分布P(X,Y)的平均意义下的损失。\n3、经验风险：模型关于训练集的平均损失（每个样本的损失加起来，然后平均一下）。\n4、结构风险：在经验风险上加上一个正则化项，防止过拟合的策略。\n2.2 最小二乘法 2.2.1 什么是最小二乘法 言归正传，进入最小二乘法的部分。\n大名鼎鼎的最小二乘法，虽然听上去挺高大上，但是思想还是挺朴素的，符合大家的直觉。\n最小二乘法源于法国数学家阿德里安的猜想：\n对于测量值来说，让总的误差的平方最小的就是真实值。这是基于，如果误差是随机的，应该围绕真值上下波动。\n即：\n那么为了求出这个二次函数的最小值，对其进行求导，导数为0的时候取得最小值：\n进而：\n正好是算数平均数（算数平均数是最小二乘法的特例）。\n这就是最小二乘法，所谓“二乘”就是平方的意思。\n（高斯证明过：如果误差的分布是正态分布，那么最小二乘法得到的就是最有可能的值。）\n2.2.2 线性回归中的应用 我们在第一章中提到：\n目标是，找到a和b，使得损失函数：尽可能的小。\n这里，将简单线性问题转为最优化问题。下面对函数的各个位置分量求导，导数为0的地方就是极值：\n对 进行求导：\n然后mb提到等号前面，两边同时除以m，等号右面的每一项相当于均值。\n现在 对 进行求导：\n此时将对 进行求导得到的结果 代入上式中，得到：\n将上式进行整理，得到\n将上式继续进行整理：\n这样在实现的时候简单很多。\n最终我们通过最小二乘法得到a、b的表达式：\n总结 本章中，我们从数学的角度了解了简单线性回归，从中总结出一类机器学习算法的基本思路：\n通过分析问题，确定问题的损失函数或者效用函数； 然后通过最优化损失函数或者效用函数，获得机器学习的模型。 理解了损失函数的概念，并列举出了常见损失函数，并引出了一堆“风险”。最后为了求出最小的损失函数，学习了最小二乘法，并进行了完整的数学推导。\n下一篇，我们将会实现简单线性回归，并添加到我们自己的工程文件里。\n","permalink":"https://reid00.github.io/post/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/","summary":"称函数为效用函数 线性回归模型看起来非常简单，简单到让人怀疑其是否有研究价值以及使用价值。但实际上，线性回归模型可以说是最重要的数学模型之一，","title":"线性回归"},{"content":"1. 无监督和有监督的区别？ 有监督学习：对具有概念标记（分类）的训练样本进行学习，以尽可能对训练样本集外的数据进行标记（分类）预测。这里，所有的标记（分类）是已知的。因此，训练样本的岐义性低。\n无监督学习：对没有概念标记（分类）的训练样本进行学习，以发现训练样本集中的结构性知识。这里，所有的标记（分类）是未知的。因此，训练样本的岐义性高。聚类就是典型的无监督学习。\n2. SVM 的推导，特性？多分类怎么处理？ SVM是最大间隔分类器，几何间隔和样本的误分次数之间存在关系， ，其中 从线性可分情况下，原问题，特征转换后的dual问题，引入kernel(线性kernel，多项式，高斯)，最后是soft margin。\n线性：简单，速度快，但是需要线性可分。\n多项式：比线性核拟合程度更强，知道具体的维度，但是高次容易出现数值不稳定，参数选择比较多。\n高斯：拟合能力最强，但是要注意过拟合问题。不过只有一个参数需要调整。\n多分类问题，一般将二分类推广到多分类的方式有三种，一对一，一对多，多对多。\n一对一：将N个类别两两配对，产生N(N-1)/2个二分类任务，测试阶段新样本同时交给所有的分类器，最终结果通过投票产生。\n一对多：每一次将一个例作为正例，其他的作为反例，训练N个分类器，测试时如果只有一个分类器预测为正类，则对应类别为最终结果，如果有多个，则一般选择置信度最大的。从分类器角度一对一更多，但是每一次都只用了2个类别，因此当类别数很多的时候一对一开销通常更小(只要训练复杂度高于O(N)即可得到此结果)。\n多对多：若干各类作为正类，若干个类作为反类。注意正反类必须特殊的设计。\n3. LR 的推导，特性？ LR的优点在于实现简单，并且计算量非常小，速度很快，存储资源低，缺点就是因为模型简单，对于复杂的情况下会出现欠拟合，并且只能处理2分类问题(可以通过一般的二元转换为多元或者用softmax回归)。\n4. 决策树的特性？ 决策树基于树结构进行决策，与人类在面临问题的时候处理机制十分类似。其特点在于需要选择一个属性进行分支，在分支的过程中选择信息增益最大的属性，定义如下　在划分中我们希望决策树的分支节点所包含的样本属于同一类别，即节点的纯度越来越高。决策树计算量简单，可解释性强，比较适合处理有缺失属性值的样本，能够处理不相关的特征，但是容易过拟合，需要使用剪枝或者随机森林。信息增益是熵减去条件熵，代表信息不确定性较少的程度，信息增益越大，说明不确定性降低的越大，因此说明该特征对分类来说很重要。由于信息增益准则会对数目较多的属性有所偏好，因此一般用信息增益率(c4.5)\n其中分母可以看作为属性自身的熵。取值可能性越多，属性的熵越大。\nCart决策树使用基尼指数来选择划分属性，直观的来说，Gini(D)反映了从数据集D中随机抽取两个样本，其类别标记不一致的概率，因此基尼指数越小数据集D的纯度越高，一般为了防止过拟合要进行剪枝，有预剪枝和后剪枝，一般用cross validation集进行剪枝。\n连续值和缺失值的处理，对于连续属性a，将a在D上出现的不同的取值进行排序，基于划分点t将D分为两个子集。一般对每一个连续的两个取值的中点作为划分点，然后根据信息增益选择最大的。与离散属性不同，若当前节点划分属性为连续属性，该属性还可以作为其后代的划分属性。\n5. SVM,LR,决策树对比？ SVM既可以用于分类问题，也可以用于回归问题，并且可以通过核函数快速的计算，LR实现简单，训练速度非常快，但是模型较为简单，决策树容易过拟合，需要进行剪枝等。从优化函数上看，soft margin的SVM用的是hinge loss，而带L2正则化的LR对应的是cross entropy loss，另外adaboost对应的是exponential loss。所以LR对远点敏感，但是SVM对outlier不太敏感，因为只关心support vector，SVM可以将特征映射到无穷维空间，但是LR不可以，一般小数据中SVM比LR更优一点，但是LR可以预测概率，而SVM不可以，SVM依赖于数据测度，需要先做归一化，LR一般不需要，对于大量的数据LR使用更加广泛，LR向多分类的扩展更加直接，对于类别不平衡SVM一般用权重解决，即目标函数中对正负样本代价函数不同，LR可以用一般的方法，也可以直接对最后结果调整(通过阈值)，一般小数据下样本维度比较高的时候SVM效果要更优一些。\n6. GBDT 和随机森林的区别？ 随机森林采用的是bagging的思想，bagging又称为bootstrap aggreagation，通过在训练样本集中进行有放回的采样得到多个采样集，基于每个采样集训练出一个基学习器，再将基学习器结合。随机森林在对决策树进行bagging的基础上，在决策树的训练过程中引入了随机属性选择。传统决策树在选择划分属性的时候是在当前节点属性集合中选择最优属性，而随机森林则是对结点先随机选择包含k个属性的子集，再选择最有属性，k作为一个参数控制了随机性的引入程度。\n另外，GBDT训练是基于Boosting思想，每一迭代中根据错误更新样本权重，因此是串行生成的序列化方法，而随机森林是bagging的思想，因此是并行化方法。\n7. 如何判断函数凸或非凸？什么是凸优化？ 首先定义凸集，如果x，y属于某个集合C，并且所有的 也属于c，那么c为一个凸集，进一步，如果一个函数其定义域是凸集，并且\n则该函数为凸函数。上述条件还能推出更一般的结果，\n如果函数有二阶导数，那么如果函数二阶导数为正，或者对于多元函数，Hessian矩阵半正定则为凸函数。\n(也可能引到SVM，或者凸函数局部最优也是全局最优的证明，或者上述公式期望情况下的Jessen不等式)\n8. 如何解决类别不平衡问题？ 有些情况下训练集中的样本分布很不平衡，例如在肿瘤检测等问题中，正样本的个数往往非常的少。从线性分类器的角度，在用 对新样本进行分类的时候，事实上在用预测出的y值和一个y值进行比较，例如常常在y\u0026gt;0.5的时候判为正例，否则判为反例。几率 反映了正例可能性和反例可能性的比值，阈值0.5恰好表明分类器认为正反的可能性相同。在样本不均衡的情况下，应该是分类器的预测几率高于观测几率就判断为正例，因此应该是 时预测为正例，这种策略称为rebalancing。但是训练集并不一定是真实样本总体的无偏采样，通常有三种做法，一种是对训练集的负样本进行欠采样，第二种是对正例进行升采样，第三种是直接基于原始训练集进行学习，在预测的时候再改变阈值，称为阈值移动。注意过采样一般通过对训练集的正例进行插值产生额外的正例，而欠采样将反例划分为不同的集合供不同的学习器使用。\n9. 解释对偶的概念。 一个优化问题可以从两个角度进行考察，一个是primal 问题，一个是dual 问题，就是对偶问题，一般情况下对偶问题给出主问题最优值的下界，在强对偶性成立的情况下由对偶问题可以得到主问题的最优下界，对偶问题是凸优化问题，可以进行较好的求解，SVM中就是将primal问题转换为dual问题进行求解，从而进一步引入核函数的思想。\n10. 如何进行特征选择 ？ 特征选择是一个重要的数据预处理过程，主要有两个原因，首先在现实任务中我们会遇到维数灾难的问题(样本密度非常稀疏)，若能从中选择一部分特征，那么这个问题能大大缓解，另外就是去除不相关特征会降低学习任务的难度，增加模型的泛化能力。冗余特征指该特征包含的信息可以从其他特征中推演出来，但是这并不代表该冗余特征一定没有作用，例如在欠拟合的情况下也可以用过加入冗余特征，增加简单模型的复杂度。\n在理论上如果没有任何领域知识作为先验假设那么只能遍历所有可能的子集。但是这显然是不可能的，因为需要遍历的数量是组合爆炸的。一般我们分为子集搜索和子集评价两个过程，子集搜索一般采用贪心算法，每一轮从候选特征中添加或者删除，分别成为前向和后先搜索。或者两者结合的双向搜索。子集评价一般采用信息增益，对于连续数据往往排序之后选择中点作为分割点。\n常见的特征选择方式有过滤式，包裹式和嵌入式，filter，wrapper和embedding。Filter类型先对数据集进行特征选择，再训练学习器。Wrapper直接把最终学习器的性能作为特征子集的评价准则，一般通过不断候选子集，然后利用cross-validation过程更新候选特征，通常计算量比较大。嵌入式特征选择将特征选择过程和训练过程融为了一体，在训练过程中自动进行了特征选择，例如L1正则化更易于获得稀疏解，而L2正则化更不容易过拟合。L1正则化可以通过PGD，近端梯度下降进行求解。\n11. 为什么会产生过拟合，有哪些方法可以预防或克服过拟合？ 一般在机器学习中，将学习器在训练集上的误差称为训练误差或者经验误差，在新样本上的误差称为泛化误差。显然我们希望得到泛化误差小的学习器，但是我们事先并不知道新样本，因此实际上往往努力使经验误差最小化。然而，当学习器将训练样本学的太好的时候，往往可能把训练样本自身的特点当做了潜在样本具有的一般性质。这样就会导致泛化性能下降，称之为过拟合，相反，欠拟合一般指对训练样本的一般性质尚未学习好，在训练集上仍然有较大的误差。\n欠拟合：一般来说欠拟合更容易解决一些，例如增加模型的复杂度，增加决策树中的分支，增加神经网络中的训练次数等等。根本的原因是特征维度过少，导致拟合的函数无法满足训练集，误差较大。\n欠拟合问题可以通过增加特征维度来解决。可以考虑加入进特征组合、高次特征，来增大假设空间;\n添加多项式特征，这个在机器学习算法里面用的很普遍，例如将线性模型通过添加二次项或者三次项使模型泛化能力更强\n减少正则化参数，正则化的目的是用来防止过拟合的，但是现在模型出现了欠拟合，则需要减少正则化参数\n使用非线性模型，比如核SVM 、决策树、深度学习等模型\n过拟合：一般认为过拟合是无法彻底避免的，因为机器学习面临的问题一般是np-hard，但是一个有效的解一定要在多项式内可以工作，所以会牺牲一些泛化能力。过拟合的解决方案一般有增加样本数量，对样本进行降维，降低模型复杂度，利用先验知识(L1，L2正则化)，利用cross-validation，early stopping等等。根本的原因则是特征维度过多，导致拟合的函数完美的经过训练集，但是对新数据的预测结果则较差。\n其他原因:\n训练数据集样本单一，样本不足。如果训练样本只有负样本，然后那生成的模型去预测正样本，这肯定预测不准。所以训练样本要尽可能的全面，覆盖所有的数据类型。 训练数据中噪声干扰过大。噪声指训练数据中的干扰数据。过多的干扰会导致记录了很多噪声特征，忽略了真实输入和输出之间的关系。 **模型过于复杂。**模型太复杂，已经能够“死记硬背”记下了训练数据的信息，但是遇到没有见过的数据的时候不能够变通，泛化能力太差。我们希望模型对不同的模型都有稳定的输出。模型太复杂是过拟合的重要因素。 获取和使用更多的数据（数据集增强）——解决过拟合的根本性方法\n减少特征维度; 可以人工选择保留的特征，或者模型选择算法\n重新清洗数据，导致过拟合的一个原因也有可能是数据不纯导致的，如果出现了过拟合就需要我们重新清洗数据。\n采用正则化方法。正则化方法包括L0正则、L1正则和L2正则，而正则一般是在目标函数之后加上对于的范数。但是在机器学习中一般使用L2正则，下面看具体的原因。\nL0范数是指向量中非0的元素的个数。L1范数是指向量中各个元素绝对值之和，也叫“稀疏规则算子”（Lasso regularization）。两者都可以实现稀疏性，既然L0可以实现稀疏，为什么不用L0，而要用L1呢？个人理解一是因为L0范数很难优化求解（NP难问题），二是L1范数是L0范数的最优凸近似，而且它比L0范数要容易优化求解。所以大家才把目光和万千宠爱转于L1范数。 L2范数是指向量各元素的平方和然后求平方根。可以使得W的每个元素都很小，都接近于0，但与L1范数不同，它不会让它等于0，而是接近于0。L2正则项起到使得参数w变小加剧的效果，但是为什么可以防止过拟合呢？一个通俗的理解便是：更小的参数值w意味着模型的复杂度更低，对训练数据的拟合刚刚好（奥卡姆剃刀），不会过分拟合训练数据，从而使得不会过拟合，以提高模型的泛化能力。还有就是看到有人说L2范数有助于处理 condition number不好的情况下矩阵求逆很困难的问题。 采用dropout方法。这个方法在神经网络里面很常用。 12. 什么是偏差与方差？ 泛化误差可以分解成偏差的平方加上方差加上噪声。偏差度量了学习算法的期望预测和真实结果的偏离程度，刻画了学习算法本身的拟合能力，方差度量了同样大小的训练集的变动所导致的学习性能的变化，刻画了数据扰动所造成的影响，噪声表达了当前任务上任何学习算法所能达到的期望泛化误差下界，刻画了问题本身的难度。偏差和方差一般称为bias和variance，一般训练程度越强，偏差越小，方差越大，泛化误差一般在中间有一个最小值，如果偏差较大，方差较小，此时一般称为欠拟合，而偏差较小，方差较大称为过拟合。\n偏差： 方差： 13. 神经网络的原理，如何进行训练？ 神经网络自发展以来已经是一个非常庞大的学科，一般而言认为神经网络是由单个的神经元和不同神经元之间的连接构成，不够的结构构成不同的神经网络。最常见的神经网络一般称为多层前馈神经网络，除了输入和输出层，中间隐藏层的个数被称为神经网络的层数。BP算法是训练神经网络中最著名的算法，其本质是梯度下降和链式法则。\n14. 介绍卷积神经网络，和 DBN 有什么区别？ 卷积神经网络的特点是卷积核，CNN中使用了权共享，通过不断的上采用和卷积得到不同的特征表示，采样层又称为pooling层，基于局部相关性原理进行亚采样，在减少数据量的同时保持有用的信息。DBN是深度信念网络，每一层是一个RBM，整个网络可以视为RBM堆叠得到，通常使用无监督逐层训练，从第一层开始，每一层利用上一层的输入进行训练，等各层训练结束之后再利用BP算法对整个网络进行训练\n15. 采用 EM 算法求解的模型有哪些，为什么不用牛顿法或梯度下降法？ 用EM算法求解的模型一般有GMM或者协同过滤，k-means其实也属于EM。EM算法一定会收敛，但是可能收敛到局部最优。由于求和的项数将随着隐变量的数目指数上升，会给梯度计算带来麻烦。\n16. 用 EM 算法推导解释 Kmeans k-means算法是高斯混合聚类在混合成分方差相等，且每个样本仅指派一个混合成分时候的特例。注意k-means在运行之前需要进行归一化处理，不然可能会因为样本在某些维度上过大导致距离计算失效。k-means中每个样本所属的类就可以看成是一个隐变量，在E步中，我们固定每个类的中心，通过对每一个样本选择最近的类优化目标函数，在M步，重新更新每个类的中心点，该步骤可以通过对目标函数求导实现，最终可得新的类中心就是类中样本的均值。\n17. 用过哪些聚类算法，解释密度聚类算法。 k-means算法，聚类性能的度量一般分为两类，一类是聚类结果与某个参考模型比较(外部指标)，另外是直接考察聚类结果(内部指标)。后者通常有DB指数和DI，DB指数是对每个类，找出类内平均距离/类间中心距离最大的类，然后计算上述值，并对所有的类求和，越小越好。类似k-means的算法仅在类中数据构成簇的情况下表现较好，密度聚类算法从样本密度的角度考察样本之间的可连接性，并基于可连接样本不断扩展聚类蔟得到最终结果。DBSCAN(density-based spatial clustering of applications with noise)是一种著名的密度聚类算法，基于一组邻域参数 进行刻画，包括邻域，核心对象(邻域内至少包含 个对象)，密度直达(j由i密度直达，表示j在i的邻域内，且i是一个核心对象)，密度可达(j由i密度可达，存在样本序列使得每一对都密度直达)，密度相连(xi，xj存在k，i，j均有k可达)，先找出样本中所有的核心对象，然后以任一核心对象作为出发点，找出由其密度可达的样本生成聚类蔟，直到所有核心对象被访问过为止。\n18. 聚类算法中的距离度量有哪些？ 聚类算法中的距离度量一般用闽科夫斯基距离，在p取不同的值下对应不同的距离，例如p=1的时候对应曼哈顿距离，p=2的情况下对应欧式距离，p=inf的情况下变为切比雪夫距离，还有jaccard距离，幂距离(闽科夫斯基的更一般形式)，余弦相似度，加权的距离，马氏距离(类似加权)作为距离度量需要满足非负性，同一性，对称性和直递性，闽科夫斯基在p\u0026gt;=1的时候满足读来那个性质，对于一些离散属性例如{飞机，火车，轮船}则不能直接在属性值上计算距离，这些称为无序属性，可以用VDM(Value Diffrence Metrix)，属性u上两个离散值a，b之间的VDM距离定义为\n其中 表示在第i个簇中属性u上a的样本数，样本空间中不同属性的重要性不同的时候可以采用加权距离，一般如果认为所有属性重要性相同则要对特征进行归一化。一般来说距离需要的是相似性度量，距离越大，相似度越小，用于相似性度量的距离未必一定要满足距离度量的所有性质，例如直递性。比如人马和人，人马和马的距离较近，然后人和马的距离可能就很远。\n19. 解释贝叶斯公式和朴素贝叶斯分类。 贝叶斯公式：\n最小化分类错误的贝叶斯最优分类器等价于最大化后验概率。\n基于贝叶斯公式来估计后验概率的主要困难在于，条件概率 是所有属性上的联合概率，难以从有限的训练样本直接估计得到。朴素贝叶斯分类器采用了属性条件独立性假设，对于已知的类别，假设所有属性相互独立。这样，朴素贝叶斯分类则定义为\n如果有足够多的独立同分布样本，那么 可以根据每个类中的样本数量直接估计出来。在离散情况下先验概率可以利用样本数量估计或者离散情况下根据假设的概率密度函数进行最大似然估计。朴素贝叶斯可以用于同时包含连续变量和离散变量的情况。如果直接基于出现的次数进行估计，会出现一项为0而乘积为0的情况，所以一般会用一些平滑的方法，例如拉普拉斯修正，\n这样既可以保证概率的归一化，同时还能避免上述出现的现象。\n20. 解释L1和L2正则化的作用。 L1正则化是在代价函数后面加上 ，L2正则化是在代价函数后面增加了 ，两者都起到一定的过拟合作用，两者都对应一定的先验知识，L1对应拉普拉斯分布，L2对应高斯分布，L1偏向于参数稀疏性，L2偏向于参数分布较为稠\n21. TF-IDF是什么？ TF指Term frequecy，代表词频，IDF代表inverse document frequency，叫做逆文档频率，这个算法可以用来提取文档的关键词，首先一般认为在文章中出现次数较多的词是关键词，词频就代表了这一项，然而有些词是停用词，例如的，是，有这种大量出现的词，首先需要进行过滤，比如过滤之后再统计词频出现了中国，蜜蜂，养殖且三个词的词频几乎一致，但是中国这个词出现在其他文章的概率比其他两个词要高不少，因此我们应该认为后两个词更能表现文章的主题，IDF就代表了这样的信息，计算该值需要一个语料库，如果一个词在语料库中出现的概率越小，那么该词的IDF应该越大，一般来说TF计算公式为(某个词在文章中出现次数/文章的总词数)，这样消除长文章中词出现次数多的影响，IDF计算公式为log(语料库文章总数/(包含该词的文章数)+1)。将两者乘乘起来就得到了词的TF-IDF。传统的TF-IDF对词出现的位置没有进行考虑，可以针对不同位置赋予不同的权重进行修正，注意这些修正之所以是有效的，正是因为人观测过了大量的信息，因此建议了一个先验估计，人将这个先验估计融合到了算法里面，所以使算法更加的有效\n22. 文本中的余弦距离是什么，有哪些作用？ 余弦距离是两个向量的距离的一种度量方式，其值在-1~1之间，如果为1表示两个向量同相，0表示两个向量正交，-1表示两个向量反向。使用TF-IDF和余弦距离可以寻找内容相似的文章，例如首先用TF-IDF找出两篇文章的关键词，然后每个文章分别取出k个关键词(10-20个)，统计这些关键词的词频，生成两篇文章的词频向量，然后用余弦距离计算其相似度。\n参考:\n应聘机器学习工程师？这是你需要知道的12个基础面试问题 Python机器学习Sklearn专题文章集锦 ","permalink":"https://reid00.github.io/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%9D%A2%E8%AF%95%E9%A2%98/","summary":"1. 无监督和有监督的区别？ 有监督学习：对具有概念标记（分类）的训练样本进行学习，以尽可能对训练样本集外的数据进行标记（分类）预测。这里，所有的","title":"机器学习面试题"},{"content":"Summary “所有模型都是坏的，但有些模型是有用的”。我们建立模型之后，接下来就要去评估模型，确定这个模型是否‘有用’。当你费尽全力去建立完模型后，你会发现仅仅就是一些单个的数值或单个的曲线去告诉你你的模型到底是否能够派上用场。\n​ 在实际情况中，我们会用不同的度量去评估我们的模型，而度量的选择，完全取决于模型的类型和模型以后要做的事。下面我们就会学习到一些用于评价模型的常用度量和图表以及它们各自的使用场景。\n模型评估这部分会介绍以下几方面的内容：\n性能度量 模型评估方法 泛化能力 过拟合、欠拟合 超参数调优 本文会首先介绍性能度量方面的内容，主要是分类问题和回归问题的性能指标，包括以下几个方法的介绍：\n准确率和错误率 精确率、召回率以及 F1 ROC 曲线 和 AUC 代价矩阵 回归问题的性能度量 其他评价指标，如计算速度、鲁棒性等 1. 性能度量 性能度量就是指对模型泛化能力衡量的评价标准。\n1.1 准确率和错误率 分类问题中最常用的两个性能度量标准\u0026ndash; 准确率和错误率。\n准确率： 指的是分类正确的样本数量占样本总数的比例，定义如下：\n错误率：指分类错误的样本占样本总数的比例，定义如下：\n错误率也是损失函数为 0-1 损失时的误差。\n这两种评价标准是分类问题中最简单也是最直观的评价指标。但它们都存在一个问题，在类别不平衡的情况下，它们都无法有效评价模型的泛化能力。即如果此时有 99% 的负样本，那么模型预测所有样本都是负样本的时候，可以得到 99% 的准确率。\n这种情况就是在类别不平衡的时候，占比大的类别往往成为影响准确率的最主要因素！\n这种时候，其中一种解决方法就是更换评价指标，比如采用更为有效的平均准确率(每个类别的样本准确率的算术平均)，即：\n其中 m 是类别的数量。\n对于准确率和错误率，用 Python 代码实现如下图所示：\n1 2 3 4 5 6 def accuracy(y_true,y_pred): return sum(y==y_p for y,y_p in zip(y_true,y_pred))/len(y_true def error(y_true, y_pred): return sum(y != y_p for y, y_p in zip(y_true, y_pred)) / len(y_true) 一个简单的二分类测试样例：\n1 2 3 4 5 6 7 y_true = [1, 0, 1, 0, 1] y_pred = [0, 0, 1, 1, 0] acc = accuracy(y_true, y_pred) err = error(y_true, y_pred) print(\u0026#39;accuracy=\u0026#39;, acc) print(\u0026#39;error=\u0026#39;, err) 输出结果如下：\n1 2 accuracy= 0.4 error= 0.6 1.2 精确率、召回率、P-R 曲线和 F1 精确率，也被称作查准率，是指所有预测为正类的结果中，真正的正类的比例。公式如下：\n召回率，也被称作查全率，是指所有正类中，被分类器找出来的比例。公式如下：\n对于上述两个公式的符号定义，是在二分类问题中，我们将关注的类别作为正类，其他类别作为负类别，因此，定义：\nTP(True Positive)：真正正类的数量，即分类为正类，实际也是正类的样本数量； FP(False Positive)：假正类的数量，即分类为正类，但实际是负类的样本数量； FN(False Negative)：假负类的数量，即分类为负类，但实际是正类的样本数量； TN(True Negative)：真负类的数量，即分类是负类，实际也负类的样本数量。 更形象的说明，可以参考下表，也是混淆矩阵的定义：\n预测：正类 预测：负类 实际：正类 TP FN 实际：负类 FP TN 精确率和召回率是一对矛盾的度量，通常精确率高时，召回率往往会比较低；而召回率高时，精确率则会比较低，原因如下：\n精确率越高，代表预测为正类的比例更高，而要做到这点，通常就是只选择有把握的样本。最简单的就是只挑选最有把握的一个样本，此时 FP=0，P=1，但 FN 必然非常大(没把握的都判定为负类)，召回率就非常低了； 召回率要高，就是需要找到所有正类出来，要做到这点，最简单的就是所有类别都判定为正类，那么 FN=0 ，但 FP 也很大，所有精确率就很低了。 而且不同的问题，侧重的评价指标也不同，比如：\n对于推荐系统，侧重的是精确率。也就是希望推荐的结果都是用户感兴趣的结果，即用户感兴趣的信息比例要高，因为通常给用户展示的窗口有限，一般只能展示 5 个，或者 10 个，所以更要求推荐给用户真正感兴趣的信息； 对于医学诊断系统，侧重的是召回率。即希望不漏检任何疾病患者，如果漏检了，就可能耽搁患者治疗，导致病情恶化。 精确率和召回率的代码简单实现如下，这是基于二分类的情况\n1 2 3 4 5 6 7 8 def precision(y_true, y_pred): true_positive = sum(y and y_p for y, y_p in zip(y_true, y_pred)) predicted_positive = sum(y_pred) return true_positive / predicted_positive def recall(y_true, y_pred): true_positive = sum(y and y_p for y, y_p in zip(y_true, y_pred)) real_positive = sum(y_true) return true_positive / real_positive 结果\n1 2 3 4 5 6 7 8 y_true = [1, 0, 1, 0, 1] y_pred = [0, 0, 1, 1, 0] precisions = precision(y_true, y_pred) recalls = recall(y_true, y_pred) print(\u0026#39;precisions=\u0026#39;, precisions) # 输出为0.5 print(\u0026#39;recalls=\u0026#39;, recalls) # 输出为 0.3333 1.2.2 P-R 曲线和 F1 预测结果其实就是分类器对样本判断为某个类别的置信度，我们可以选择不同的阈值来调整分类器对某个样本的输出结果，比如设置阈值是 0.9，那么只有置信度是大于等于 0.9 的样本才会最终判定为正类，其余的都是负类。\n我们设置不同的阈值，自然就会得到不同的正类数量和负类数量，依次计算不同情况的精确率和召回率，然后我们可以以精确率为纵轴，召回率为横轴，绘制一条“P-R曲线”，如下图所示：\n当然，以上这个曲线是比较理想情况下的，未来绘图方便和美观，实际情况如下图所示：\n对于 P-R 曲线，有：\n1.曲线从左上角 (0,1) 到右下角 (1,0) 的走势，正好反映了精确率和召回率是一对矛盾的度量，一个高另一个低的特点：\n开始是精确率高，因为设置阈值很高，只有第一个样本（分类器最有把握是正类）被预测为正类，其他都是负类，所以精确率高，几乎是 1，而召回率几乎是 0，仅仅找到 1 个正类。 右下角时候就是召回率很高，精确率很低，此时设置阈值就是 0，所以类别都被预测为正类，所有正类都被找到了，召回率很高，而精确率非常低，因为大量负类被预测为正类。 2.P-R 曲线可以非常直观显示出分类器在样本总体上的精确率和召回率。所以可以对比两个分类器在同个测试集上的 P-R 曲线来比较它们的分类能力：\n如果分类器 B 的 P-R 曲线被分类器 A 的曲线完全包住，如下左图所示，则可以说，A 的性能优于 B; 如果是下面的右图，两者的曲线有交叉，则很难直接判断两个分类器的优劣，只能根据具体的精确率和召回率进行比较： 一个合理的依据是比较 P-R 曲线下方的面积大小，它在一定程度上表征了分类器在精确率和召回率上取得“双高”的比例，但这个数值不容易计算； 另一个比较就是平衡点(Break-Event Point, BEP)，它是精确率等于召回率时的取值，如下右图所示，而且可以判定，平衡点较远的曲线更好。 当然了，平衡点还是过于简化，于是有了 F1 值这个新的评价标准，它是精确率和召回率的调和平均值，定义为：\nF1 还有一个更一般的形式： ，能让我们表达出对精确率和召回率的不同偏好，定义如下：\n其中 度量了召回率对精确率的相对重要性，当 ，就是 F1；如果 ，召回率更加重要；如果 ，则是精确率更加重要。\n1.2.3 宏精确率/微精确率、宏召回率/微召回率以及宏 F1 / 微 F1 很多时候，我们会得到不止一个二分类的混淆矩阵，比如多次训练/测试得到多个混淆矩阵，在多个数据集上进行训练/测试来估计算法的“全局”性能，或者是执行多分类任务时对类别两两组合得到多个混淆矩阵。\n总之，我们希望在 n 个二分类混淆矩阵上综合考察精确率和召回率。这里一般有两种方法来进行考察：\n1.第一种是直接在各个混淆矩阵上分别计算出精确率和召回率，记为 ，接着计算平均值，就得到宏精确率(macro-P)、宏召回率(macro-R)以及宏 F1(macro-F1) , 定义如下：\n2.第二种则是对每个混淆矩阵的对应元素进行平均，得到 TP、FP、TN、FN 的平均值，再基于这些平均值就就得到微精确率(micro-P)、微召回率(micro-R)以及微 F1(micro-F1) , 定义如下：\n1.3 ROC 与 AUC 1.3.1 ROC 曲线 ROC 曲线的 Receiver Operating Characteristic 曲线的简称，中文名是“受试者工作特征”，起源于军事领域，后广泛应用于医学领域。\n它的横坐标是假正例率(False Positive Rate, FPR)，纵坐标是真正例率(True Positive Rate, TPR)，两者的定义分别如下：\nTPR 表示正类中被分类器预测为正类的概率，刚好就等于正类的召回率；\nFPR 表示负类中被分类器预测为正类的概率，它等于 1 减去负类的召回率，负类的召回率如下，称为真反例率(True Negative Rate, TNR), 也被称为特异性，表示负类被正确分类的比例。\n第二种更直观地绘制 ROC 曲线的方法，首先统计出正负样本的数量，假设分别是 P 和 N，接着，将横轴的刻度间隔设置为 1/N，纵轴的刻度间隔设置为 1/P。然后根据模型输出的概率对样本排序，并按顺序遍历样本，从零点开始绘制 ROC 曲线，每次遇到一个正样本就沿纵轴方向绘制一个刻度间隔的曲线，遇到一个负样本就沿横轴绘制一个刻度间隔的曲线，直到遍历完所有样本，曲线最终停留在 (1,1) 这个点，此时就完成了 ROC 曲线的绘制了。\n当然，更一般的 ROC 曲线是如下图所示的，会更加的平滑，上图是由于样本数量有限才导致的。\n对于 ROC 曲线，有以下几点特性：\n1.ROC 曲线通常都是从左下角 (0,0) 开始，到右上角 (1,1) 结束。\n开始时候，\n第一个样本被预测为正类\n，其他都是预测为负类别；\nTPR 会很低，几乎是 0，上述例子就是 0.1，此时大量正类没有被分类器找出来； FPR 也很低，可能就是0，上述例子就是 0，这时候被预测为正类的样本可能实际也是正类，所以几乎没有预测错误的正类样本。 结束时候，\n所有样本都预测为正类.\nTPR 几乎就是 1，因为所有样本都预测为正类，那肯定就找出所有的正类样本了； FPR 也是几乎为 1，因为所有负样本都被错误判断为正类。 2.ROC 曲线中：\n对角线对应于随机猜想模型，即概率为 0.5； 点 (0,1) 是理想模型，因为此时 TPR=1，FPR=0，也就是正类都预测出来，并且没有预测错误； 通常，ROC 曲线越接近点 (0, 1) 越好。 3.同样可以根据 ROC 曲线来判断两个分类器的性能：\n如果分类器 A 的 ROC 曲线被分类器 B 的曲线完全包住，可以说 B 的性能好过 A，这对应于上一条说的 ROC 曲线越接近点 (0, 1) 越好； 如果两个分类器的 ROC 曲线发生了交叉，则同样很难直接判断两者的性能优劣，需要借助 ROC 曲线下面积大小来做判断，而这个面积被称为 AUC:Area Under ROC Curve。 1.3.2 ROC 和 P-R 曲线的对比 相同点\n1.两者刻画的都是阈值的选择对分类度量指标的影响。虽然每个分类器对每个样本都会输出一个概率，也就是置信度，但通常我们都会人为设置一个阈值来影响分类器最终判断的结果，比如设置一个很高的阈值\u0026ndash;0.95，或者比较低的阈值\u0026ndash;0.3。\n如果是偏向于精确率，则提高阈值，保证只把有把握的样本判断为正类，此时可以设置阈值为 0.9，或者更高； 如果偏向于召回率，那么降低阈值，保证将更多的样本判断为正类，更容易找出所有真正的正样本，此时设置阈值是 0.5，或者更低。 2.两个曲线的每个点都是对应某个阈值的选择，该点是在该阈值下的 (精确率，召回率) / (TPR, FPR)。然后沿着横轴方向对应阈值的下降。\n不同\n相比较 P-R 曲线，ROC 曲线有一个特点，就是正负样本的分布发生变化时，它的曲线形状能够基本保持不变。如下图所示:\n分别比较了增加十倍的负样本后， P-R 和 ROC 曲线的变化，可以看到 ROC 曲线的形状基本不变，但 P-R 曲线发生了明显的变化。\n所以 ROC 曲线的这个特点可以降低不同测试集带来的干扰，更加客观地评估模型本身的性能，因此它适用的场景更多，比如排序、推荐、广告等领域。\n这也是由于现实场景中很多问题都会存在正负样本数量不平衡的情况，比如计算广告领域经常涉及转化率模型，正样本的数量往往是负样本数量的千分之一甚至万分之一，这时候选择 ROC 曲线更加考验反映模型本身的好坏。\n当然，如果希望看到模型在特定数据集上的表现，P-R 曲线会更直观地反映其性能。所以还是需要具体问题具体分析。\n1.3.3 AUC 曲线 AUC 是 ROC 曲线的面积，其物理意义是：从所有正样本中随机挑选一个样本，模型将其预测为正样本的概率是 ；从所有负样本中随机挑选一个样本，模型将其预测为正样本的概率是 。 的概率就是 AUC。\nAUC 曲线有以下几个特点：\n如果完全随机地对样本进行分类，那么 的概率是 0.5，则 AUC=0.5；\nAUC 在样本不平衡的条件下依然适用。\n如：在反欺诈场景下，假设正常用户为正类（设占比 99.9%），欺诈用户为负类（设占比 0.1%）。\n如果使用准确率评估，则将所有用户预测为正类即可获得 99.9%的准确率。很明显这并不是一个很好的预测结果，因为欺诈用户全部未能找出。\n如果使用 AUC 评估，则此时 FPR=1,TPR=1，对应的 AUC=0.5 。因此 AUC 成功的指出了这并不是一个很好的预测结果。\nAUC 反应的是模型对于样本的排序能力（根据样本预测为正类的概率来排序）。如：AUC=0.8 表示：给定一个正样本和一个负样本，在 80% 的情况下，模型对正样本预测为正类的概率大于对负样本预测为正类的概率。\nAUC 对于均匀采样不敏感。如：上述反欺诈场景中，假设对正常用户进行均匀的降采样。任意给定一个负样本 n，设模型对其预测为正类的概率为 Pn 。降采样前后，由于是均匀采样，因此预测为正类的概率大于 Pn 和小于 Pn 的真正样本的比例没有发生变化。因此 AUC 保持不变。\n但是如果是非均匀的降采样，则预测为正类的概率大于 Pn 和小于 Pn 的真正样本的比例会发生变化，这也会导致 AUC 发生变化。\n正负样本之间的预测为正类概率之间的差距越大，则 AUC 越高。因为这表明正负样本之间排序的把握越大，区分度越高。\n如：在电商场景中，点击率模型的 AUC 要低于购买转化模型的 AUC 。因为点击行为的成本低于购买行为的成本，所以点击率模型中正负样本的差别要小于购买转化模型中正负样本的差别。\nAUC 的计算可以通过对 ROC 曲线下各部分的面积求和而得。假设 ROC 曲线是由坐标为下列这些点按顺序连接而成的：\n那么 AUC 可以这样估算：\n1.4 代价矩阵 前面介绍的性能指标都有一个隐式的前提，错误都是均等代价。但实际应用过程中，不同类型的错误所造成的后果是不同的。比如将健康人判断为患者，与患者被判断为健康人，代价肯定是不一样的，前者可能就是需要再次进行检查，而后者可能错过治疗的最佳时机。\n因此，为了衡量不同类型所造成的不同损失，可以为错误赋予非均等代价(unequal cost)。\n对于一个二类分类问题，可以设定一个代价矩阵(cost matrix)，其中 表示将第 i 类样本预测为第 j 类样本的代价，而预测正确的代价是 0 。如下表所示：\n预测：第 0 类 预测：第 1 类 真实：第 0 类 0 真实： 第 1 类 0 在非均等代价下，希望找到的不再是简单地最小化错误率的模型，而是希望找到最小化总体代价 total cost 的模型。\n在非均等代价下，ROC 曲线不能直接反映出分类器的期望总体代价，此时需要使用代价曲线 cost curve\n代价曲线的横轴是正例概率代价，如下所示，其中 p 是正例(第 0 类)的概率 代价曲线的纵轴是归一化代价，如下所示：\n其中，假正例率 FPR 表示模型将负样本预测为正类的概率，定义如下：\n假负例率 FNR 表示将正样本预测为负类的概率，定义如下：\n代价曲线如下图所示：\n1.5 回归问题的性能度量 对于回归问题，常用的性能度量标准有：\n1.均方误差(Mean Square Error, MSE)，定义如下：\n2.均方根误差(Root Mean Squared Error, RMSE)，定义如下：\n3.均方根对数误差(Root Mean Squared Logarithmic Error, RMSLE)，定义如下\n4.平均绝对误差(Mean Absolute Error, MAE)，定义如下：\n这四个标准中，比较常用的第一个和第二个，即 MSE 和 RMSE，这两个标准一般都可以很好反映回归模型预测值和真实值的偏离程度，但如果遇到个别偏离程度非常大的离群点时，即便数量很少，也会让这两个指标变得很差。\n遇到这种情况，有三种解决思路：\n将离群点作为噪声点来处理，即数据预处理部分需要过滤掉这些噪声点； 从模型性能入手，提高模型的预测能力，将这些离群点产生的机制建模到模型中，但这个方法会比较困难； 采用其他指标，比如第三个指标 RMSLE，它关注的是预测误差的比例，即便存在离群点，也可以降低这些离群点的影响；或者是 MAPE，平均绝对百分比误差(Mean Absolute Percent Error)，定义为： RMSE 的简单代码实现如下所示：\n1 2 3 4 5 6 7 8 def rmse(predictions, targets): # 真实值和预测值的误差 differences = predictions - targets differences_squared = differences ** 2 mean_of_differences_squared = differences_squared.mean() # 取平方根 rmse_val = np.sqrt(mean_of_differences_squared) return rmse_val 1.6 其他评价指标 计算速度：模型训练和预测需要的时间； 鲁棒性：处理缺失值和异常值的能力； 可拓展性：处理大数据集的能力； 可解释性：模型预测标准的可理解性，比如决策树产生的规则就很容易理解，而神经网络被称为黑盒子的原因就是它的大量参数并不好理解。 ","permalink":"https://reid00.github.io/post/%E5%A6%82%E4%BD%95%E8%AF%84%E4%BB%B7%E6%A8%A1%E5%9E%8B%E5%A5%BD%E5%9D%8F/","summary":"Summary “所有模型都是坏的，但有些模型是有用的”。我们建立模型之后，接下来就要去评估模型，确定这个模型是否‘有用’。当你费尽全力去建立完模型后，你","title":"如何评价模型好坏"},{"content":"Summary 简单的说，k-近邻算法采用测量不同特征值之间的距离方法进行分类。 它的思路是：如果一个样本在特征空间中的k个最相似(即特征空间中最邻近)的样本中的大多数属于某一个类别，则该样本也属于这个类别，其中K通常是不大于20的整数。KNN算法中，所选择的邻居都是已经正确分类的对象。该方法在定类决策上只依据最邻近的一个或者几个样本的类别来决定待分样本所属的类别。\n优点：精度高、对异常值不敏感、无数据输入假定。\n缺点：计算复杂度高、空间复杂度高。\n适用数据范围：数值型和标称型。\n详细介绍 下面通过一个简单的例子说明一下：如下图，绿色圆要被决定赋予哪个类，是红色三角形还是蓝色四方形？如果K=3，由于红色三角形所占比例为2/3，绿色圆将被赋予红色三角形那个类，如果K=5，由于蓝色四方形比例为3/5，因此绿色圆被赋予蓝色四方形类。\n由此也说明了KNN算法的结果很大程度取决于K的选择。\n在KNN中，通过计算对象间距离来作为各个对象之间的非相似性指标，避免了对象之间的匹配问题，在这里距离一般使用欧氏距离或曼哈顿距离：\n**接下来对KNN算法的思想总结一下：**就是在训练集中数据和标签已知的情况下，输入测试数据，将测试数据的特征与训练集中对应的特征进行相互比较，找到训练集中与之最为相似的前K个数据，则该测试数据对应的类别就是K个数据中出现次数最多的那个分类，其算法的描述为：\n1）计算测试数据与各个训练数据之间的距离；\n2）按照距离的递增关系进行排序；\n3）选取距离最小的K个点；\n4）确定前K个点所在类别的出现频率；\n5）返回前K个点中出现频率最高的类别作为测试数据的预测分类。\n常见问题 1. K值设定为多大？ K太小，分类结果易受噪声点影响；k太大，近邻中又可能包含太多的其它类别的点。（对距离加权，可以降低k值设定的影响） k值通常是采用交叉检验来确定（以k=1为基准） 经验规则：k一般低于训练样本数的平方根\n2. 类别如何判定最合适？ 投票法没有考虑近邻的距离的远近，距离更近的近邻也许更应该决定最终的分类，所以加权投票法更恰当一些。\n3. 如何选择合适的距离衡量？ 高维度对距离衡量的影响：众所周知当变量数越多，欧式距离的区分能力就越差。 变量值域对距离的影响：值域越大的变量常常会在距离计算中占据主导作用，因此应先对变量进行标准化。\n4. 训练样本是否要一视同仁？ 在训练集中，有些样本可能是更值得依赖的。 可以给不同的样本施加不同的权重，加强依赖样本的权重，降低不可信赖样本的影响。\n5. 性能问题？ KNN是一种懒惰算法，平时不好好学习，考试（对测试样本分类）时才临阵磨枪（临时去找k个近邻）。 懒惰的后果：构造模型很简单，但在对测试样本分类地的系统开销大，因为要扫描全部训练样本并计算距离。 已经有一些方法提高计算的效率，例如压缩训练样本量等。\n6. 能否大幅减少训练样本量，同时又保持分类精度？ 浓缩技术(condensing) 编辑技术(editing)\n算法实例 如scikit-learn中的KNN算法使用:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 #coding:utf-8 from sklearn import datasets #sk-learn 内置数据库 import numpy as np \u0026#39;\u0026#39;\u0026#39;KNN算法\u0026#39;\u0026#39;\u0026#39; iris = datasets.load_iris() #内置的鸢尾花卉数据集 #数据集包含150个数据集，分为3类，每类50个数据, #可通过花萼长度，花萼宽度，花瓣长度，花瓣宽度4个特征预测鸢尾花卉属于 #(Setosa，Versicolour，Virginica)三个种类中的哪一类 iris_X,iris_y = iris.data,iris.target #数据集及其对应的分类标签 # 将数据集随机分为训练数据集和测试数据集 np.random.seed(0) indices = np.random.permutation(len(iris_X)) #用于训练模型 iris_X_train = iris_X[indices[:-10]] iris_y_train = iris_y[indices[:-10]] #用于测试模型 iris_X_test = iris_X[indices[-10:]] iris_y_test = iris_y[indices[-10:]] from sklearn.neighbors import KNeighborsClassifier knn = KNeighborsClassifier() knn.fit(iris_X_train,iris_y_train) prediction = knn.predict(iris_X_test) score = knn.score(iris_X_test,iris_y_test) print \u0026#39;真实分类标签:\u0026#39;+str(iris_y_test) print \u0026#39;模型分类结果:\u0026#39;+str(prediction)+\u0026#39;\\n算法准确度:\u0026#39;+str(score) 输出结果:\n1 2 3 真实分类标签:[1 1 1 0 0 0 2 1 2 0] 模型分类结果:[1 2 1 0 0 0 2 1 2 0] 算法准确度:0.9 ","permalink":"https://reid00.github.io/post/knn%E7%AE%97%E6%B3%95/","summary":"Summary 简单的说，k-近邻算法采用测量不同特征值之间的距离方法进行分类。 它的思路是：如果一个样本在特征空间中的k个最相似(即特征空间中最邻近)的样","title":"KNN算法"},{"content":"贝叶斯准备知识 贝叶斯决策论是概率框架下实施决策的基本方法。要了解贝叶斯决策论，首先得先了解以下几个概念：先验概率、条件概率、后验概率、误判损失、条件风险、贝叶斯判别准则\n先验概率： 所谓先验概率，就是根据以往的经验或者现有数据的分析所得到的概率。如，随机扔一枚硬币，则p(正面) = p(反面) = 1/2，这是我们根据已知的知识所知道的信息，即p(正面) = 1/2为先验概率。\n条件概率： 所谓条件概率是指事件A在另一事件B发生的条件下发送的概率。用数学符号表示为：P(B\\|A)，即B在A发生的条件下发生的概率。举个栗子，你早上误喝了一瓶过期了的牛奶（A），那我们来算一下你今天拉肚子的概率（B），这个就叫做条件概率。即P（拉肚子\\|喝了过期牛奶）， 易见，条件概率是有因求果（知道原因推测结果）。\n后验概率： 后验概率跟条件概率的表达形式有点相似。数学表达式为p(A\\|B), 即A在B发生的条件下发生的概率。以误喝牛奶的例子为例，现在知道了你今天拉肚子了（B），算一下你早上误喝了一瓶过期了的牛奶(A)的概率, 即P（A|B），这就是后验概率，后验概率是有果求因（知道结果推出原因）\n误判损失： 数学表达式：L(j|i)， 判别损失表示把一个标记为i类的样本误分类为j类所造成的损失。 比如，当你去参加体检时，明明你各项指标都是正常的，但是医生却把你分为癌症病人，这就造成了误判损失，用数学表示为：L(癌症|正常)。\n条件风险： 是指基于后验概率P(i|x)可获得将样本x分类为i所产生的期望损失，公式为：R(i|x) = ∑L(i|j)P(j|x)。(其实就是所有判别损失的加权和，而这个权就是样本判为j类的概率，样本本来应该含有P(j|x)的概率判为j类，但是却判为了i类，这就造成了错判损失，而将所有的错判损失与正确判断的概率的乘积相加，就能得到样本错判为i类的平均损失，即条件风险。)\n举个栗子，假设把癌症病人判为正常人的误判损失是100，把正常人判为癌症病人的误判损失是10，把感冒病人判为癌症的误判损失是8，即L（正常|癌症） = 100， L（癌症|正常） = 10，L(癌症|感冒) = 8， 现在，我们经过计算知道有一个来体检的员工的后验概率分别为：p(正常|各项指标) = 0.2， p(感冒|各项指标) = 0.4, p（ 癌症|各项指标)=0.4。假如我们需要计算将这个员工判为癌症的条件风险，则：R（癌症|各项指标） = L（癌症|正常） p(正常|各项指标) + L(癌症|感冒) * p(感冒|各项指标) = 5.2。*\n贝叶斯判别准则：\n贝叶斯判别准则是找到一个使条件风险达到最小的判别方法。即，将样本判为哪一类，所得到的条件风险R(i|x)（或者说平均判别损失）最小，那就将样本归为那个造成平均判别损失最小的类。\n此时：h*(x) = argminR(i|x) 就称为 贝叶斯最优分类器。\n总结：贝叶斯决策论是基于先验概率求解后验概率的方法，其核心是寻找一个判别准则使得条件风险达到最小。而在最小化分类错误率的目标下，贝叶斯最优分类器又可以转化为求后验概率达到最大的类别标记，即 h*（x) = argmaxP(i|x)。（此时，L(i|j) = 0, if i = j;L(i|j) = 1, otherwise)\n简单说说朴素贝叶斯 朴素贝叶斯采用 属性条件独立性 的假设，对于给定的待分类观测数据X,计算在X出现的条件下，各个目标类出现的概率（即后验概率），将该后验概率最大的类作为X所属的类。而计算后验概率的贝叶斯公式为：p(A|B) =[ p(A) * p(B|A)]/p(B),因为p(B)表示观测数据X出现的概率，它在所有关于X的分类计算公式中都是相同的，所以我们可以把p(B)忽略，则 p(A|B)= p(A) * p(B|A)。\n举个栗子，公司里面男性有60人，女性有40人，男性穿皮鞋的人数有25人，穿运动鞋的人数有35人，女性穿皮鞋的人数有10人，穿高跟鞋的人数有30人。现在你只知道有一个人穿了皮鞋，这时候你就需要推测他的性别是什么。如果推测出他是男性的概率大于女性，那么就认为他是男性，否则认为他是女性。（如果此时条件允许，你可以现场给面试官演示一下怎么计算， 计算过程如下：\n1 p(性别 = 男性) = 0.6p(性别 = 女性) = 0.4p(穿皮鞋\\|男性) = 0.417p(穿皮鞋\\|女性) = 0.25p(穿皮鞋\\|男性) * p(性别 = 男性) = 0.2502p(穿皮鞋\\|女性) * p(性别 = 女性) = 0.1 朴素贝叶斯中的朴素怎么理解 素贝叶斯中的朴素可以理解为是“简单、天真”的意思，因为“朴素”是假设了特征之间是同等重要、相互独立、互不影响的，但是在我们的现实社会中，属性之间并不是都是互相独立的，有些属性也会存在性，所以说朴素贝叶斯是一种很“朴素”的算法。\n素贝叶斯的工作流程 可以分为三个阶段进行，分别是准备阶段、分类器训练阶段和应用阶段。\n**准备阶段：**这个阶段的任务是为朴素贝叶斯分类做必要的准备，主要工作是根据具体情况确定特征属性，并对每个特征属性进行适当划分，去除高度相关性的属性(如果两个属性具有高度相关性的话，那么该属性将会在模型中发挥了2次作用，会使得朴素贝叶斯所预测的结果向该属性所希望的方向偏离，导致分类出现偏差)，然后由人工对一部分待分类项进行分类，形成训练样本集合。这一阶段的输入是所有待分类数据，输出是特征属性和训练样本。(这一阶段是整个朴素贝叶斯分类中唯一需要人工完成的阶段，其质量对整个过程将有重要影响。）\n分类器训练阶段：这个阶段的任务就是生成分类器，主要工作是计算每个类别在训练样本中的出现频率及每个特征属性划分对每个类别的条件概率估计，并将结果记录。其输入是特征属性和训练样本，输出是分类器。这一阶段是机械性阶段，根据前面讨论的公式可以由程序自动计算完成。\n**应用阶段：**这个阶段的任务是使用分类器对待分类项进行分类，其输入是分类器和待分类项，输出是待分类项与类别的映射关系。这一阶段也是机械性阶段，由程序完成。\n朴素贝叶斯有什么优缺点 优点 朴素贝叶斯模型发源于古典数学理论，有稳定的分类效率。\n对缺失数据不太敏感，算法也比较简单，常用于文本分类。\n分类准确度高，速度快。\n对小规模的数据表现很好，能处理多分类任务，适合增量式训练，当数据量超出内存时，我们可以一批批的去增量训练(朴素贝叶斯在训练过程中只需要计算各个类的概率和各个属性的类条件概率，这些概率值可以快速地根据增量数据进行更新，无需重新全量计算)。\n缺点 对训练数据的依赖性很强，如果训练数据误差较大，那么预测出来的效果就会不佳。对输入数据的表达形式很敏感（离散、连续，值极大极小之类的）\n理论上，朴素贝叶斯模型与其他分类方法相比具有最小的误差率。\n但是在实际中，因为朴素贝叶斯“朴素，”的特点，导致在属性个数比较多或者属性之间相关性较大时，分类效果不好。\n而在属性相关性较小时，朴素贝叶斯性能最为良好。\n对于这一点，有半朴素贝叶斯之类的算法通过考虑部分关联性适度改进。\n需要知道先验概率，且先验概率很多时候是基于假设或者已有的训练数据所得的，这在某些时候可能会因为假设先验概率的原因出现分类决策上的错误。\n“朴素”是朴素贝叶斯在进行预测时候的缺点，那么有这么一个明显的假设缺点在，为什么朴素贝叶斯的预测仍然可以取得较好的效果？ 对于分类任务来说，只要各个条件概率之间的排序正确，那么就可以通过比较概率大小来进行分类，不需要知道精确的概率值(朴素贝叶斯分类的核心思想是找出后验概率最大的那个类，而不是求出其精确的概率) 如果属性之间的相互依赖对所有类别的影响相同，或者相互依赖关系可以互相抵消，那么属性条件独立性的假设在降低计算开销的同时不会对分类结果产生不良影响。 什么是拉普拉斯平滑法? 在估计条件概率P(X|Y)时出现概率为0的情况怎么办？\n简单来说：引入λ，当λ=1时称为拉普拉斯平滑。\n拉普拉斯平滑法是朴素贝叶斯中处理零概率问题的一种修正方式。在进行分类的时候，可能会出现某个属性在训练集中没有与某个类同时出现过的情况，如果直接基于朴素贝叶斯分类器的表达式进行计算的话就会出现零概率现象。为了避免其他属性所携带的信息被训练集中未出现过的属性值“抹去”，所以才使用拉普拉斯估计器进行修正。具体的方法是：在分子上加1,对于先验概率，在分母上加上训练集中可能的类别数；对于条件概率，则在分母上加上第i个属性可能的取值数\n朴素贝叶斯中有没有超参数可以调？ 朴素贝叶斯是没有超参数可以调的，所以它不需要调参，朴素贝叶斯是根据训练集进行分类，分类出来的结果基本上就是确定了的，拉普拉斯估计器不是朴素贝叶斯中的参数，不能通过拉普拉斯估计器来对朴素贝叶斯调参。\n朴素贝叶斯中有多少种模型？ 朴素贝叶斯含有3种模型，分别是高斯模型，对连续型数据进行处理；多项式模型，对离散型数据进行处理，计算数据的条件概率(使用拉普拉斯估计器进行平滑的一个模型)；伯努利模型，伯努利模型的取值特征是布尔型，即出现为ture,不出现为false,在进行文档分类时，就是一个单词有没有在一个文档中出现过。\n你知道朴素贝叶斯有哪些应用吗？ 知道(肯定得知道啊，不然不就白学了吗？) 朴素贝叶斯的应用最广的应该就是在文档分类、垃圾文本过滤(如垃圾邮件、垃圾信息等)、情感分析(微博、论坛上的积极、消极等情绪判别)这些方面，除此之外还有多分类实时预测、推荐系统(贝叶斯与协同过滤组合使用)、拼写矫正(当你输入一个错误单词时，可以通过文档库中出现的概率对你的输入进行矫正)等。\n你觉得朴素贝叶斯对异常值敏不敏感？ 朴素贝叶斯对异常值不敏感。所以在进行数据处理时，我们可以不去除异常值，因为保留异常值可以保持朴素贝叶斯算法的整体精度，而去除异常值则可能在进行预测的过程中由于失去部分异常值导致模型的泛化能力下降。\n朴素贝叶斯是高方差还是低方差模型？ 朴素贝叶斯是低方差模型。(误差 = 偏差 + 方差)对于复杂模型来说，由于复杂模型充分拟合了部分数据，使得它们的偏差变小，但由于对部分数据过分拟合，这就导致预测的方差会变大。因为朴素贝叶斯假设了各个属性之间是相互的，算是一个简单的模型。对于简单的模型来说，则恰恰相反，简单模型的偏差会更大，相对的，方差就会较小。(偏差是模型输出值与真实值的误差，也就是模型的精准度，方差是预测值与模型输出期望的的误差，即模型的稳定性，也就是数据的集中性的一个指标)\nNavie Bayes和Logistic回归区别是什么？ 前者是生成式模型，后者是判别式模型，二者的区别就是生成式模型与判别式模型的区别。\n1）首先，Navie Bayes通过已知样本求得先验概率P(Y), 及条件概率P(X|Y), 对于给定的实例，计算联合概率，进而求出后验概率。也就是说，它尝试去找到底这个数据是怎么生成的（产生的），然后再进行分类。哪个类别最有可能产生这个信号，就属于那个类别。\n优点：样本容量增加时，收敛更快；隐变量存在时也可适用。\n缺点：时间长；需要样本多；浪费计算资源\n2）相比之下，Logistic回归不关心样本中类别的比例及类别下出现特征的概率，它直接给出预测模型的式子。设每个特征都有一个权重，训练样本数据更新权重w，得出最终表达式。梯度法。\n优点：直接预测往往准确率更高；简化问题；可以反应数据的分布情况，类别的差异特征；适用于较多类别的识别。\n缺点：收敛慢；不适用于有隐变量的情况。\n参考:https://mp.weixin.qq.com/s/xzJDNRv8ipJY9hTo8WXoCw\n","permalink":"https://reid00.github.io/post/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/","summary":"贝叶斯准备知识 贝叶斯决策论是概率框架下实施决策的基本方法。要了解贝叶斯决策论，首先得先了解以下几个概念：先验概率、条件概率、后验概率、误判损","title":"朴素贝叶斯"},{"content":"什么是生成模型和判别模型？ 从本质上讲，生成模型和判别模型是解决分类问题的两类基本思路。首先，您得先了解，分类问题，就是给定一个数据x，要判断它对应的标签y（这么naive的东西都要解释下，求面试官此时内心的阴影面积，嘎嘎）。生成模型就是要学习x和y的联合概率分布P(x,y)，然后根据贝叶斯公式来求得条件概率P(y|x)，预测条件概率最大的y。贝叶斯公式这么简单的知识相信您也了解，我就不啰嗦了。判别模型就是直接学习条件概率分布P(y|x)。\n举个栗子 例子1 假设你从来没有见过大象和猫，连听都没有听过，这时，给你看了一张大象的照片和一张猫的照片。如下所示：\n然后牵来我家的大象（面试官：你家开动物园的吗？），让你判断这是大象还是猫。你咋办？\n你开始回想刚刚看过的照片，大概记起来，大象和猫比起来，有个长鼻子，而眼前这个家伙也有个长鼻子，所以，你兴奋地说：“这是大象！”恭喜你答对了！\n你也有可能这样做，你努力回想刚才的两张照片，然后用笔把它们画在了纸上，拿着纸和我家的大象做比较，你发现，眼前的动物更像是大象。于是，你惊喜地宣布：“这玩意是大象！”恭喜你又答对了！\n在这个问题中，第一个解决问题的思路就是判别模型，因为你只记住了大象和猫之间的不同之处。第二个解决问题的思路就是生成模型，因为你实际上学习了什么是大象，什么是猫。\n例子2 来来来，看一下这四个形式为(x,y)的样本。(1,0), (1,0), (2,0), (2, 1）。假设，我们想从这四个样本中，学习到如何通过x判断y的模型。用生成模型，我们要学习P(x,y)。如下所示：\n我们学习到了四个概率值，它们的和是1，这就是P(x,y)。\n我们也可以用判别模型，我们要学习P(y|x)，如下所示：\n我们同样学习到了四个概率值，但是，这次，是每一行的两个概率值的和为1了。让我们具体来看一下，如何使用这两个模型做判断。\n假设 x=1。\n对于生成模型， 我们会比较：\nP(x=1,y=0) = 1/2 P(x=1,y=1) = 0 我们发现P(x=1,y=0)的概率要比P(x=1,y=1)的概率大，所以，我们判断：x=1时，y=0。\n对于判别模型，我们会比较：\nP(y=0|x=1) = 1 P(y=1|x=1) = 0 同样，P(y=0|x=1)要比P(y=1|x=1)大，所以，我们判断：x=1时，y=0。\n我们看到，虽然最后预测的结果一样，但是得出结果的逻辑却是完全不同的。两个栗子说完，你心里感到很痛快，面试官脸上也露出了赞赏的微笑，但是，他突然问了一个问题。\n生成模型为啥叫生成模型 这个问题着实让你没想到，不过，聪明的你略加思考，应该就可以想到。生成模型之所以叫生成模型，是因为，它背后的思想是，x是特征，y是标签，什么样的标签就会生成什么样的特征。好比说，标签是大象，那么可能生成的特征就有大耳朵，长鼻子等等。\n当我们来根据x来判断y时，我们实际上是在比较，什么样的y标签更可能生成特征x，我们预测的结果就是更可能生成x特征的y标签。\n常见的生成模型和判别模型有哪些呢 生成模型\nHMM\n朴素贝叶斯\n判别模型\n逻辑回归\nSVM\nCRF\n最近邻\n一般的神经网络\n","permalink":"https://reid00.github.io/post/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8Bvs%E5%88%A4%E5%88%AB%E6%A8%A1%E5%9E%8B/","summary":"什么是生成模型和判别模型？ 从本质上讲，生成模型和判别模型是解决分类问题的两类基本思路。首先，您得先了解，分类问题，就是给定一个数据x，要判断","title":"生成模型vs判别模型"},{"content":"Summary 数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已。由此可见，特征工程在机器学习中占有相当重要的地位。在实际应用当中，可以说特征工程是机器学习成功的关键。\n那特征工程是什么？\n​\t特征工程是利用数据领域的相关知识来创建能够使机器学习算法达到最佳性能的特征的过程。\n特征工程又包含了Feature Selection（特征选择）、Feature Extraction（特征提取）和Feature construction（特征构造）等子问题，本章内容主要讨论特征选择相关的方法及实现。\n在实际项目中，我们可能会有大量的特征可使用，有的特征携带的信息丰富，有的特征携带的信息有重叠，有的特征则属于无关特征，如果所有特征不经筛选地全部作为训练特征，经常会出现维度灾难问题，甚至会降低模型的准确性。因此，我们需要进行特征筛选，排除无效/冗余的特征，把有用的特征挑选出来作为模型的训练数据。\n特征选择介绍 特征按重要性分类 相关特征\n对于学习任务（例如分类问题）有帮助，可以提升学习算法的效果\n无关特征\n对于我们的算法没有任何帮助，不会给算法的效果带来任何提升\n冗余特征\n不会对我们的算法带来新的信息，或者这种特征的信息可以由其他的特征推断出\n特征选择的目的 对于一个特定的学习算法来说，哪一个特征是有效的是未知的。因此，需要从所有特征中选择出对于学习算法有益的相关特征。而且在实际应用中，经常会出现维度灾难问题。如果只选择所有特征中的部分特征构建模型，那么可以大大减少学习算法的运行时间，也可以增加模型的可解释性\n特征选择的原则 获取尽可能小的特征子集，不显著降低分类精度、不影响分类分布以及特征子集应具有稳定、适应性强等特点\n特征选择的方法 Filter 方法(过滤式) 先进行特征选择，然后去训练学习器，所以特征选择的过程与学习器无关。相当于先对特征进行过滤操作，然后用特征子集来训练分类器。\n**主要思想：**对每一维特征“打分”，即给每一维的特征赋予权重，这样的权重就代表着该特征的重要性，然后依据权重排序。\n主要方法：\n卡方检验 信息增益 相关系数 优点: 运行速度快，是一种非常流行的特征选择方法。\n**缺点：**无法提供反馈，特征选择的标准/规范的制定是在特征搜索算法中完成，学习算法无法向特征搜索算法传递对特征的需求。另外，可能处理某个特征时由于任意原因表示该特征不重要，但是该特征与其他特征结合起来则可能变得很重要。\nWrapper 方法 (封装式) 直接把最后要使用的分类器作为特征选择的评价函数，对于特定的分类器选择最优的特征子集。\n主要思想： 将子集的选择看作是一个搜索寻优问题，生成不同的组合，对组合进行评价，再与其他的组合进行比较。这样就将子集的选择看作是一个优化问题，这里有很多的优化算法可以解决，尤其是一些启发式的优化算法，如GA、PSO（如：优化算法-粒子群算法）、DE、ABC（如：优化算法-人工蜂群算法）等。\n主要方法:\n递归特征消除算法 优点: 对特征进行搜索时围绕学习算法展开的，对特征选择的标准/规范是在学习算法的需求中展开的，能够考虑学习算法所属的任意学习偏差，从而确定最佳子特征，真正关注的是学习问题本身。由于每次尝试针对特定子集时必须运行学习算法，所以能够关注到学习算法的学习偏差/归纳偏差，因此封装能够发挥巨大的作用。\n缺点: 运行速度远慢于过滤算法，实际应用用封装方法没有过滤方法流行。\nEmbedded 方法(嵌入式) 将特征选择嵌入到模型训练当中，其训练可能是相同的模型，但是特征选择完成后，还能给予特征选择完成的特征和模型训练出的超参数，再次训练优化。\n主要思想: 在模型既定的情况下学习出对提高模型准确性最好的特征。也就是在确定模型的过程中，挑选出那些对模型的训练有重要意义的特征。\n主要方法: 用带有L1正则化的项完成特征选择（也可以结合L2惩罚项来优化）、随机森林平均不纯度减少法/平均精确度减少法。\n优点: 对特征进行搜索时围绕学习算法展开的，能够考虑学习算法所属的任意学习偏差。训练模型的次数小于Wrapper方法，比较节省时间。\n缺点: 运行速度慢\n特征选择的实现方法 从两个方面考虑来选择特征： 特征是否发散： 如果一个特征不发散，例如方差接近于0，也就是说样本在这个特征上基本上没有差异，这个特征对于样本的区分并没有什么用。\n假设某特征的特征值只有0和1，并且在所有输入样本中，95%的实例的该特征取值都是1，那就可以认为这个特征作用不大。如果100%都是1，那这个特征就没意义了。\n**特征与目标的相关性：**这点比较显见，与目标相关性高的特征，应当优选选择。除方差法外，本文介绍的其他方法均从相关性考虑。\nFilter: 卡方检验 经典的卡方检验是检验定性自变量对定性因变量的相关性。假设自变量有N种取值，因变量有M种取值，考虑自变量等于i且因变量等于j的样本频数的观察值与期望的差距，构建统计量：\n不难发现，这个统计量的含义简而言之就是自变量对因变量的相关性。用feature_selection库的SelectKBest类结合卡方检验来选择特征的代码如下：\n1 2 3 4 5 from sklearn.feature_selection import SelectKBest from sklearn.feature_selection import chi2 #选择K个最好的特征，返回选择特征后的数据 SelectKBest(chi2, k=2).fit_transform(iris.data, iris.target) 方差选择 使用方差选择法，先要计算各个特征的方差，然后根据阈值，选择方差大于阈值的特征。使用feature_selection库的VarianceThreshold类来选择特征的代码如下：\n1 2 3 4 5 from sklearn.feature_selection import VarianceThreshold #方差选择法，返回值为特征选择后的数据 #参数threshold为方差的阈值 VarianceThreshold(threshold=3).fit_transform(iris.data) 相关系数 使用相关系数法，先要计算各个特征对目标值的相关系数以及相关系数的P值。用feature_selection库的SelectKBest类结合相关系数来选择特征的代码如下：\n1 2 3 4 5 6 7 from sklearn.feature_selection import SelectKBest from scipy.stats import pearsonr #选择K个最好的特征，返回选择特征后的数据 #第一个参数为计算评估特征是否好的函数，该函数输入特征矩阵和目标向量，输出二元组（评分，P值）的数组，数组第i项为第i个特征的评分和P值。在此定义为计算相关系数 #参数k为选择的特征个数 SelectKBest(lambda X, Y: array(map(lambda x:pearsonr(x, Y), X.T)).T, k=2).fit_transform(iris.data, iris.target) 互信息法 经典的互信息也是评价定性自变量对定性因变量的相关性的，互信息计算公式如下：\n为了处理定量数据，最大信息系数法被提出，使用feature_selection库的SelectKBest类结合最大信息系数法来选择特征的代码如下：\n1 2 3 4 5 6 7 8 9 10 11 from sklearn.feature_selection import SelectKBest from minepy import MINE #由于MINE的设计不是函数式的，定义mic方法将其为函数式的，返回一个二元组，二元组的第2项设置成固定的P值0.5 def mic(x, y): m = MINE() m.compute_score(x, y) return (m.mic(), 0.5) #选择K个最好的特征，返回特征选择后的数据 SelectKBest(lambda X, Y: array(map(lambda x:mic(x, Y), X.T)).T, k=2).fit_transform(iris.data, iris.target) Wrapper: 递归特征消除法 递归消除特征法使用一个基模型来进行多轮训练，每轮训练后，消除若干权值系数的特征，再基于新的特征集进行下一轮训练。使用feature_selection库的RFE类来选择特征的代码如下：\n1 2 3 4 5 6 7 from sklearn.feature_selection import RFE from sklearn.linear_model import LogisticRegression #递归特征消除法，返回特征选择后的数据 #参数estimator为基模型 #参数n_features_to_select为选择的特征个数 RFE(estimator=LogisticRegression(), n_features_to_select=2).fit_transform(iris.data, iris.target) Embedded : 基于惩罚项的特征选择法 使用带惩罚项的基模型，除了筛选出特征外，同时也进行了降维。使用feature_selection库的SelectFromModel类结合带L1惩罚项的逻辑回归模型，来选择特征的代码如下：\n1 2 3 4 5 from sklearn.feature_selection import SelectFromModel from sklearn.linear_model import LogisticRegression #带L1惩罚项的逻辑回归作为基模型的特征选择 SelectFromModel(LogisticRegression(penalty=\u0026#34;l1\u0026#34;, C=0.1)).fit_transform(iris.data, iris.target) 实际上，L1惩罚项降维的原理在于保留多个对目标值具有同等相关性的特征中的一个，所以没选到的特征不代表不重要。故，可结合L2惩罚项来优化。具体操作为：若一个特征在L1中的权值为1，选择在L2中权值差别不大且在L1中权值为0的特征构成同类集合，将这一集合中的特征平分L1中的权值，故需要构建一个新的逻辑回归模型：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 from sklearn.linear_model import LogisticRegression class LR(LogisticRegression): def __init__(self, threshold=0.01, dual=False, tol=1e-4, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver=\u0026#39;liblinear\u0026#39;, max_iter=100, multi_class=\u0026#39;ovr\u0026#39;, verbose=0, warm_start=False, n_jobs=1): #权值相近的阈值 self.threshold = threshold LogisticRegression.__init__(self, penalty=\u0026#39;l1\u0026#39;, dual=dual, tol=tol, C=C, fit_intercept=fit_intercept, intercept_scaling=intercept_scaling, class_weight=class_weight, random_state=random_state, solver=solver, max_iter=max_iter, multi_class=multi_class, verbose=verbose, warm_start=warm_start, n_jobs=n_jobs) #使用同样的参数创建L2逻辑回归 self.l2 = LogisticRegression(penalty=\u0026#39;l2\u0026#39;, dual=dual, tol=tol, C=C, fit_intercept=fit_intercept, intercept_scaling=intercept_scaling, class_weight = class_weight, random_state=random_state, solver=solver, max_iter=max_iter, multi_class=multi_class, verbose=verbose, warm_start=warm_start, n_jobs=n_jobs) def fit(self, X, y, sample_weight=None): #训练L1逻辑回归 super(LR, self).fit(X, y, sample_weight=sample_weight) self.coef_old_ = self.coef_.copy() #训练L2逻辑回归 self.l2.fit(X, y, sample_weight=sample_weight) cntOfRow, cntOfCol = self.coef_.shape #权值系数矩阵的行数对应目标值的种类数目 for i in range(cntOfRow): for j in range(cntOfCol): coef = self.coef_[i][j] #L1逻辑回归的权值系数不为0 if coef != 0: idx = [j] #对应在L2逻辑回归中的权值系数 coef1 = self.l2.coef_[i][j] for k in range(cntOfCol): coef2 = self.l2.coef_[i][k] #在L2逻辑回归中，权值系数之差小于设定的阈值，且在L1中对应的权值为0 if abs(coef1-coef2) \u0026lt; self.threshold and j != k and self.coef_[i][k] == 0: idx.append(k) #计算这一类特征的权值系数均值 mean = coef / len(idx) self.coef_[i][idx] = mean return self 使用feature_selection库的SelectFromModel类结合带L1以及L2惩罚项的逻辑回归模型，来选择特征的代码如下：\n1 2 3 4 5 from sklearn.feature_selection import SelectFromModel #带L1和L2惩罚项的逻辑回归作为基模型的特征选择 #参数threshold为权值系数之差的阈值 SelectFromModel(LR(threshold=0.5, C=0.1)).fit_transform(iris.data, iris.target) 基于树模型的特征选择法\n树模型中GBDT也可用来作为基模型进行特征选择，使用feature_selection库的SelectFromModel类结合GBDT模型，来选择特征的代码如下：\n1 2 3 4 5 from sklearn.feature_selection import SelectFromModel from sklearn.ensemble import GradientBoostingClassifier #GBDT作为基模型的特征选择 SelectFromModel(GradientBoostingClassifier()).fit_transform(iris.data, iris.target) 降维 当特征选择完成后，可以直接训练模型了，但是可能由于特征矩阵过大，导致计算量大，训练时间长的问题，因此降低特征矩阵维度也是必不可少的。常见的降维方法除了以上提到的基于L1惩罚项的模型以外，另外还有主成分分析法（PCA）和线性判别分析（LDA），线性判别分析本身也是一个分类模型。PCA和LDA有很多的相似点，其本质是要将原始的样本映射到维度更低的样本空间中，但是PCA和LDA的映射目标不一样：PCA是为了让映射后的样本具有最大的发散性；而LDA是为了让映射后的样本有最好的分类性能。所以说PCA是一种无监督的降维方法，而LDA是一种有监督的降维方法。\n主成分分析法(PCA) 使用decomposition库的PCA类选择特征的代码如下：\n1 2 3 4 5 from sklearn.decomposition import PCA #主成分分析法，返回降维后的数据 #参数n_components为主成分数目 PCA(n_components=2).fit_transform(iris.data) 线性判别分析法（LDA） 使用lda库的LDA类选择特征的代码如下：\n1 2 3 4 5 from sklearn.lda import LDA #线性判别分析法，返回降维后的数据 #参数n_components为降维后的维数 LDA(n_components=2).fit_transform(iris.data, iris.target) 什么是特征选择，为什么要进行特征选择，以及如何进行？ 特征选择是通过选择旧属性的子集得到新属性，是一种维规约方式。\nWhy： 应用方面：提升准确率，特征选择能够删除冗余不相关的特征并降低噪声，避免维灾难。在许多数据挖掘算法中，维度较低，效果更好；\n执行方面：维度越少，运行效率越高，同时内存需求越少。\nHow: 过滤方法，独立于算法，在算法运行前进行特征选择。如可以选择属性的集合，集合内属性对之间的相关度尽可能低。常用对特征重要性（方差，互信息，相关系数，卡方检验）排序选择；可结合别的算法（随机森林，GBDT等）进行特征重要性提取，过滤之后再应用于当前算法。 包装方法，算法作为黑盒，在确定模型和评价准则之后，对特征空间的不同子集做交叉验证，进而搜索最佳特征子集。深度学习具有自动化包装学习的特性。 总之，特征子集选择是搜索所有可能的特性子集的过程，可以使用不同的搜索策略，但是搜索策略的效率要求比较高，并且应当找到最优或近似最优的特征子集。 嵌入方法，算法本身决定使用哪些属性和忽略哪些属性。即特征选择与训练过程融为一体，比如L1正则、决策树等； 参考: https://blog.csdn.net/Dream_angel_Z/article/details/49388733\n","permalink":"https://reid00.github.io/post/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B%E4%B9%8B%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9/","summary":"Summary 数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已。由此可见，特征工程在机器学习中占有相当重要的地位。在实际应用当中，可以说","title":"特征工程之特征选择"},{"content":"Summary PCA 是无监督学习中最常见的数据降维方法，但是实际上问题特征很多的情况，PCA通常会预处理来减少特征个数。\n将维的意义： 通过降维提高算法的效率 通过降维更方便数据的可视化，通过可视化我们可以更好的理解数据\n相关统计概念 均值： 述的是样本集合的中间点。 方差： 概率论和统计方差衡量随机变量或一组数据时离散程度的度量。 标准差：而标准差给我们描述的是样本集合的各个样本点到均值的距离之平均。方差开根号。 标准差和方差一般是用来描述一维数据的 协方差: （多维）度量两个随机变量关系的统计量,来度量各个维度偏离其均值的程度。 协方差矩阵: （多维）度量各个维度偏离其均值的程度 当 cov(X, Y)\u0026gt;0时，表明X与Y正相关(X越大，Y也越大；X越小Y，也越小。) 当 cov(X, Y)\u0026lt;0时，表明X与Y负相关； 当 cov(X, Y)=0时，表明X与Y不相关。 cov协方差=[(x1-x均值)(y1-y均值)+(x2-x均值)(y2-y均值)+\u0026hellip;+(xn-x均值)*(yn-y均值)]/(n-1) PCA 思想 对数据进行归一化处理（代码中并非这么做的，而是直接减去均值） 计算归一化后的数据集的协方差矩阵 计算协方差矩阵的特征值和特征向量 将特征值排序 保留前N个最大的特征值对应的特征向量 将数据转换到上面得到的N个特征向量构建的新空间中（实现了特征压缩） 简述主成分分析PCA工作原理，以及PCA的优缺点？ PCA旨在找到数据中的主成分，并利用这些主成分表征原始数据，从而达到降维的目的。\n​ 工作原理可由两个角度解释，第一个是最大化投影方差（让数据在主轴上投影的方差尽可能大）；第二个是最小化平方误差（样本点到超平面的垂直距离足够近）。\n​ 做法是数据中心化之后，对样本数据协方差矩阵进行特征分解，选取前d个最大的特征值对应的特征向量，即可将数据从原来的p维降到d维，也可根据奇异值分解来求解主成分。\n优点： 1.计算简单，易于实现\n2.各主成分之间正交，可消除原始数据成分间的相互影响的因素\n3.仅仅需要以方差衡量信息量，不受数据集以外的因素影响\n4.降维维数木有限制，可根据需要制定\n缺点： 1.无法利用类别的先验信息\n2.降维后，只与数据有关，主成分各个维度的含义模糊，不易于解释\n3.方差小的非主成分也可能含有对样本差异的重要信息，因降维丢弃可能对后续数据处理有影响\n4.线性模型，对于复杂数据集难以处理（可用核映射方式改进）\nPCA中有第一主成分、第二主成分，它们分别是什么，又是如何确定的？ 主成分分析是设法将原来众多具有一定相关性（比如P个指标），重新组合成一组新的互相无关的综合指标来代替原来的指标。主成分分析，是考察多个变量间相关性一种多元统计方法，研究如何通过少数几个主成分来揭示多个变量间的内部结构，即从原始变量中导出少数几个主成分，使它们尽可能多地保留原始变量的信息，且彼此间互不相关，通常数学上的处理就是将原来P个指标作线性组合，作为新的综合指标。\n​ 最经典的做法就是用F1（选取的第一个线性组合，即第一个综合指标）的方差来表达，即Var(F1)越大，表示F1包含的信息越多。因此在所有的线性组合中选取的F1应该是方差最大的，故称F1为第一主成分。如果第一主成分不足以代表原来P个指标的信息，再考虑选取F2即选第二个线性组合，为了有效地反映原来信息，F1已有的信息就不需要再出现在F2中，用数学语言表达就是要求Cov(F1, F2)=0，则称F2为第二主成分，依此类推可以构造出第三、第四，……，第P个主成分。\nLDA与PCA都是常用的降维方法，二者的区别 它其实是对数据在高维空间下的一个投影转换，通过一定的投影规则将原来从一个角度看到的多个维度映射成较少的维度。到底什么是映射，下面的图就可以很好地解释这个问题——正常角度看是两个半椭圆形分布的数据集，但经过旋转（映射）之后是两条线性分布数据集。\nLDA与PCA都是常用的降维方法，二者的区别在于：\n**出发思想不同。**PCA主要是从特征的协方差角度，去找到比较好的投影方式，即选择样本点投影具有最大方差的方向（ 在信号处理中认为信号具有较大的方差，噪声有较小的方差，信噪比就是信号与噪声的方差比，越大越好。）；而LDA则更多的是考虑了分类标签信息，寻求投影后不同类别之间数据点距离更大化以及同一类别数据点距离最小化，即选择分类性能最好的方向。\n**学习模式不同。**PCA属于无监督式学习，因此大多场景下只作为数据处理过程的一部分，需要与其他算法结合使用，例如将PCA与聚类、判别分析、回归分析等组合使用；LDA是一种监督式学习方法，本身除了可以降维外，还可以进行预测应用，因此既可以组合其他模型一起使用，也可以独立使用。\n**降维后可用维度数量不同。**LDA降维后最多可生成C-1维子空间（分类标签数-1），因此LDA与原始维度N数量无关，只有数据标签分类数量有关；而PCA最多有n维度可用，即最大可以选择全部可用维度。\n线性判别分析LDA算法由于其简单有效性在多个领域都得到了广泛地应用，是目前机器学习、数据挖掘领域经典且热门的一个算法；但是算法本身仍然存在一些局限性：\n当样本数量远小于样本的特征维数，样本与样本之间的距离变大使得距离度量失效，使LDA算法中的类内、类间离散度矩阵奇异，不能得到最优的投影方向，在人脸识别领域中表现得尤为突出\nLDA不适合对非高斯分布的样本进行降维\nLDA在样本分类信息依赖方差而不是均值时，效果不好\nLDA可能过度拟合数据\n主成分分析 PCA 详解 原理及对应操作 主成分分析顾名思义是对主成分进行分析，那么找出主成分应该是key点。PCA的基本思想就是将初始数据集中的n维特征映射至k维上，得到的k维特征就可以被称作主成分，k维不是在n维中挑选出来的，而是以n维特征为基础重构出来的。\nPCA会在已知数据的基础上重构坐标轴，它的原理是要最大化保留样本间的方差，两个特征之间方差越大不就代表相关性越差嘛。比如：\n第一个新坐标轴就是原始数据中方差最大的方向。 第二个新坐标轴要是与第一个新坐标轴正交的平面中方差最大的方向。 第三个新坐标轴要是与第一、第二新坐标轴正交的平面中方差最大的方向。 第四、第五\u0026hellip;依次类推直到第n个新坐标轴(对应n维)。 为了加深这部分理解，以二维平面先举一个例子，二维平面中依据原始数据新建坐标轴如下图：\n为了更直观的理解，若将方差换一个说法，那么第一个新坐标轴就是覆盖样本最多的一条(斜向右上)，第二个新坐标轴需要与第一新坐标轴正交且覆盖样本最多(斜向左上)，依次类推。\n覆盖的样本多少并不是以坐标轴穿过多少样本点评判的，而是通过样本点垂直映射至该轴的个数有多少，具体如下图：\n回到之前的n维重构坐标轴，由于顺序是依据方差的大小依次排序的，所以越到后面方差越小，而方差越小代表特征之间相关性越强，那么这类特征就可以删去，只保留前k个坐标轴(对应k维)，这就相当于保留了含有数据集绝大部分方差的特征，而除去方差几乎为0的特征。\n那么问题来了，二维、三维可以根据样本点的分布画出重构坐标轴，但是更高维人的大脑是不接受的，我们不得不通过计算的方式求得特征之间的方差，进而得到这些新坐标轴的的方向。\n具体方法就是通过计算原始数据矩阵对应的协方差矩阵，然后可以得到协方差矩阵对应的特征值和特征向量，选取特征值最大的前k个特征向量组成的矩阵，通过特征矩阵就可以将原始数据矩阵从n维空间映射至k维空间，从而实现特征降维。\n方差、协方差及协方差矩阵 如果你曾经接触过线性代数可能对这三个概念很熟悉，可能间隔时间太久有些模糊，下面再帮大家温习一下：\n方差(Variance)一般用来描述样本集合中的各个样本点到样本均值的差的平方和的均值：\n协方差(Covariance)目的是度量两个变量(只能为两个)线性相关的程度：\n为可以说明两个变量线性无关，但不能证明两个变量相互独立，当时，二者呈正相关，时，二者呈负相关。\n协方差矩阵就是由两两变量之间的协方差组成，有以下特点：\n协方差矩阵可以处理多维度问题。 协方差矩阵是一个对称的矩阵，而且对角线是各个维度上的方差。 协方差矩阵计算的是不同维度之间的协方差，而不是不同样本之间的。 样本矩阵中若每行是一个样本，则每列为一个维度。 假设数据是3维的，那么对应协方差矩阵为：\n这里简要概括一下协方差矩阵是怎么求得的，假设一个数据集有3维特征、每个特征有m个变量，这个数据集对应的数据矩阵如下：\n若假设他们的均值都为0，可以得到下面等式：\n可以看到对角线上为每个特征方差，其余位置为两个特征之间的协方差，求得的就为协方差矩阵。\n这里叙述的有些简略，感兴趣的小伙伴可以自行查询相关知识。\n特征值和特征向量 得到了数据矩阵的协方差矩阵，下面就应该求协方差矩阵的特征值和特征向量，先了解一下这两个概念，如果一个向量v是矩阵A的特征向量，那么一定存在下列等式：\n其中A可视为数据矩阵对应的协方差矩阵，是特征向量v的特征值。数据矩阵的主成分就是由其对应的协方差矩阵的特征向量，按照对应的特征值由大到小排序得到的。最大的特征值对应的特征向量就为第一主成分，第二大的特征值对应的特征向量就为第二主成分，依次类推，如果由n维映射至k维就截取至第k主成分。\n实例操作 通过上述部分总结一下PCA降维操作的步骤：\n去均值化 依据数据矩阵计算协方差矩阵 计算协方差矩阵的特征值和特征向量 将特征值从大到小排序 保留前k个特征值对应的特征向量 将原始数据的n维映射至k维中 公式手推降维 原始数据集矩阵，每行代表一个特征:\n对每个特征去均值化：\n计算对应的协方差矩阵：\n依据协方差矩阵计算特征值和特征向量，套入公式：\n拆开计算如下：\n可以求得两特征值：\n，\n当时，对应向量应该满足如下等式：\n对应的特征向量可取为：\n同理当时，对应特征向量可取为：\n这里我就不对两个特征向量进行标准化处理了，直接合并两个特征向量可以得到矩阵P：\n选取大的特征值对应的特征向量乘以原数据矩阵后可得到降维后的矩阵A：\n综上步骤就是通过PCA手推公式实现二维降为一维的操作。\nnumpy实现降维 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 import numpy as np def PCA(X,k): \u0026#39;\u0026#39;\u0026#39; X:输入矩阵 k:需要降低到的维数 \u0026#39;\u0026#39;\u0026#39; X = np.array(X) #转为矩阵 sample_num ,feature_num = X.shape #样本数和特征数 meanVals = np.mean(X,axis = 0) #求每个特征的均值 X_mean = X-meanVals #去均值化 Cov = np.dot(X_mean.T,X_mean)/sample_num #求协方差矩阵 feature_val,feature_vec = np.linalg.eig(Cov) #将特征值和特征向量打包 val_sort = [(np.abs(feature_val[i]),feature_vec[:,i]) for i in range(feature_num)] val_sort.sort(reverse=True) #按特征值由大到小排列 #截取至前k个特征向量组成特征矩阵 feature_mat = [feature[1] for feature in val_sort[:k]] # 降n维映射至k维 PCA_mat = np.dot(X_mean,np.array(feature_mat).T) return PCA_mat if __name__ == \u0026#34;__main__\u0026#34;: X = [[1, 1], [1, 3], [2, 3], [4, 4], [2, 4]] print(PCA(X,1)) 运行截图如下：\n代码部分就是公式的套用，每一步后都有注释，不再过多解释。可以看到得到的结果和上面手推公式得到的有些出入，上文曾提过特征向量是可以随意缩放的，这也是导致两个结果不同的原因，可以在运行代码时打印一下特征向量feature_vec，观察一下这个特点。\nsklearn库实现降维 1 2 3 4 5 6 7 8 from sklearn.decomposition import PCA import numpy as np X = [[1, 1], [1, 3], [2, 3], [4, 4], [2, 4]] X = np.array(X) pca = PCA(n_components=1) PCA_mat = pca.fit_transform(X) print(PCA_mat) 这里只说一下参数n_components，如果输入的是整数，代表数据集需要映射的维数，比如输入3代表最后要映射至3维；如果输入的是小数，则代表映射的维数为原数据维数的占比，比如输入0.3，如果原数据20维，就将其映射至6维。\n","permalink":"https://reid00.github.io/post/%E6%95%B0%E6%8D%AE%E9%99%8D%E7%BB%B4%E4%B9%8B%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90-pca/","summary":"Summary PCA 是无监督学习中最常见的数据降维方法，但是实际上问题特征很多的情况，PCA通常会预处理来减少特征个数。 将维的意义： 通过降维提高算法的效率 通","title":"数据降维之主成分分析 PCA"},{"content":"Summary 数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已。由此可见，特征工程在机器学习中占有相当重要的地位。在实际应用当中，可以说特征工程是机器学习成功的关键。\n什么是特征工程 特征工程又包含了Data PreProcessing（数据预处理）、Feature Extraction（特征提取）、Feature Selection（特征选择）和Feature construction（特征构造）等子问题，本章内容主要讨论数据预处理的方法及实现。 特征工程是机器学习中最重要的起始步骤，数据预处理是特征工程的最重要的起始步骤，而数据清洗是数据预处理的重要组成部分，会直接影响机器学习的效果。\n数据清洗整体介绍 1. 箱线图分析异常值 箱线图提供了识别异常值的标准，如果一个数下雨 QL-1.5IQR or 大于OU + 1.5 IQR, 则这个值被称为异常值。\nQL 下四分位数，表示四分之一的数据值比它小 QU　上四分位数，表示四分之一的数据值比它大 IRQ　四分位距，是QU－QL　的差值，包含了全部关差值的一般 2. 数据的光滑处理 除了检测出异常值然后再处理异常值外，还可以使用以下方法对异常数据进行光滑处理。\n2.1. 变量分箱（即变量离散化) 离散特征的增加和减少都很容易，易于模型的快速迭代； 稀疏向量内积乘法运算速度快，计算结果方便存储，容易扩展； 离散化后的特征对异常数据有很强的鲁棒性：比如一个特征是年龄\u0026gt;30是1，否则0。如果特征没有离散化，一个异常数据“年龄300岁”会给模型造成很大的干扰； 逻辑回归属于广义线性模型，表达能力受限；单变量离散化为N个后，每个变量有单独的权重，相当于为模型引入了非线性，能够提升模型表达能力，加大拟合； 离散化后可以进行特征交叉，由M+N个变量变为M*N个变量，进一步引入非线性，提升表达能力； 特征离散化后，模型会更稳定，比如如果对用户年龄离散化，20-30作为一个区间，不会因为一个用户年龄长了一岁就变成一个完全不同的人。当然处于区间相邻处的样本会刚好相反，所以怎么划分区间是门学问； 特征离散化以后，起到了简化了逻辑回归模型的作用，降低了模型过拟合的风险。 可以将缺失作为独立的一类带入模型。 将所有变量变换到相似的尺度上。 2.1.0 变量分箱的方法 2.1.1 无序变量分箱 举个例子，在实际模型建立当中，有个 job 职业的特征，取值为（“国家机关人员”，“专业技术人员”，“商业服务人员”），对于这一类变量，如果我们将其依次赋值为（国家机关人员=1；专业技术人员=2；商业服务人员=3），就很容易产生一个问题，不同种类的职业在数据层面上就有了大小顺序之分，国家机关人员和商业服务人员的差距是2，专业技术人员和商业服务人员的之间的差距是1，而我们原来的中文分类中是不存在这种先后顺序关系的。所以这么简单的赋值是会使变量失去原来的衡量效果。\n怎么处理这个问题呢? “一位有效编码” （one-hot Encoding）可以解决这个问题，通常叫做虚变量或者哑变量（dummpy variable）：比如职业特征有3个不同变量，那么将其生成个2哑变量，分别是“是否国家党政职业人员”，“是否专业技术人员” ，每个虚变量取值（1，0）。 为什么2个哑变量而非3个？ 在模型中引入多个虚拟变量时，虚拟变量的个数应按下列原则确定： 回归模型有截距：一般的，若该特征下n个属性均互斥（如，男/女;儿童/青年/中年/老年），在生成虚拟变量时，应该生成 n-1个虚变量，这样可以避免产生多重共线性 回归模型无截距项：有n个特征，设置n个虚拟变量 python 实现方法pd.get_dummies() 2.1.2 有序变量分箱 有序多分类变量是很常见的变量形式，通常在变量中有多个可能会出现的取值，各取值之间还存在等级关系。比如高血压分级（0=正常，1=正常高值，2=1级高血压，3=2级高血压，4=3级高血压）这类变量处理起来简直不要太省心，使用 pandas 中的 map（）替换相应变量就行。\n1 2 3 4 5 import pandas as pd df= pd.DataFrame([\u0026#39;正常\u0026#39;,\u0026#39;3级高血压\u0026#39;,\u0026#39;正常\u0026#39;,\u0026#39;2级高血压\u0026#39;,\u0026#39;正常\u0026#39;,\u0026#39;正常高值\u0026#39;,\u0026#39;1级高血压\u0026#39;],columns=[\u0026#39;blood_pressure\u0026#39;]) dic_blood = {\u0026#39;正常\u0026#39;:0,\u0026#39;正常高值\u0026#39;:1,\u0026#39;1级高血压\u0026#39;:2,\u0026#39;2级高血压\u0026#39;:3,\u0026#39;3级高血压\u0026#39;:4} df[\u0026#39;blood_pressure_enc\u0026#39;] = df[\u0026#39;blood_pressure\u0026#39;].map(dic_blood) print(df) 2.1.3 连续变量的分箱方式 等宽划分：按照相同宽度将数据分成几等份。缺点是受到异常值的影响比较大。 pandas.cut方法可以进行等宽划分。 等频划分：将数据分成几等份，每等份数据里面的个数是一样的。pandas.qcut方法可以进行等频划分。 1 2 3 4 5 6 import pandas as pd df = pd.DataFrame([[22,1],[13,1],[33,1],[52,0],[16,0],[42,1],[53,1],[39,1],[26,0],[66,0]],columns=[\u0026#39;age\u0026#39;,\u0026#39;Y\u0026#39;]) #print(df) df[\u0026#39;age_bin_1\u0026#39;] = pd.qcut(df[\u0026#39;age\u0026#39;],3) #新增一列存储等频划分的分箱特征 df[\u0026#39;age_bin_2\u0026#39;] = pd.cut(df[\u0026#39;age\u0026#39;],3) #新增一列存储等距划分的分箱特征 print(df) 2.1.4 有监督学习分箱方法 最小熵法分箱 假设因变量为分类变量，可取值1，… ，J。令pijpij表示第i个分箱内因变量取值为j的观测的比例，i=1，…，k，j=1，…，J；那么第i个分箱的熵值为∑Jj=0−pij×logpij∑j=0J−pij×logpij。如果第i个分箱内因变量各类别的比例相等，即p11=p12=p1J=1/Jp11=p12=p1J=1/J，那么第i个分箱的熵值达到最大值；如果第i个分箱内因变量只有一种取值，即某个pijpij等于1而其他类别的比例等于0，那么第i个分箱的熵值达到最小值。 令riri表示第i个分箱的观测数占所有观测数的比例；那么总熵值为∑ki=0∑Jj=0(−pij×logpij)∑i=0k∑j=0J(−pij×logpij)。需要使总熵值达到最小，也就是使分箱能够最大限度地区分因变量的各类别。 卡方分箱 (常用) 自底向上的(即基于合并的)数据离散化方法。 它依赖于卡方检验:具有最小卡方值的相邻区间合并在一起,直到满足确定的停止准则。 基本思想: 对于精确的离散化，相对类频率在一个区间内应当完全一致。因此,如果两个相邻的区间具有非常类似的类分布，则这两个区间可以合并；否则，它们应当保持分开。而低卡方值表明它们具有相似的类分布。 2.2 无量纲化 无量纲化使不同规格的数据转换到同一规格。常见的无量纲化方法有标准化和区间缩放法。标准化的前提是特征值服从正态分布，标准化后，其转换成标准正态分布。区间缩放法利用了边界值信息，将特征的取值区间缩放到某个特点的范围，例如[0, 1]等。\n2.2.1 标准化 标准化需要计算特征的均值和标准差，公式表达为：\n使用preproccessing库的StandardScaler类对数据进行标准化的代码如下：\n1 2 3 4 from sklearn.preprocessing import StandardScaler #标准化，返回值为标准化后的数据 StandardScaler().fit_transform(iris.data) 2.2.2 区间缩放法 区间缩放法的思路有多种，常见的一种为利用两个最值进行缩放，公式表达为：\n使用preproccessing库的MinMaxScaler类对数据进行区间缩放的代码如下：\n1 2 3 4 from sklearn.preprocessing import MinMaxScaler #区间缩放，返回值为缩放到[0, 1]区间的数据 MinMaxScaler().fit_transform(iris.data) 2.1.3 标准化与归一化的区别 简单来说，标准化是依照特征矩阵的列处理数据，其通过求z-score的方法，将样本的特征值转换到同一量纲下。归一化是依照特征矩阵的行处理数据，其目的在于样本向量在点乘运算或其他核函数计算相似性时，拥有统一的标准，也就是说都转化为“单位向量”。规则为l2的归一化公式如下：\n什么时候需要进行归一化？\n归一化后加快了梯度下降求最优解的速度 归一化有可能提高精度 什么时候需要进行归一化？\n通常在需要用到梯度下降法的时候。 包括线性回归、逻辑回归、支持向量机、神经网络等模型。\n决策树模型就不适用 例如 C4.5 ，主要根据信息增益比来分裂，归一化不会改变样本在特征 x 上的信息增益\n比较概率大小分布即可，不需要。\n使用preproccessing库的Normalizer类对数据进行归一化的代码如下：\n1 2 3 4 from sklearn.preprocessing import Normalizer #归一化，返回值为归一化后的数据 Normalizer().fit_transform(iris.data) 2.3 对定量特征二值化 定量特征二值化的核心在于设定一个阈值，大于阈值的赋值为1，小于等于阈值的赋值为0，公式表达如下：\n使用preproccessing库的Binarizer类对数据进行二值化的代码如下：\n1 2 3 4 from sklearn.preprocessing import Binarizer #二值化，阈值设置为3，返回值为二值化后的数据 Binarizer(threshold=3).fit_transform(iris.data) 2.4 对定性特征哑编码 由于IRIS数据集的特征皆为定量特征，故使用其目标值进行哑编码（实际上是不需要的）。使用preproccessing库的OneHotEncoder类对数据进行哑编码的代码如下：\n1 2 3 4 from sklearn.preprocessing import OneHotEncoder #哑编码，对IRIS数据集的目标值，返回值为哑编码后的数据 OneHotEncoder().fit_transform(iris.target.reshape((-1,1))) 2.5 缺失值计算 由于IRIS数据集没有缺失值，故对数据集新增一个样本，4个特征均赋值为NaN，表示数据缺失。使用preproccessing库的Imputer类对数据进行缺失值计算的代码如下：\n1 2 3 4 5 6 7 from numpy import vstack, array, nan from sklearn.preprocessing import Imputer #缺失值计算，返回值为计算缺失值后的数据 #参数missing_value为缺失值的表示形式，默认为NaN #参数strategy为缺失值填充方式，默认为mean（均值） Imputer().fit_transform(vstack((array([nan, nan, nan, nan]), iris.data))) 2.6 数据变换 常见的数据变换有基于多项式的、基于指数函数的、基于对数函数的。4个特征，度为2的多项式转换公式如下：\n使用preproccessing库的PolynomialFeatures类对数据进行多项式转换的代码如下：\n1 2 3 4 5 from sklearn.preprocessing import PolynomialFeatures #多项式转换 #参数degree为度，默认值为2 PolynomialFeatures().fit_transform(iris.data) 基于单变元函数的数据变换可以使用一个统一的方式完成，使用preproccessing库的FunctionTransformer对数据进行对数函数转换的代码如下：\n1 2 3 4 5 6 from numpy import log1p from sklearn.preprocessing import FunctionTransformer #自定义转换函数为对数函数的数据变换 #第一个参数是单变元函数 FunctionTransformer(log1p).fit_transform(iris.data) 2.7 回归 可以用一个函数（如回归函数）拟合数据来光滑数据。线性回归涉及找出拟合两个属性（或变量）的“最佳”线，是的一个属性可以用来预测另一个。多元线性回归是线性回归的扩展，其中涉及的属性多于两个，并且数据拟合到一个多维曲面。\n3. 异常值处理方法 删除含有异常值的记录； 某些筛选出来的异常样本是否真的是不需要的异常特征样本，最好找懂业务的再确认一下，防止我们将正常的样本过滤掉了。 将异常值视为缺失值，交给缺失值处理方法来处理； 使用均值/中位数/众数来修正； 不处理。 4. 什么是组合特征？如何处理高维组合特征？ 为了提高复杂关系的拟合能力，在特征工程中经常会把一阶离散特征两两组合成高阶特征，构成交互特征（Interaction Feature）。以广告点击预估问题为例，如图1所示，原始数据有语言和类型两种离散特征。为了提高拟合能力，语言和类型可以组成二阶特征。\n5. 类别型特征 什么是类别型特征？\n例如：性别（男、女）、血型（A、B、AB、O）\n通常是字符串形式，需要转化成数值型，传递给模型\n如何处理类别型特征？\n序号编码（Ordinal Encoding） 例如学习成绩有高中低三档，也就是不同类别之间关系。\n这时可以用321来表示，保留了大小关系。\n独热编码（One-hot Encoding） 例如血型，它的类别没有大小关系。A 型血表示为（1, 0, 0, 0），B 型血表示为（0, 1, 0, 0）……\n二进制编码（Binary Encoding） 第一步，先用序号编码给每个类别编码\n第二步，将类别 ID 转化为相应的二进制\n","permalink":"https://reid00.github.io/post/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B%E4%B9%8B%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/","summary":"Summary 数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已。由此可见，特征工程在机器学习中占有相当重要的地位。在实际应用当中，可以说","title":"特征工程之数据预处理"},{"content":"介绍 这是我博客 Blog 的地址 和 Github Repositroy。\n本博客是用Hugo 来生成静态网站。 Hugo GitHub\n并通过 GitHub Action 来自动化部署到 GitHub Pages。\n搭建步骤 创建代码仓库 首先按照文档创建 GitHub Pages 站点。该仓库可见性必须是 Public。\n另外创建一个仓库用来存放 Hugo 的源文件，名称随意，这里假设仓库名叫 .github.io.source。建议将仓库可见性设置成 Private 以保护好你的源代码。\n创建完毕后你的账户下将存在以下两个代码仓库：\n==https://github.com//.github.io (公开的)==\n==https://github.com//pages-hugo-source (私有的)==\n生成Hugo 网站 安装Hugo For Windows\n到Github Release 下载最新版本，用hugo version 或者extended version (部分主题需要extended version 才能使用)\n安装步骤参考官方提供\n在C盘新建Hugo/sites 目录用于 生成hugo 项目\n在C盘新建Hugo/bin 目录，用来存放上面解压后的hugo 二进制文件\n添加C:\\Hugo\\bin 到系统环境变量中\n添加完成后，在cmd 或者其他console 中输入hugo version检查 环境变量是否添加成功。\n出现下面的表示成功。注意：环境变量添加成功后，记得重启console\nFor mac/linux\n可以只用用命令下载，此处不多讲了。\nHugo 生成网站 在/c/Hugo/sites 目录下使用命令hugo new site siteName生成网站\n1 hugo new site hello-hugo 执行成功后，Hugo 会给出温馨的提示：\nJust a few more steps and you’re ready to go:\nDownload a theme into the same-named folder. Choose a theme from https://themes.gohugo.io/ or create your own with the “hugo new theme ” command. Perhaps you want to add some content. You can add single files with “hugo new .”. Start the built-in live server via “hugo server”.\n先看看执行完 hugo new site 命令后，Hugo 为我们做了什么。\n进入 hello-hugo 目录，Hugo 生成的内容如下图所示：\n这些大致作用如下：\narchetypes：存放博客的模板，默认提供了一个 default.md 作为所有博客的模板。 data：存放一些数据，如 xml、json 等。 layouts：与博客页面布局相关的内容，如博客网页中的 header、footer 等。 static：存放静态资源，如图标、图片等。 themes：主题相关。 config.toml：站点、主题等相关内容的配置文件，它支持 yaml、toml 和 json 格式，后续将会一直和这个文件打交道。 建议config.toml 改为config.yaml 语法看着更舒服点。\nHugo 主题使用 根据提示，要使用 Hugo，我们必须先下载 主题，这里我选择自己比较喜欢的 PaperMod。\n根据文档安装 hugo 主题。\n文档提供了三种方式，建议使用第一种或者第二种。\n安装主题之后，在项目 theme 文件夹下生成了主题名称的文件夹。\n1 2 3 4 5 6 7 8 9 PS C:\\Hugo\\sites\\Reid00.github.io.source\\themes\u0026gt; ls 目录: C:\\Hugo\\sites\\Reid00.github.io.source\\themes Mode LastWriteTime Length Name ---- ------------- ------ ---- d----- 2022/6/6 19:39 PaperMod 建议修改archetypes/defeault.md， 以后hugo new post/1.md 新建文档的时候就会使用改模板\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 --- title: \u0026#34;{{ replace .Name \u0026#34;-\u0026#34; \u0026#34; \u0026#34; | title }}\u0026#34; date: {{ .Date }} lastmod: {{ .Date }} author: [\u0026#34;Reid\u0026#34;] categories: - tags: - series: - description: \u0026#34;\u0026#34; weight: # 输入1可以顶置文章，用来给文章展示排序，不填就默认按时间排序 slug: \u0026#34;\u0026#34; draft: false # 是否为草稿 comments: true showToc: true # 显示目录 TocOpen: true # 自动展开目录 hidemeta: false # 是否隐藏文章的元信息，如发布日期、作者等 disableShare: true # 底部不显示分享栏 showbreadcrumbs: true #顶部显示当前路径 cover: image: \u0026#34;\u0026#34; caption: \u0026#34;\u0026#34; alt: \u0026#34;\u0026#34; relative: false --- 修改项目配置config.yaml 我的配置如下： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 baseURL: \u0026#34;https://reid00.github.io/\u0026#34; # 绑定的域名 languageCode: zh-cn # en-us title: \u0026#34;Reid\u0026#39;s Blog\u0026#34; theme: PaperMod # 主题名字，和themes文件夹下的一致 enableInlineShortcodes: true enableRobotsTXT: true # 允许爬虫抓取到搜索引擎，建议 true buildDrafts: false buildFuture: false buildExpired: false enableEmoji: true # 允许使用 Emoji 表情，建议 true pygmentsUseClasses: true googleAnalytics: UA-123-45 # 谷歌统计 Copyright: hasCJKLanguage: true # 自动检测是否包含 中文日文韩文 如果文章中使用了很多中文引号的话可以开启 paginate: 10 # 首页每页显示的文章数 minify: disableXML: true # minifyOutput: true defaultContentLanguage: en # 最顶部首先展示的语言页面 defaultContentLanguageInSubdir: true languages: en: languageName: \u0026#34;English\u0026#34; weight: 1 taxonomies: category: categories tag: tags series: series menu: main: - name: Archive url: archives weight: 5 - name: Search url: search/ weight: 7 - name: Categorys url: categories/ weight: 10 - name: Tags url: tags/ weight: 10 outputs: home: - HTML - RSS - JSON params: env: production # to enable google analytics, opengraph, twitter-cards and schema. description: \u0026#34;Reid\u0026#39;s Personal Notes -- https://github.com/Reid00\u0026#34; author: Reid # author: [\u0026#34;Me\u0026#34;, \u0026#34;You\u0026#34;] # multiple authors defaultTheme: auto # disableThemeToggle: true DateFormat: \u0026#34;2006-01-02\u0026#34; ShowShareButtons: false ShowReadingTime: true # disableSpecial1stPost: true displayFullLangName: true ShowPostNavLinks: true ShowBreadCrumbs: true ShowCodeCopyButtons: true ShowRssButtonInSectionTermList: true ShowLastMod: true # 显示文章更新时间 ShowToc: true # 显示目录 TocOpen: true # 自动展开目录 comments: true images: [\u0026#34;https://i.loli.net/2021/09/26/3OMGXylm8HUYJ6p.png\u0026#34;] # profileMode: # enabled: false # title: PaperMod # imageUrl: \u0026#34;#\u0026#34; # imageTitle: my image # # imageWidth: 120 # # imageHeight: 120 # buttons: # - name: Archives # url: archives # - name: Tags # url: tags homeInfoParams: Title: \u0026#34;Hi there \\U0001F44B\u0026#34; Content: \u0026gt; Welcome to My Blog. - **Blog** 是我个人的一些笔记 - 包含Go, Python, 机器学习, KV 存储引擎的一些相关笔记, 方便以后复习 - [GitHub主页](https://github.com/Reid00) socialIcons: - name: github url: \u0026#34;https://github.com/Reid00\u0026#34; - name: twitter url: \u0026#34;https://twitter.com\u0026#34; - name: RsS url: \u0026#34;index.xml\u0026#34; # editPost: # URL: \u0026#34;https://github.com/adityatelange/hugo-PaperMod/tree/exampleSite/content\u0026#34; # Text: \u0026#34;Suggest Changes\u0026#34; # edit text # appendFilePath: true # to append file path to Edit link # label: # text: \u0026#34;Home\u0026#34; # icon: icon.png # iconHeight: 35 # analytics: # google: # SiteVerificationTag: \u0026#34;XYZabc\u0026#34; # assets: # favicon: \u0026#34;\u0026lt;link / abs url\u0026gt;\u0026#34; # favicon16x16: \u0026#34;\u0026lt;link / abs url\u0026gt;\u0026#34; # favicon32x32: \u0026#34;\u0026lt;link / abs url\u0026gt;\u0026#34; # apple_touch_icon: \u0026#34;\u0026lt;link / abs url\u0026gt;\u0026#34; # safari_pinned_tab: \u0026#34;\u0026lt;link / abs url\u0026gt;\u0026#34; cover: responsiveImages: false # 仅仅用在Page Bundle情况下，此处不讨论 hidden: false # hide everywhere but not in structured data hiddenInList: false # hide on list pages and home hiddenInSingle: false # hide on single page # fuseOpts: # isCaseSensitive: false # shouldSort: true # location: 0 # distance: 1000 # threshold: 0.4 # minMatchCharLength: 0 # keys: [\u0026#34;title\u0026#34;, \u0026#34;permalink\u0026#34;, \u0026#34;summary\u0026#34;, \u0026#34;content\u0026#34;] markup: goldmark: renderer: unsafe: true highlight: # anchorLineNos: true codeFences: true guessSyntax: true lineNos: true noClasses: false style: monokai privacy: vimeo: disabled: false simple: true twitter: disabled: false enableDNT: true simple: true instagram: disabled: false simple: true youtube: disabled: false privacyEnhanced: true services: instagram: disableInlineCSS: true twitter: disableInlineCSS: true 新建hugo 网页 这时候主题已经激活了，我们先往博客中添加一篇文章，hugo new post/first.md：\n1 2 hugo new post/first.md hugo new post/second.md 此处观看content 目录，会生成posts 文件夹\n1 2 3 4 5 6 7 8 9 10 11 12 13 PS C:\\Hugo\\sites\\Reid00.github.io.source\\content\u0026gt; tree /F 文件夹 PATH 列表 卷序列号为 E2D5-548C C:. │ archives.md │ search.md │ └─post 4th.md first.md second.md test.md third.md 另外要使用 Archive 和 Search，需要进行以下操作：\n在 content 下增加 archives.md 文件，具体位置如下：\n1 2 3 4 5 6 7 . ├── content/ │ ├── archives.md \u0026lt;--- Create archive.md here │ └── posts/ ├── static/ └── themes/ └── PaperMod/ archives.md 内容为：\n1 2 3 4 5 6 --- title: \u0026#34;Archive\u0026#34; layout: \u0026#34;archives\u0026#34; url: \u0026#34;/archives\u0026#34; summary: \u0026#34;archives\u0026#34; --- 同样在 content 新增一个 search.md，内容如下：\n1 2 3 4 5 6 7 --- title: \u0026#34;Search\u0026#34; # in any language you want layout: \u0026#34;search\u0026#34; # is necessary # url: \u0026#34;/archive\u0026#34; description: \u0026#34;Search part\u0026#34; summary: \u0026#34;search\u0026#34; --- 查看网站效果: 在项目目录c/hugo/sites/projectName 目录下输入hugo server -D\n看到一下输出, 表示可以访问 http://localhost:1313/ 查看效果，如果有其他不满意的地方，可以自行查找其他资料修改配置。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 Start building sites … hugo v0.100.0-27b077544d8efeb85867cb4cfb941747d104f765+extended windows/amd64 BuildDate=2022-05-31T08:37:12Z VendorInfo=gohugoio | EN -------------------+----- Pages | 20 Paginator pages | 0 Non-page files | 0 Static files | 0 Processed images | 0 Aliases | 2 Sitemaps | 1 Cleaned | 0 Built in 98 ms Watching for changes in C:\\Hugo\\sites\\Reid00.github.io.source\\{archetypes,content,data,layouts,static,themes} Watching for config changes in C:\\Hugo\\sites\\Reid00.github.io.source\\config.yaml Environment: \u0026#34;development\u0026#34; Serving pages from memory Running in Fast Render Mode. For full rebuilds on change: hugo server --disableFastRender Web Server is available at http://localhost:1313/ (bind address 127.0.0.1) Press Ctrl+C to stop 效果如下：\n部署到GitHub pages 两种方式:\nhugo 命令后生成public 文件夹，将public 单独push 到.github.io 仓库 是将整个项目部署到.github.io.source 仓库，通过github action 自动部署 SSH 这里需要重新生成一对密钥，使用之前用来配置过 Github 的密钥不能在这里使用啦，会报错提示已经被使用过啦。\n1 2 3 4 5 6 7 8 9 10 ssh-keygen -t rsa - -C \u0026#34;$(git config user.email)\u0026#34; # 注意：这次不要直接回车，以免覆盖之前生成的 # 确认秘钥的保存路径（如果不需要改路径则直接回车）；如果已经有秘钥文件，则需要换一个路径，避免覆盖掉，如我更改之后的路径为 /home/kearney/.ssh_action/id_rsa； # 创建密码（如果不需要密码则直接回车）； # 确认密码（如果不需要密码则直接回车），生成结束； # 查看公钥，路径需要改为你上面的设置 cat ~/.ssh_action/id_rsa.pub # 查看私钥 cat ~/.ssh_action/id_rsa Page 仓库 Reid00/ Reid00.github.io 中，点击 Setting - Deploy keys - Add deploy key，名称随意，粘贴进去刚生成的公钥，务必勾选 Allow write access 。点击保存。\n源码仓库 Reid00/ Reid00.github.io.source 。点击 Setting - Secrets - New repo secrets ，名称务必设置为 ACTIONS_DEPLOY_KEY， 添加刚刚生成的私钥(id_rsa)，变量名称是要在 action 的配置文件中使用的，因此要保持统一，可修改为别的名称，但要相同即可。\n将项目hello-hugo 推送到 Reid00.github.io.source 仓库 讲到这里突然发现还没有讲，把项目推送到github，方式如下:\n此处本质就是用git 创建项目，推送到Github 如果出现错误，请自行搜索排查。\n1 2 3 4 5 6 git init git remote add origin git@github.com:Reid00/Reid00.github.io.source.git git add . git commit -m \u0026#39;init\u0026#39; git push -f --set-upstream origin master 配置 Github Action 在源码跟目录下新建 /.github/workflows/github-actions-demo.yml，内容如下，需要更改的地方为 Page 仓库、分支。\nyml push 上去之后，再更新下文章，直接 push 源码，后台就会自动生成并发布到 Page 仓库。\n测试良好，但也发现了一些问题，本人对 Action 了解不够深，猜测是 yml 没抄好。一个问题是源码仓库中 public 指向的网页仓库的 commit 标志未更新，但实际上对于的网页已经更新到 Page 中了，不过这不影响网页发布，暂不考虑解决这个问题。\n其次是我的 submodule 主题中有个在 gitee 中，需要移回到 github 并设置，还有 public 也是，那么干脆就将这些 submodule 取消掉的了，直接并入源码仓库，也不要考虑啥 commit 指针标记了。\n遇到问题 网站css 错乱\n参考此处 Fixing the CSS Integrity Digest Error in Hugo\nwindows git add 的时候LF 会用CRLF 替换，需要对git 进行设置。\n参考文章第二种方法解决\n单独 将public push 到github pages 仓库可以用，但是Github Action 推送后，Github pages 主页变成了index.xml 不是index.html，不可用?\n原因：public 里面又github pages 的.git 文件夹，会导致workflow那边submodules 出错。\n删除.git 文件夹 在与config.yaml 同级目录下添加.gitmodules 1 2 3 4 5 6 7 8 C:. │ .gitmodules │ config.yaml │ README.md [submodule \u0026#34;themes/PaperMod\u0026#34;] path = themes/PaperMod url = https://github.com/adityatelange/hugo-PaperMod.git ","permalink":"https://reid00.github.io/post/hugo%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%E5%B9%B6%E7%94%A8githubaction%E9%83%A8%E7%BD%B2/","summary":"介绍 这是我博客 Blog 的地址 和 Github Repositroy。 本博客是用Hugo 来生成静态网站。 Hugo GitHub 并通过 GitHub Action 来自动化部署到 GitHub Pages。 搭建步骤 创建代码","title":"Hugo搭建博客并用GitHubAction部署"}]