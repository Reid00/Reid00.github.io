<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>机器学习 on Reid&#39;s Blog</title>
    <link>https://reid00.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</link>
    <description>Recent content in 机器学习 on Reid&#39;s Blog</description>
    <image>
      <url>https://i.loli.net/2021/09/26/3OMGXylm8HUYJ6p.png</url>
      <link>https://i.loli.net/2021/09/26/3OMGXylm8HUYJ6p.png</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Wed, 08 Jun 2022 11:45:57 +0800</lastBuildDate><atom:link href="https://reid00.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>KG表示学习</title>
      <link>https://reid00.github.io/post/kg%E8%A1%A8%E7%A4%BA%E5%AD%A6%E4%B9%A0/</link>
      <pubDate>Wed, 08 Jun 2022 11:45:57 +0800</pubDate>
      
      <guid>https://reid00.github.io/post/kg%E8%A1%A8%E7%A4%BA%E5%AD%A6%E4%B9%A0/</guid>
      <description>一、概述 网络表示学习（Representation Learning on Network），一般说的就是向量化（Embedding）技术，简单来说，就是将网络中</description>
    </item>
    
    <item>
      <title>常用Normalization方法的总结与思考</title>
      <link>https://reid00.github.io/post/%E5%B8%B8%E7%94%A8normalization%E6%96%B9%E6%B3%95%E7%9A%84%E6%80%BB%E7%BB%93%E4%B8%8E%E6%80%9D%E8%80%83/</link>
      <pubDate>Wed, 08 Jun 2022 11:36:46 +0800</pubDate>
      
      <guid>https://reid00.github.io/post/%E5%B8%B8%E7%94%A8normalization%E6%96%B9%E6%B3%95%E7%9A%84%E6%80%BB%E7%BB%93%E4%B8%8E%E6%80%9D%E8%80%83/</guid>
      <description>简介 常用的Normalization方法主要有：Batch Normalization（BN，2015年）、Layer Normalizatio</description>
    </item>
    
    <item>
      <title>Self Attention</title>
      <link>https://reid00.github.io/post/self-attention/</link>
      <pubDate>Wed, 08 Jun 2022 11:35:50 +0800</pubDate>
      
      <guid>https://reid00.github.io/post/self-attention/</guid>
      <description>Refer ：https://blog.csdn.net/shenfuli/article/details/106523650 Multi-Head Attention: https://blog.csdn.net/qq_37394634/article/details/102679096</description>
    </item>
    
    <item>
      <title>CNN RNN GAN</title>
      <link>https://reid00.github.io/post/cnn-rnn-gan/</link>
      <pubDate>Wed, 08 Jun 2022 11:33:17 +0800</pubDate>
      
      <guid>https://reid00.github.io/post/cnn-rnn-gan/</guid>
      <description>01 全连接网络 全连接、密集和线性网络是最基本但功能强大的架构这是机器学习的直接扩展，将神经网络与单个隐藏层结合使用。全连接层充当所有架构的最后</description>
    </item>
    
    <item>
      <title>特征工程之数据预处理</title>
      <link>https://reid00.github.io/post/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B%E4%B9%8B%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/</link>
      <pubDate>Tue, 07 Jun 2022 19:09:30 +0800</pubDate>
      
      <guid>https://reid00.github.io/post/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B%E4%B9%8B%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/</guid>
      <description>Summary 数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已。由此可见，特征工程在机器学习中占有相当重要的地位。在实际应用当中，可以说</description>
    </item>
    
  </channel>
</rss>
