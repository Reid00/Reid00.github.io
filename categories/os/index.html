<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>OS | Reid's Blog</title><meta name=keywords content><meta name=description content="Reid's Personal Notes -- https://github.com/Reid00"><meta name=author content="Reid"><link rel=canonical href=https://reid00.github.io/categories/os/><link crossorigin=anonymous href=/assets/css/stylesheet.d7fb4cbf980fe688a21621b06a795933c4e6bb2d4070ec940667af1715d84af2.css integrity="sha256-1/tMv5gP5oiiFiGwanlZM8Tmuy1AcOyUBmevFxXYSvI=" rel="preload stylesheet" as=style><link rel=icon href=https://reid00.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://reid00.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://reid00.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://reid00.github.io/apple-touch-icon.png><link rel=mask-icon href=https://reid00.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://reid00.github.io/categories/os/index.xml><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-QRR6GRNQGK"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-QRR6GRNQGK",{anonymize_ip:!1})}</script><meta property="og:title" content="OS"><meta property="og:description" content="Reid's Personal Notes -- https://github.com/Reid00"><meta property="og:type" content="website"><meta property="og:url" content="https://reid00.github.io/categories/os/"><meta property="og:image" content="https://i.loli.net/2021/09/26/3OMGXylm8HUYJ6p.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://i.loli.net/2021/09/26/3OMGXylm8HUYJ6p.png"><meta name=twitter:title content="OS"><meta name=twitter:description content="Reid's Personal Notes -- https://github.com/Reid00"></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://reid00.github.io/ accesskey=h title="Reid's Blog (Alt + H)">Reid's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://reid00.github.io/archives title=Archive><span>Archive</span></a></li><li><a href=https://reid00.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://reid00.github.io/categories/ title=Categorys><span>Categorys</span></a></li><li><a href=https://reid00.github.io/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=https://reid00.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://reid00.github.io/categories/>Categories</a></div><h1>OS
<a href=index.xml title=RSS aria-label=RSS><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" height="23"><path d="M4 11a9 9 0 019 9"/><path d="M4 4a16 16 0 0116 16"/><circle cx="5" cy="19" r="1"/></svg></a></h1></header><article class="post-entry tag-entry"><header class=entry-header><h2>高并发架构</h2></header><div class=entry-content><p>介绍 什么是高并发，从字面上理解，就是在某一时刻产生大量的请求，那么多少量称为大量，业界并没有标准的衡量范围。原因非常简单，不同的业务处理复杂度不一样。
而我所理解的高并发，它并不只是一个数字，而更是一种架构思维模式，它让你在面对不同的复杂情况下，从容地选择不同的技术手段，来提升应用系统的处理能力。
但是，并不意味应用系统从诞生的那一刻，就需要具备强大的处理能力，这种做法并不提倡。要知道，脱离实际情况的技术，会显得毫无价值，甚至是一种浪费的表现。
言归正传，那高并发到底是一种怎样的架构思维模式，它对架构设计又有什么影响，以及如何通过它来驱动架构演进，让我们接着往下读，慢慢去体会这其中的精髓。
性能是一种基础 在架构设计的过程中，思考固然重要，但目标更为关键。通过目标的牵引力，可以始终确保推进方向，不会脱离成功的轨道。那高并发的目标是什么，估计你的第一反应就是性能。
没错，性能是高并发的目标之一，它不可或缺，但并不代表所有。而我将它视为是高并发的一种基础能力，它的能力高低将会直接影响到其他能力的取舍。例如：服务可用性，数据一致性等。
性能在软件研发过程中无处不在，不管是在非功能性需求中，还是在性能测试报告中，都能见到它的身影。那么如何来衡量它的高低呢，先来看看常用的性能指标。
每秒处理事务数（TPS） 每秒能够处理的事务数，其中T(Transactions)可以定义不同的含义，它可以是完整的一笔业务，也可以是单个的接口请求。
每秒请求数（RPS） 每秒请求数量，也可以叫做QPS，但它与TPS有所不同，前者注重请求能力，后者注重处理能力。不过，若所有请求都在得到响应后再次发起，那么RPS基本等于TPS。
响应时长（RT） 从发出请求到得到响应的耗时，一般可以采用毫秒单位来表示，而在一些对RT比较敏感的业务场景下，可以使用精度更高的微秒来表示。
并发用户数（VU） 同时请求的用户数，很多人将它与并发数画上等号，但两者稍有不同，前者关注客户端，后者关注服务端，除非每个用户仅发送一笔请求，且请求从客户端到服务端没有延迟，同时服务端有足够的处理线程。
以上都是些常用的性能指标，基本可以覆盖80%以上的性能衡量要求。但千万不要以单个指标的高低来衡量性能。比如：订单查询TPS=100万就认为性能很高，但RT=10秒。
这显然毫无意义。因此，建议同时观察多个指标的方式来衡量性能的高低，大多数情况下主要会关注TPS和RT，而你可以将TPS视为一种水平能力，注重并行处理能力，将RT视为一种垂直能力，注重单笔处理能力，两者缺一不可。
接触过性能测试的同学，可能会见过如下这种性能测试结果图，图中包含了刚才提到过的三个性能指标，其中横坐标为VU，纵坐标分别为TPS和RT。 图中的两条曲线，在不断增加VU的情况下，TPS不断上升，但RT保持稳定，但当VU增加到一定量级的时候，TPS开始趋于稳定，而RT不断上升。
如果你仔细观察，还会发现一个奇妙的地方，当RT=25ms时，它们三者存在着某种关系，即：TPS=VU/RT。但当RT>25ms时，这种关系似乎被打破了，这里暂时先卖个关子，稍后再说。
根据表格中的数据，性能测试报告结论：最大TPS=65000，当RT=25ms(最短)时，最大可承受VU=1500。
感觉有点不对劲，用刚才的公式来验证一下，1500/0.025s=60000，但最大却是TPS=65000。那是因为，当VU=1500时，应用系统的使用资源还有空间。
再来观察一下表格中的数据，VU从1500增加到1750时，TPS继续上升，且到了最大值65000。此时，你是不是会理解为当VU增加到1750时，使用资源被耗尽了。话虽没错，但不严谨。
注：使用资源不一定是指硬件资源，也可能是其他方面，例如：应用系统设置的最大处理线程。
其实在VU增加到1750前，使用资源就已饱和，那如何来测算VU的临界值呢。你可以将最大TPS作为已知条件，即：VU=TPS * RT，65000*0.025s=1625。也就是说，当VU=1625时，使用资源将出现瓶颈。
调整性能测试报告结论：最大TPS=65000，当RT=25ms(最短)时，最大可承受VU=1625。
有人会问，表格中的RT是不是平均值，首先回答为是。不过，高并发场景对RT会特别敏感，所以除了要考虑RT的平均值外，建议还要考虑它的分位值，例如：P99。
举例：假设1000笔请求，其中900笔RT=23ms，50笔RT=36ms，50笔RT=50ms
平均值 P99值 P95 P90 25ms 50ms 36ms 23ms P99的计算方式，是将1000笔请求的RT从小到大进行排序，然后取排在第99%位的数值，基于以上举例数据来进行计算，P99=50ms，其他分位值的计算方式类似。
再次调整性能测试报告结论：最大TPS=65000，当RT(平均)=25ms(最短)时，最大可承受VU=1625，RT(P99)=50ms，RT(P95)=36ms，RT(P90)=23ms。
在非功能性需求中，你可能会看到这样的需求，性能指标要求：RT(平均)&lt;=30。结合刚才的性能测试报告结论，当RT(平均)=25ms(最短)时，最大可承受VU=1625。那就等于在RT上还有5ms的容忍时间。
既然是这样的话，那我们不妨就继续尝试增加VU，不过RT(平均)会出现上升，但只要控制不要上升到30ms即可，这是一种通过牺牲耗时(RT)来换取并发用户数(VU)的行为。但请不要把它理解为每笔请求耗时都会上升5ms，这将是一个严重的误区。
RT(平均)的增加，完全可能是由于应用系统当前没有足够的使用资源来处理请求所造成的，例如：处理线程。如果没有可用线程可以分配给请求时，就会将这请求先放入队列，等前面的请求处理完成并释放线程后，就可以继续处理队列中的请求了。
那也就是说，没有进入队列的请求并不会增加额外的耗时，而只有进入队列的请求会增加。那么进入队列的请求会增加多少耗时呢，在理想情况下(RT恒定)，可能会是正常处理一笔请求耗时的倍数，而倍数的大小又取决于并发请求的数量。
假设最大处理线程=1625，若每个用户仅发送一笔请求，且请求从客户端到服务端没有延迟的条件下，当并发用户数=1625时，能够保证RT=25ms，但当并发用户数>1625时，因为线程只能分配给1625笔请求，那多余的请求就无法保证RT=25ms。
超过1625笔的请求会先放入队列，等前面1625笔请求处理完成后，再从队列中拿出最多1625笔请求进行下一批处理，如果队列中还有剩余请求，那就继续按照这种方式循环处理。
进入队列的请求，每等待一批就需要增加前一批的处理耗时。在理想情况下，每一批都是RT=25ms，如果这笔请求在队列中等待了两批，那就要额外增加50ms的耗时。
因此，并不能简单通过VU=TPS* RT=65000*0.03=1950来计算最大可承受VU。而是需要引入一种叫做科特尔法则(Little’s Law)的排队模型来估算，不过由于这个法则比较复杂，这里暂时不做展开。
通过粗略估算后，VU大约在2032，我们再对这个值用上述表格中再反向验算一下。 最终调整性能测试报告结论：最大TPS=65000，当RT(平均)=25(最短)时，最大可承受VU=1625，RT(P99)=50，RT(P95)=36，RT(P90)=23；当RT(平均)=30(容忍)时，(理想情况)最大可承受VU=2032，RT(P99)=RT(P95)=50，RT(P90)=25。
这就解释了为什么当RT>25ms时，VU=TPS*RT会不成立的原因。不过，这些都是在理想情况下推演出来的，实际情况会比这要复杂得多。
所以，还是尽量采用多轮性能测试来得到性能指标，这样也更具备真实性。毕竟影响性能的因素实在大多且很难完全掌控，任何细微变化都将影响性能指标的变化。
到这里，我们已经了解了可以用哪些指标来衡量性能的高低。不过，这里更想强调的是，性能是高并发的基础能力，是实现高并发的基础条件，并且你需要有侧重性地提升不同维度的性能指标，而非仅关注某一项。
限制是一种设计 上文说到，性能是高并发的目标之一。追求性能没有错，但并非永无止境。想要提升性能，势必投入成本，不过它们并不是一直成正比，而是随着成本不断增加，性能提升幅度逐渐衰减，甚至可能不再提升。所以，有时间我们要懂得适可而止。
思考一下，追求性能是为了解决什么问题，至少有一点，是为了让应用系统能够应对突发请求。换言之，如果能解决这个问题，是不是也算实现了高并发的目标。
而有时候，我们在解决问题时，不要总是习惯做加法，还可以尝试做减法，架构设计同样如此。那么，如何通过做减法的方式，来解决应对突发请求的问题呢。让我们来讲讲限制。
限制，从狭义上可以理解为是一种约束或控制能力。在软件领域中，它可以针对功能性或非功能性，而在高并发的场景中，它更偏向于非功能性。
限制应用系统的处理能力，并不代表要降低应用系统的处理能力，而是通过某些控制手段，让突发请求能够被平滑地处理，同时起到应用系统的保护能力，避免瘫痪，还能将应用系统的资源进行合理分配，避免浪费。
那么，到底有哪些控制手段，既能实现以上这些能力，又能减少对客户体验上的影响，下面就来介绍几种常用的控制手段。
第一招：限流 限流，是在一个时间窗口内，对请求进行速率控制。若请求达到提前设定的阈值时，则对请求进行排队或拒绝。常用的限流算法有两种：漏桶算法和令牌桶算法。
漏桶算法 所有请求先进入漏桶，然后按照一个恒定的速率对漏桶里的请求进行处理，是一种控制处理速率的限流方式，用于平滑突发请求速率。
它的优点是，能够确保资源不会瞬间耗尽，避免请求处理发生阻塞现象，另外，还能够保护被应用系统所调用的外部服务，也免受突发请求的冲击。
它的缺点是，对于突发请求仍然会以一个恒定的速率来进行处理，其灵活性会较弱一点，容易发生突发请求超过漏桶的容量，导致后续请求直接被丢弃。...</p></div><footer class=entry-footer><span title='2022-06-08 14:28:02 +0800 +0800'>2022-06-08</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;Reid</footer><a class=entry-link aria-label="post link to 高并发架构" href=https://reid00.github.io/posts/%E9%AB%98%E5%B9%B6%E5%8F%91%E6%9E%B6%E6%9E%84/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>拔掉网线后,原本的TCP连接还存在吗？</h2></header><div class=entry-content><p>背景 今天，聊一个有趣的问题：拔掉网线几秒，再插回去，原本的 TCP 连接还存在吗？
可能有的同学会说，网线都被拔掉了，那说明物理层被断开了，那在上层的传输层理应也会断开，所以原本的 TCP 连接就不会存在了。就好像， 我们拨打有线电话的时候，如果某一方的电话线被拔了，那么本次通话就彻底断了。
真的是这样吗？
上面这个逻辑就有问题。问题在于，错误地认为拔掉网线这个动作会影响传输层，事实上并不会影响。
实际上，TCP 连接在 Linux 内核中是一个名为 struct socket 的结构体，该结构体的内容包含 TCP 连接的状态等信息。当拔掉网线的时候，操作系统并不会变更该结构体的任何内容，所以 TCP 连接的状态也不会发生改变。
我在我的电脑上做了个小实验，我用 ssh 终端连接了我的云服务器，然后我通过断开 wifi 的方式来模拟拔掉网线的场景，此时查看 TCP 连接的状态没有发生变化，还是处于 ESTABLISHED 状态。 通过上面这个实验结果，我们知道了，拔掉网线这个动作并不会影响 TCP 连接的状态。 接下来，要看拔掉网线后，双方做了什么动作。 针对这个问题，要分场景来讨论：
拔掉网线后，有数据传输； 拔掉网线后，没有数据传输。 拔掉网线后，有数据传输 在客户端拔掉网线后，服务端向客户端发送的数据报文会得不到任何的响应，在等待一定时长后，服务端就会触发超时重传机制，重传未得到响应的数据报文。
如果在服务端重传报文的过程中，客户端刚好把网线插回去了，由于拔掉网线并不会改变客户端的 TCP 连接状态，并且还是处于 ESTABLISHED 状态，所以这时客户端是可以正常接收服务端发来的数据报文的，然后客户端就会回 ACK 响应报文。
此时，客户端和服务端的 TCP 连接依然存在，就感觉什么事情都没有发生。
但是，如果在服务端重传报文的过程中，客户端一直没有将网线插回去，服务端超时重传报文的次数达到一定阈值后，内核就会判定出该 TCP 有问题，然后通过 Socket 接口告诉应用程序该 TCP 连接出问题了，于是服务端的 TCP 连接就会断开。
而等客户端插回网线后，如果客户端向服务端发送了数据，由于服务端已经没有与客户端相同四元组的 TCP 连接了，因此服务端内核就会回复 RST 报文，客户端收到后就会释放该 TCP 连接。
此时，客户端和服务端的 TCP 连接都已经断开了。
那 TCP 的数据报文具体重传几次呢？ 在 Linux 系统中，提供了一个叫 tcp_retries2 配置项，默认值是 15，如下：...</p></div><footer class=entry-footer><span title='2022-06-08 14:26:19 +0800 +0800'>2022-06-08</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;Reid</footer><a class=entry-link aria-label="post link to 拔掉网线后,原本的TCP连接还存在吗？" href=https://reid00.github.io/posts/%E6%8B%94%E6%8E%89%E7%BD%91%E7%BA%BF%E5%90%8E%E5%8E%9F%E6%9C%AC%E7%9A%84tcp%E8%BF%9E%E6%8E%A5%E8%BF%98%E5%AD%98%E5%9C%A8%E5%90%97/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>编码那些事</h2></header><div class=entry-content><p>一直以来，编码问题像幽灵一般，不少开发人员都受过它的困扰。
试想你请求一个数据，却得到一堆乱码，丈二和尚摸不着头脑。有同事质疑你的数据是乱码，虽然你很确定传了 UTF-8 ，却也无法自证清白，更别说帮同事 debug 了。
有时，靠着百度和一手瞎调的手艺，乱码也能解决。尽管如此，还是很羡慕那些骨灰级程序员。为什么他们每次都能犀利地指出问题，并快速修复呢？原因在于，他们早就把编码问题背后的各种来龙去脉搞清楚了。
本文从 ASCII 码说起，带你扒一扒编码背后那些事。相信搞清编码的原理后，你将不再畏惧任何编码问题。
从 ASCII 码说起 现代计算机技术从英文国家兴起，最先遇到的也是英文文本。英文文本一般由 26 个字母、 10 个数字以及若干符号组成，总数也不过 100 左右。
计算机中最基本的存储单位为 字节 ( byte )，由 8 个比特位( bit )组成，也叫做 八位字节 ( octet )。8 个比特位可以表示 $ 2^8 = 256 $ 个字符，看上去用字节来存储英文字符即可？
计算机先驱们也是这么想的。他们为每个英文字符编号，再加上一些控制符，形成了我们所熟知的 ASCII 码表。实际上，由于英文字符不多，他们只用了字节的后 7 位而已。
根据 ASCII 码表，由 01000001 这 8 个比特位组成的八位字节，代表字母 A 。
顺便提一下，比特本身没有意义，比特 在 上下文 ( context )中才构成信息。举个例子，对于内存中一个字节 01000001 ，你将它看做一个整数，它就是 65 ；将它作为一个英文字符，它就是字母 A ；你看待比特的方式，就是所谓的上下文。
所以，猜猜下面这个程序输出啥？
1 2 3 4 5 6 7 8 9 10 11 12 13 14 #include &lt;stdio....</p></div><footer class=entry-footer><span title='2022-06-08 11:40:53 +0800 +0800'>2022-06-08</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;Reid</footer><a class=entry-link aria-label="post link to 编码那些事" href=https://reid00.github.io/posts/%E7%BC%96%E7%A0%81%E9%82%A3%E4%BA%9B%E4%BA%8B/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>TCP IP协议</h2></header><div class=entry-content><p>TCP/IP 协议族 通常我说 TCP/IP 是指 TCP/IP 协议族。它是基于 TCP 和 IP 这两个最初的协议之上的不同的通信协议的大集合。 例如：http、https、ftp、icmp、arp、rarp、smtp（简单邮件传输协议）
当输入 xxxxHub 后，到网页显示，其间发生了什么？这问题被面试官问了五六十次，熬夜赶出这篇文章
https://mp.weixin.qq.com/s/ESJ8Zt0GBVXHKj3KICoqjg
一个网络请求是怎么传输的？ 我们拿访问浏览器举个栗子，如图所示：
TCP、UDP有什么区别？各有什么优劣？ TCP 面向连接，提供可靠交付。通过 TCP 连接传输的数据，无差错、不丢失、不重复、并且按序到达。相对 UDP 开销大 UDP 面向无连接，不保证可靠交付。无拥塞控制，支持一对一、一对多、多对多，开销小。
关于 TCP 协议 确认 ACK - ACKnowledgement 仅当ACK = 1 时，确认才有效。简单来说，就是确认收到数据。 复位 RST - ReSet 标明 TCP 出现严重差错时，必须释放连接，重新建立连接。 同步 SYN - SYNchronization 在建立连接时，用来同步序号。当 SYN = 1，ACK = 0 时，表名这是一个连接请求报文。SYN = 1，ACK = 1 表示这是一个同意请求报文。 终止 FNI - FINis（表示终、完）用来释放连接。当 FNI = 1 表示此段报文发送方已发送完毕。 关于 UDP 协议 解释三次握手 确认号 ack 期望收到对方下一个报文的序列号...</p></div><footer class=entry-footer><span title='2022-06-08 11:39:22 +0800 +0800'>2022-06-08</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;Reid</footer><a class=entry-link aria-label="post link to TCP IP协议" href=https://reid00.github.io/posts/tcp-ip%E5%8D%8F%E8%AE%AE/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>进程与线程基础知识</h2></header><div class=entry-content><p>前言 先来看看一则小故事
我们写好的一行行代码，为了让其工作起来，我们还得把它送进城（进程）里，那既然进了城里，那肯定不能胡作非为了。
城里人有城里人的规矩，城中有个专门管辖你们的城管（操作系统），人家让你休息就休息，让你工作就工作，毕竟摊位（CPU）就一个，每个人都要占这个摊位来工作，城里要工作的人多着去了。
所以城管为了公平起见，它使用一种策略（调度）方式，给每个人一个固定的工作时间（时间片），时间到了就会通知你去休息而换另外一个人上场工作。
另外，在休息时候你也不能偷懒，要记住工作到哪了，不然下次到你工作了，你忘记工作到哪了，那还怎么继续？
有的人，可能还进入了县城（线程）工作，这里相对轻松一些，在休息的时候，要记住的东西相对较少，而且还能共享城里的资源。
“哎哟，难道本文内容是进程和线程？”
可以，聪明的你猜出来了，也不枉费我瞎编乱造的故事了。
进程和线程对于写代码的我们，真的天天见、日日见了，但见的多不代表你就熟悉它们，比如简单问你一句，你知道它们的工作原理和区别吗？
不知道没关系，今天就要跟大家讨论操作系统的进程和线程。
提纲
正文 进程 我们编写的代码只是一个存储在硬盘的静态文件，通过编译后就会生成二进制可执行文件，当我们运行这个可执行文件后，它会被装载到内存中，接着 CPU 会执行程序中的每一条指令，那么这个运行中的程序，就被称为「进程」。
现在我们考虑有一个会读取硬盘文件数据的程序被执行了，那么当运行到读取文件的指令时，就会去从硬盘读取数据，但是硬盘的读写速度是非常慢的，那么在这个时候，如果 CPU 傻傻的等硬盘返回数据的话，那 CPU 的利用率是非常低的。
做个类比，你去煮开水时，你会傻傻的等水壶烧开吗？很明显，小孩也不会傻等。我们可以在水壶烧开之前去做其他事情。当水壶烧开了，我们自然就会听到“嘀嘀嘀”的声音，于是再把烧开的水倒入到水杯里就好了。
所以，当进程要从硬盘读取数据时，CPU 不需要阻塞等待数据的返回，而是去执行另外的进程。当硬盘数据返回时，CPU 会收到个中断，于是 CPU 再继续运行这个进程。
进程 1 与进程 2 切换
这种多个程序、交替执行的思想，就有 CPU 管理多个进程的初步想法。
对于一个支持多进程的系统，CPU 会从一个进程快速切换至另一个进程，其间每个进程各运行几十或几百个毫秒。
虽然单核的 CPU 在某一个瞬间，只能运行一个进程。但在 1 秒钟期间，它可能会运行多个进程，这样就产生并行的错觉，实际上这是并发。
并发和并行有什么区别？
一图胜千言。
并发与并行
进程与程序的关系的类比
到了晚饭时间，一对小情侣肚子都咕咕叫了，于是男生见机行事，就想给女生做晚饭，所以他就在网上找了辣子鸡的菜谱，接着买了一些鸡肉、辣椒、香料等材料，然后边看边学边做这道菜。
突然，女生说她想喝可乐，那么男生只好把做菜的事情暂停一下，并在手机菜谱标记做到哪一个步骤，把状态信息记录了下来。
然后男生听从女生的指令，跑去下楼买了一瓶冰可乐后，又回到厨房继续做菜。
这体现了，CPU 可以从一个进程（做菜）切换到另外一个进程（买可乐），在切换前必须要记录当前进程中运行的状态信息，以备下次切换回来的时候可以恢复执行。
所以，可以发现进程有着「运行 - 暂停 - 运行」的活动规律。
进程的状态 在上面，我们知道了进程有着「运行 - 暂停 - 运行」的活动规律。一般说来，一个进程并不是自始至终连续不停地运行的，它与并发执行中的其他进程的执行是相互制约的。
它有时处于运行状态，有时又由于某种原因而暂停运行处于等待状态，当使它暂停的原因消失后，它又进入准备运行状态。
所以，在一个进程的活动期间至少具备三种基本状态，即运行状态、就绪状态、阻塞状态。
进程的三种基本状态
上图中各个状态的意义：
运行状态（Runing）：该时刻进程占用 CPU； 就绪状态（Ready）：可运行，但因为其他进程正在运行而暂停停止； 阻塞状态（Blocked）：该进程正在等待某一事件发生（如等待输入/输出操作的完成）而暂时停止运行，这时，即使给它CPU控制权，它也无法运行； 当然，进程另外两个基本状态：...</p></div><footer class=entry-footer><span title='2022-06-08 11:28:07 +0800 +0800'>2022-06-08</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;Reid</footer><a class=entry-link aria-label="post link to 进程与线程基础知识" href=https://reid00.github.io/posts/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/></a></article></main><footer class=footer><span>&copy; 2022 <a href=https://reid00.github.io/>Reid's Blog</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>