<!doctype html><html lang=en dir=auto><head><meta name=generator content="Hugo 0.125.2"><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Reid's Blog</title>
<meta name=description content="Reid's Personal Notes -- https://github.com/Reid00"><meta name=author content="Reid"><link rel=canonical href=https://reid00.github.io/en/><link crossorigin=anonymous href=/assets/css/stylesheet.d7fb4cbf980fe688a21621b06a795933c4e6bb2d4070ec940667af1715d84af2.css integrity="sha256-1/tMv5gP5oiiFiGwanlZM8Tmuy1AcOyUBmevFxXYSvI=" rel="preload stylesheet" as=style><link rel=icon href=https://reid00.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://reid00.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://reid00.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://reid00.github.io/apple-touch-icon.png><link rel=mask-icon href=https://reid00.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://reid00.github.io/en/index.xml><link rel=alternate type=application/json href=https://reid00.github.io/en/index.json><link rel=alternate hreflang=en href=https://reid00.github.io/en/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><head><meta name=referrer content="no-referrer"></head><script async src="https://www.googletagmanager.com/gtag/js?id=G-QRR6GRNQGK"></script><script>var doNotTrack=!1,dnt;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-QRR6GRNQGK")}</script><meta property="og:title" content="Reid's Blog"><meta property="og:description" content="Reid's Personal Notes -- https://github.com/Reid00"><meta property="og:type" content="website"><meta property="og:url" content="https://reid00.github.io/en/"><meta property="og:image" content="https://i.loli.net/2021/09/26/3OMGXylm8HUYJ6p.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://i.loli.net/2021/09/26/3OMGXylm8HUYJ6p.png"><meta name=twitter:title content="Reid's Blog"><meta name=twitter:description content="Reid's Personal Notes -- https://github.com/Reid00"><script type=application/ld+json>{"@context":"https://schema.org","@type":"Organization","name":"Reid's Blog","url":"https://reid00.github.io/","description":"Reid\u0026#39;s Personal Notes -- https://github.com/Reid00","thumbnailUrl":"https://reid00.github.io/favicon.ico","sameAs":["https://github.com/Reid00","https://twitter.com","index.xml"]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://reid00.github.io/en/ accesskey=h title="Reid's Blog (Alt + H)">Reid's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li></ul></div></div><ul id=menu><li><a href=https://reid00.github.io/en/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://reid00.github.io/en/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://reid00.github.io/en/categories/ title=Categorys><span>Categorys</span></a></li><li><a href=https://reid00.github.io/en/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-entry><header class=entry-header><h2>CNN RNN GAN</h2></header><div class=entry-content><p>01 全连接网络 全连接、密集和线性网络是最基本但功能强大的架构这是机器学习的直接扩展，将神经网络与单个隐藏层结合使用。全连接层充当所有架构的最后一部分，用于获得使用下方深度网络所得分数的概率分布。
**如其名称所示，全连接网络将其上一层和下一层中的所有神经元相互连接。**网络可能最终通过设置权重来关闭一些神经元，但在理想情况下，最初所有神经元都参与训练。
02 编码器和解码器 编码器和解码器可能是深度学习另一个最基本的架构之一。所有网络都有一个或多个编码器–解码器层。你可以将全连接层中的隐藏层视为来自编码器的编码形式，将输出层视为解码器，它将隐藏层解码并作为输出。通常，编码器将输入编码到中间状态，其中输入为向量，然后解码器网络将该中间状态解码为我们想要的输出形式。
编码器–解码器网络的一个规范示例是序列到序列 （seq2seq）网络（图1.11），可用于机器翻译。一个句子将被编码为中间向量表示形式，其中整个句子以一些浮点数字的形式表示，解码器根据中间向量解码以生成目标语言的句子作为输出。
▲图1.11 seq2seq 网络
自动编码器（图1.12）是一种特殊的编码器–解码器网络，属于无监督学习范畴。自动编码器尝试从未标记的数据中进行学习，将目标值设置为输入值。
例如，如果输入一个大小为100×100的图像，则输入向量的维度为10 000。因此，输出的大小也将为 10 000，但隐藏层的大小可能为 500。简而言之，你正在尝试将输入转换为较小的隐藏状态表示形式，从隐藏状态重新生成相同的输入。
图1.12 自动编码器的结构
你如果能够训练一个可以做到这一点的神经网络，就会找到一个好的压缩算法，其可以将高维输入变为低维向量，这具有数量级收益。
如今，自动编码器正被广泛应用于不同的情景和行业。
03 循环神经网络 循环神经网络（RNN）是**最常见的深度学习算法之一，它席卷了整个世界。**我们现在在自然语言处理或理解方面几乎所有最先进的性能都归功于RNN的变体。在循环网络中，你尝试识别数据中的最小单元，并使数据成为一组这样的单元。
在自然语言的示例中，最常见的方法是将一个单词作为一个单元，并在处理句子时将句子视为一组单词。你在整个句子上展开RNN，一次处理一个单词（图1.13）。RNN 具有适用于不同数据集的变体，有时我们会根据效率选择变体。长短期记忆 （LSTM）和门控循环单元（GRU）是最常见的 RNN 单元。
图1.13 循环网络中单词的向量表示形式
04 递归神经网络 顾名思义，递归神经网络是一种树状网络，用于理解序列数据的分层结构。递归网络被研究者（尤其是 Salesforce 的首席科学家理查德·索彻和他的团队）广泛用于自然语言处理。
字向量能够有效地将一个单词的含义映射到一个向量空间，但当涉及整个句子的含义时，却没有像word2vec这样针对单词的首选解决方案。递归神经网络是此类应用最常用的算法之一。 递归网络可以创建解析树和组合向量，并映射其他分层关系（图1.14），这反过来又帮助我们找到组合单词和形成句子的规则。斯坦福自然语言推理小组开发了一种著名的、使用良好的算法，称为SNLI，这是应用递归网络的一个好例子。
▲图1.14 递归网络中单词的向量表示形式
05 卷积神经网络 卷积神经网络（CNN）（图1.15）使我们能够在计算机视觉中获得超人的性能，它在2010年代早期达到了人类的精度，而且其精度仍在逐年提高。
卷积网络是最容易理解的网络，因为它有可视化工具来显示每一层正在做什么。
Facebook AI研究（FAIR）负责人Yann LeCun早在20世纪90年代就发明了CNN。人们当时无法使用它，因为并没有足够的数据集和计算能力。CNN像滑动窗口一样扫描输入并生成中间表征，然后在它到达末端的全连接层之前对其进行逐层抽象。CNN也已成功应用于非图像数据集。
▲图1.15 典型的 CNN
Facebook的研究小组发现了一个基于卷积神经网络的先进自然语言处理系统，其卷积网络优于RNN，而后者被认为是任何序列数据集的首选架构。虽然一些神经科学家和人工智能研究人员不喜欢CNN（因为他们认为大脑不会像CNN那样做），但基于CNN的网络正在击败所有现有的网络实现。
06 生成对抗网络 生成对抗网络（GAN）由 Ian Goodfellow 于 2014 年发明，自那时起，它颠覆了整个 AI 社群。它是最简单、最明显的实现之一，但其能力吸引了全世界的注意。GAN的配置如图1.16所示。
▲图1.16 GAN配置 两个网络相互竞争，最终达到一种平衡，即生成网络可以生成数据，而鉴别网络很难将其与实际图像区分开。
一个真实的例子就是警察和造假者之间的斗争：假设一个造假者试图制造假币，而警察试图识破它。最初，造假者没有足够的知识来制造看起来真实的假币。随着时间的流逝，造假者越来越善于制造看起来更像真实货币的假币。这时，警察起初未能识别假币，但最终他们会再次成功识别。
这种生成–对抗过程最终会形成一种平衡。GAN 具有极大的优势。
07 强化学习 通过互动进行学习是人类智力的基础，强化学习是领导我们朝这个方向前进的方法。过去强化学习是一个完全不同的领域，它认为人类通过试错进行学习。然而，随着深度学习的推进，另一个领域出现了“深度强化学习”，它结合了深度学习与强化学习。...</p></div><footer class=entry-footer><span title='2023-03-16 19:35:16 +0800 +0800'>2023-03-16</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;76 words&nbsp;·&nbsp;Reid</footer><a class=entry-link aria-label="post link to CNN RNN GAN" href=https://reid00.github.io/en/posts/ml/cnn-rnn-gan/></a></article><article class=post-entry><header class=entry-header><h2>CTR发展</h2></header><div class=entry-content><p>简介 在推荐、搜索、广告等领域，CTR（click-through rate）预估是一项非常核心的技术，这里引用阿里妈妈资深算法专家朱小强大佬的一句话：“它（CTR预估）是镶嵌在互联网技术上的明珠”。
本篇文章主要是对CTR预估中的常见模型进行梳理与总结，并分成模块进行概述。每个模型都会从「模型结构」、「优势」、「不足」三个方面进行探讨，在最后对所有模型之间的关系进行比较与总结。本篇文章讨论的模型如下图所示（原创图），这个图中展示了本篇文章所要讲述的算法以及之间的关系，在文章的最后总结会对这张图进行详细地说明。
一. 分布式线性模型 Logistic Regression Logistic Regression是每一位算法工程师再也熟悉不过的基本算法之一了，毫不夸张地说，LR作为最经典的统计学习算法几乎统治了早期工业机器学习时代。这是因为其具备简单、时间复杂度低、可大规模并行化等优良特性。在早期的CTR预估中，算法工程师们通过手动设计交叉特征以及特征离散化等方式，赋予LR这样的线性模型对数据集的非线性学习能力，高维离散特征+手动交叉特征构成了CTR预估的基础特征。LR在工程上易于大规模并行化训练恰恰适应了这个时代的要求。
模型结构：
优势：
模型简单，具备一定可解释性 计算时间复杂度低 工程上可大规模并行化 不足：
依赖于人工大量的特征工程，例如需要根据业务背知识通过特征工程融入模型 特征交叉难以穷尽 对于训练集中没有出现的交叉特征无法进行参数学习 二. 自动化特征工程 GBDT + LR（2014）—— 特征自动化时代的初探索 Facebook在2014年提出了GBDT+LR的组合模型来进行CTR预估，其本质上是通过Boosting Tree模型本身的特征组合能力来替代原先算法工程师们手动组合特征的过程。GBDT等这类Boosting Tree模型本身具备了特征筛选能力（每次分裂选取增益最大的分裂特征与分裂点）以及高阶特征组合能力（树模型天然优势）对应树的一条路径（用叶子节点来表示），因此通过GBDT来自动生成特征向量就成了一个非常自然的思路。注意这里虽然是两个模型的组合，但实际并非是端到端的模型，而是两阶段的、解耦的，即先通过GBDT训练得到特征向量后，再作为下游LR的输入，LR的在训练过程中并不会对GBDT进行更新。
模型结构：
通过GBDT训练模型，得到组合的特征向量。例如训练了两棵树，每棵树有5个叶子结点，对于某个特定样本来说，落在了第一棵树的第3个结点，此时我们可以得到向量 ；落在第二棵树的第4个结点，此时的到向量 ；那么最终通过concat所有树的向量，得到这个样本的最终向量 。将这个向量作为下游LR模型的inputs，进行训练。
优势：
特征工程自动化，通过Boosting Tree模型的天然优势自动探索特征组合 不足：
两阶段的、非端到端的模型 CTR预估场景涉及到大量高维稀疏特征，树模型并不适合处理（因此实际上会将dense特征或者低维的离散特征给GBDT，剩余高维稀疏特征在LR阶段进行训练） GBDT模型本身比较复杂，无法做到online learning，模型对数据的感知相对较滞后（必须提高离线模型的更新频率） 由于LR善于处理离散特征，GBDT善于处理连续特征。所以也可以交由GBDT处理连续特征，输出结果拼接上离散特征一起输入LR。
三. FM模型以及变体 （1）FM：Factorization Machines, 2010 —— 隐向量学习提升模型表达 FM是在2010年提出的一种可以学习二阶特征交叉的模型，通过在原先线性模型的基础上，枚举了所有特征的二阶交叉信息后融入模型，提高了模型的表达能力。但不同的是，模型在二阶交叉信息的权重学习上，采用了隐向量内积（也可看做embedding）的方式进行学习。
FM和基于树的模型（e.g. GBDT）都能够自动学习特征交叉组合。基于树的模型适合连续中低度稀疏数据，容易学到高阶组合。但是树模型却不适合学习高度稀疏数据的特征组合，一方面高度稀疏数据的特征维度一般很高，这时基于树的模型学习效率很低，甚至不可行；另一方面树模型也不能学习到训练数据中很少或没有出现的特征组合。相反，FM模型因为通过隐向量的内积来提取特征组合，对于训练数据中很少或没有出现的特征组合也能够学习到。例如，特征 和特征 在训练数据中从来没有成对出现过，但特征 经常和特征 成对出现，特征 也经常和特征 成对出现，因而在FM模型中特征 和特征 也会有一定的相关性。毕竟所有包含特征 的训练样本都会导致模型更新特征 的隐向量 ，同理，所有包含特征 的样本也会导致模型更新隐向量 ，这样 就不太可能为0。
模型结构：
FM的公式包含了一阶线性部分与二阶特征交叉部分：
在LR中，一般是通过手动构造交叉特征后，喂给模型进行训练，例如我们构造性别与广告类别的交叉特征： (gender=’女’ & ad_category=’美妆’)，此时我们会针对这个交叉特征学习一个参数 。但是在LR中，参数梯度更新公式与该特征取值 关系密切： ，当 取值为0时，参数 就无法得到更新，而 要非零就要求交叉特征的两项都要非零，但实际在数据高度稀疏，一旦两个特征只要有一个取0，参数 不能得到有效更新；除此之外，对于训练集中没有出现的交叉特征，也没办法学习这类权重，泛化性能不够好。...</p></div><footer class=entry-footer><span title='2023-03-16 19:35:16 +0800 +0800'>2023-03-16</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;330 words&nbsp;·&nbsp;Reid</footer><a class=entry-link aria-label="post link to CTR发展" href=https://reid00.github.io/en/posts/ml/ctr%E5%8F%91%E5%B1%95/></a></article><article class=post-entry><header class=entry-header><h2>FM FFM DeepFM</h2></header><div class=entry-content><p>介绍 FM和FMM模型在数据量比较大并且特征稀疏的情况下，仍然有优秀的性能表现，在CTR/CVR任务上尤其突出。
本文包括：
- FM 模型 - FFM 模型 - Deep FM 模型 - Deep FFM模型 FM模型的引入-广告特征的稀疏性 FM（Factorization machines）模型由Steffen Rendle于2010年提出，目的是解决稀疏数据下的特征组合问题。
在介绍FM模型之前，来看看稀疏数据的训练问题。
以广告CTR（click-through rate）点击率预测任务为例，假设有如下数据
Clicked? Country Day Ad_type 1 USA 26/11/15 Movie 0 China 19/2/15 Game 1 China 26/11/15 Game 第一列Clicked是类别标记，标记用户是否点击了该广告，而其余列则是特征（这里的三个特征都是类别类型），一般的，我们会对数据进行One-hot编码将类别特征转化为数值特征，转化后数据如下:
Clicked? Country=USA Country=China Day=26/11/15 Day=19/2/15 Ad_type=Movie Ad_type=Game 1 1 0 1 0 1 0 0 0 1 0 1 0 1 1 0 1 1 0 0 1 经过One-hot编码后，特征空间是十分稀疏的。特别的，某类别特征有m种不同的取值，则one-hot编码后就会被变为m维！当类别特征越多、类别特征的取值越多，其特征空间就更加稀疏。
此外，往往我们会将特征进行两两的组合，这是因为：...</p></div><footer class=entry-footer><span title='2023-03-16 19:35:16 +0800 +0800'>2023-03-16</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;191 words&nbsp;·&nbsp;Reid</footer><a class=entry-link aria-label="post link to FM FFM DeepFM" href=https://reid00.github.io/en/posts/ml/fm-ffm-deepfm/></a></article><article class=post-entry><header class=entry-header><h2>进程与线程基础知识</h2></header><div class=entry-content><p>前言 先来看看一则小故事
我们写好的一行行代码，为了让其工作起来，我们还得把它送进城（进程）里，那既然进了城里，那肯定不能胡作非为了。
城里人有城里人的规矩，城中有个专门管辖你们的城管（操作系统），人家让你休息就休息，让你工作就工作，毕竟摊位（CPU）就一个，每个人都要占这个摊位来工作，城里要工作的人多着去了。
所以城管为了公平起见，它使用一种策略（调度）方式，给每个人一个固定的工作时间（时间片），时间到了就会通知你去休息而换另外一个人上场工作。
另外，在休息时候你也不能偷懒，要记住工作到哪了，不然下次到你工作了，你忘记工作到哪了，那还怎么继续？
有的人，可能还进入了县城（线程）工作，这里相对轻松一些，在休息的时候，要记住的东西相对较少，而且还能共享城里的资源。
“哎哟，难道本文内容是进程和线程？”
可以，聪明的你猜出来了，也不枉费我瞎编乱造的故事了。
进程和线程对于写代码的我们，真的天天见、日日见了，但见的多不代表你就熟悉它们，比如简单问你一句，你知道它们的工作原理和区别吗？
不知道没关系，今天就要跟大家讨论操作系统的进程和线程。
提纲
正文 进程 我们编写的代码只是一个存储在硬盘的静态文件，通过编译后就会生成二进制可执行文件，当我们运行这个可执行文件后，它会被装载到内存中，接着 CPU 会执行程序中的每一条指令，那么这个运行中的程序，就被称为「进程」。
现在我们考虑有一个会读取硬盘文件数据的程序被执行了，那么当运行到读取文件的指令时，就会去从硬盘读取数据，但是硬盘的读写速度是非常慢的，那么在这个时候，如果 CPU 傻傻的等硬盘返回数据的话，那 CPU 的利用率是非常低的。
做个类比，你去煮开水时，你会傻傻的等水壶烧开吗？很明显，小孩也不会傻等。我们可以在水壶烧开之前去做其他事情。当水壶烧开了，我们自然就会听到“嘀嘀嘀”的声音，于是再把烧开的水倒入到水杯里就好了。
所以，当进程要从硬盘读取数据时，CPU 不需要阻塞等待数据的返回，而是去执行另外的进程。当硬盘数据返回时，CPU 会收到个中断，于是 CPU 再继续运行这个进程。
进程 1 与进程 2 切换
这种多个程序、交替执行的思想，就有 CPU 管理多个进程的初步想法。
对于一个支持多进程的系统，CPU 会从一个进程快速切换至另一个进程，其间每个进程各运行几十或几百个毫秒。
虽然单核的 CPU 在某一个瞬间，只能运行一个进程。但在 1 秒钟期间，它可能会运行多个进程，这样就产生并行的错觉，实际上这是并发。
并发和并行有什么区别？
一图胜千言。
并发与并行
进程与程序的关系的类比
到了晚饭时间，一对小情侣肚子都咕咕叫了，于是男生见机行事，就想给女生做晚饭，所以他就在网上找了辣子鸡的菜谱，接着买了一些鸡肉、辣椒、香料等材料，然后边看边学边做这道菜。
突然，女生说她想喝可乐，那么男生只好把做菜的事情暂停一下，并在手机菜谱标记做到哪一个步骤，把状态信息记录了下来。
然后男生听从女生的指令，跑去下楼买了一瓶冰可乐后，又回到厨房继续做菜。
这体现了，CPU 可以从一个进程（做菜）切换到另外一个进程（买可乐），在切换前必须要记录当前进程中运行的状态信息，以备下次切换回来的时候可以恢复执行。
所以，可以发现进程有着「运行 - 暂停 - 运行」的活动规律。
进程的状态 在上面，我们知道了进程有着「运行 - 暂停 - 运行」的活动规律。一般说来，一个进程并不是自始至终连续不停地运行的，它与并发执行中的其他进程的执行是相互制约的。
它有时处于运行状态，有时又由于某种原因而暂停运行处于等待状态，当使它暂停的原因消失后，它又进入准备运行状态。
所以，在一个进程的活动期间至少具备三种基本状态，即运行状态、就绪状态、阻塞状态。
进程的三种基本状态
上图中各个状态的意义：
运行状态（Runing）：该时刻进程占用 CPU； 就绪状态（Ready）：可运行，但因为其他进程正在运行而暂停停止； 阻塞状态（Blocked）：该进程正在等待某一事件发生（如等待输入/输出操作的完成）而暂时停止运行，这时，即使给它CPU控制权，它也无法运行； 当然，进程另外两个基本状态：...</p></div><footer class=entry-footer><span title='2023-03-16 19:35:15 +0800 +0800'>2023-03-16</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;719 words&nbsp;·&nbsp;Reid</footer><a class=entry-link aria-label="post link to 进程与线程基础知识" href=https://reid00.github.io/en/posts/os_network/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/></a></article><article class=post-entry><header class=entry-header><h2>高并发架构</h2></header><div class=entry-content><p>介绍 什么是高并发，从字面上理解，就是在某一时刻产生大量的请求，那么多少量称为大量，业界并没有标准的衡量范围。原因非常简单，不同的业务处理复杂度不一样。
而我所理解的高并发，它并不只是一个数字，而更是一种架构思维模式，它让你在面对不同的复杂情况下，从容地选择不同的技术手段，来提升应用系统的处理能力。
但是，并不意味应用系统从诞生的那一刻，就需要具备强大的处理能力，这种做法并不提倡。要知道，脱离实际情况的技术，会显得毫无价值，甚至是一种浪费的表现。
言归正传，那高并发到底是一种怎样的架构思维模式，它对架构设计又有什么影响，以及如何通过它来驱动架构演进，让我们接着往下读，慢慢去体会这其中的精髓。
性能是一种基础 在架构设计的过程中，思考固然重要，但目标更为关键。通过目标的牵引力，可以始终确保推进方向，不会脱离成功的轨道。那高并发的目标是什么，估计你的第一反应就是性能。
没错，性能是高并发的目标之一，它不可或缺，但并不代表所有。而我将它视为是高并发的一种基础能力，它的能力高低将会直接影响到其他能力的取舍。例如：服务可用性，数据一致性等。
性能在软件研发过程中无处不在，不管是在非功能性需求中，还是在性能测试报告中，都能见到它的身影。那么如何来衡量它的高低呢，先来看看常用的性能指标。
每秒处理事务数（TPS） 每秒能够处理的事务数，其中T(Transactions)可以定义不同的含义，它可以是完整的一笔业务，也可以是单个的接口请求。
每秒请求数（RPS） 每秒请求数量，也可以叫做QPS，但它与TPS有所不同，前者注重请求能力，后者注重处理能力。不过，若所有请求都在得到响应后再次发起，那么RPS基本等于TPS。
响应时长（RT） 从发出请求到得到响应的耗时，一般可以采用毫秒单位来表示，而在一些对RT比较敏感的业务场景下，可以使用精度更高的微秒来表示。
并发用户数（VU） 同时请求的用户数，很多人将它与并发数画上等号，但两者稍有不同，前者关注客户端，后者关注服务端，除非每个用户仅发送一笔请求，且请求从客户端到服务端没有延迟，同时服务端有足够的处理线程。
以上都是些常用的性能指标，基本可以覆盖80%以上的性能衡量要求。但千万不要以单个指标的高低来衡量性能。比如：订单查询TPS=100万就认为性能很高，但RT=10秒。
这显然毫无意义。因此，建议同时观察多个指标的方式来衡量性能的高低，大多数情况下主要会关注TPS和RT，而你可以将TPS视为一种水平能力，注重并行处理能力，将RT视为一种垂直能力，注重单笔处理能力，两者缺一不可。
接触过性能测试的同学，可能会见过如下这种性能测试结果图，图中包含了刚才提到过的三个性能指标，其中横坐标为VU，纵坐标分别为TPS和RT。 图中的两条曲线，在不断增加VU的情况下，TPS不断上升，但RT保持稳定，但当VU增加到一定量级的时候，TPS开始趋于稳定，而RT不断上升。
如果你仔细观察，还会发现一个奇妙的地方，当RT=25ms时，它们三者存在着某种关系，即：TPS=VU/RT。但当RT>25ms时，这种关系似乎被打破了，这里暂时先卖个关子，稍后再说。
根据表格中的数据，性能测试报告结论：最大TPS=65000，当RT=25ms(最短)时，最大可承受VU=1500。
感觉有点不对劲，用刚才的公式来验证一下，1500/0.025s=60000，但最大却是TPS=65000。那是因为，当VU=1500时，应用系统的使用资源还有空间。
再来观察一下表格中的数据，VU从1500增加到1750时，TPS继续上升，且到了最大值65000。此时，你是不是会理解为当VU增加到1750时，使用资源被耗尽了。话虽没错，但不严谨。
注：使用资源不一定是指硬件资源，也可能是其他方面，例如：应用系统设置的最大处理线程。
其实在VU增加到1750前，使用资源就已饱和，那如何来测算VU的临界值呢。你可以将最大TPS作为已知条件，即：VU=TPS * RT，65000*0.025s=1625。也就是说，当VU=1625时，使用资源将出现瓶颈。
调整性能测试报告结论：最大TPS=65000，当RT=25ms(最短)时，最大可承受VU=1625。
有人会问，表格中的RT是不是平均值，首先回答为是。不过，高并发场景对RT会特别敏感，所以除了要考虑RT的平均值外，建议还要考虑它的分位值，例如：P99。
举例：假设1000笔请求，其中900笔RT=23ms，50笔RT=36ms，50笔RT=50ms
平均值 P99值 P95 P90 25ms 50ms 36ms 23ms P99的计算方式，是将1000笔请求的RT从小到大进行排序，然后取排在第99%位的数值，基于以上举例数据来进行计算，P99=50ms，其他分位值的计算方式类似。
再次调整性能测试报告结论：最大TPS=65000，当RT(平均)=25ms(最短)时，最大可承受VU=1625，RT(P99)=50ms，RT(P95)=36ms，RT(P90)=23ms。
在非功能性需求中，你可能会看到这样的需求，性能指标要求：RT(平均)&lt;=30。结合刚才的性能测试报告结论，当RT(平均)=25ms(最短)时，最大可承受VU=1625。那就等于在RT上还有5ms的容忍时间。
既然是这样的话，那我们不妨就继续尝试增加VU，不过RT(平均)会出现上升，但只要控制不要上升到30ms即可，这是一种通过牺牲耗时(RT)来换取并发用户数(VU)的行为。但请不要把它理解为每笔请求耗时都会上升5ms，这将是一个严重的误区。
RT(平均)的增加，完全可能是由于应用系统当前没有足够的使用资源来处理请求所造成的，例如：处理线程。如果没有可用线程可以分配给请求时，就会将这请求先放入队列，等前面的请求处理完成并释放线程后，就可以继续处理队列中的请求了。
那也就是说，没有进入队列的请求并不会增加额外的耗时，而只有进入队列的请求会增加。那么进入队列的请求会增加多少耗时呢，在理想情况下(RT恒定)，可能会是正常处理一笔请求耗时的倍数，而倍数的大小又取决于并发请求的数量。
假设最大处理线程=1625，若每个用户仅发送一笔请求，且请求从客户端到服务端没有延迟的条件下，当并发用户数=1625时，能够保证RT=25ms，但当并发用户数>1625时，因为线程只能分配给1625笔请求，那多余的请求就无法保证RT=25ms。
超过1625笔的请求会先放入队列，等前面1625笔请求处理完成后，再从队列中拿出最多1625笔请求进行下一批处理，如果队列中还有剩余请求，那就继续按照这种方式循环处理。
进入队列的请求，每等待一批就需要增加前一批的处理耗时。在理想情况下，每一批都是RT=25ms，如果这笔请求在队列中等待了两批，那就要额外增加50ms的耗时。
因此，并不能简单通过VU=TPS* RT=65000*0.03=1950来计算最大可承受VU。而是需要引入一种叫做科特尔法则(Little’s Law)的排队模型来估算，不过由于这个法则比较复杂，这里暂时不做展开。
通过粗略估算后，VU大约在2032，我们再对这个值用上述表格中再反向验算一下。 最终调整性能测试报告结论：最大TPS=65000，当RT(平均)=25(最短)时，最大可承受VU=1625，RT(P99)=50，RT(P95)=36，RT(P90)=23；当RT(平均)=30(容忍)时，(理想情况)最大可承受VU=2032，RT(P99)=RT(P95)=50，RT(P90)=25。
这就解释了为什么当RT>25ms时，VU=TPS*RT会不成立的原因。不过，这些都是在理想情况下推演出来的，实际情况会比这要复杂得多。
所以，还是尽量采用多轮性能测试来得到性能指标，这样也更具备真实性。毕竟影响性能的因素实在大多且很难完全掌控，任何细微变化都将影响性能指标的变化。
到这里，我们已经了解了可以用哪些指标来衡量性能的高低。不过，这里更想强调的是，性能是高并发的基础能力，是实现高并发的基础条件，并且你需要有侧重性地提升不同维度的性能指标，而非仅关注某一项。
限制是一种设计 上文说到，性能是高并发的目标之一。追求性能没有错，但并非永无止境。想要提升性能，势必投入成本，不过它们并不是一直成正比，而是随着成本不断增加，性能提升幅度逐渐衰减，甚至可能不再提升。所以，有时间我们要懂得适可而止。
思考一下，追求性能是为了解决什么问题，至少有一点，是为了让应用系统能够应对突发请求。换言之，如果能解决这个问题，是不是也算实现了高并发的目标。
而有时候，我们在解决问题时，不要总是习惯做加法，还可以尝试做减法，架构设计同样如此。那么，如何通过做减法的方式，来解决应对突发请求的问题呢。让我们来讲讲限制。
限制，从狭义上可以理解为是一种约束或控制能力。在软件领域中，它可以针对功能性或非功能性，而在高并发的场景中，它更偏向于非功能性。
限制应用系统的处理能力，并不代表要降低应用系统的处理能力，而是通过某些控制手段，让突发请求能够被平滑地处理，同时起到应用系统的保护能力，避免瘫痪，还能将应用系统的资源进行合理分配，避免浪费。
那么，到底有哪些控制手段，既能实现以上这些能力，又能减少对客户体验上的影响，下面就来介绍几种常用的控制手段。
第一招：限流 限流，是在一个时间窗口内，对请求进行速率控制。若请求达到提前设定的阈值时，则对请求进行排队或拒绝。常用的限流算法有两种：漏桶算法和令牌桶算法。
漏桶算法 所有请求先进入漏桶，然后按照一个恒定的速率对漏桶里的请求进行处理，是一种控制处理速率的限流方式，用于平滑突发请求速率。
它的优点是，能够确保资源不会瞬间耗尽，避免请求处理发生阻塞现象，另外，还能够保护被应用系统所调用的外部服务，也免受突发请求的冲击。
它的缺点是，对于突发请求仍然会以一个恒定的速率来进行处理，其灵活性会较弱一点，容易发生突发请求超过漏桶的容量，导致后续请求直接被丢弃。...</p></div><footer class=entry-footer><span title='2023-03-16 19:35:15 +0800 +0800'>2023-03-16</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;153 words&nbsp;·&nbsp;Reid</footer><a class=entry-link aria-label="post link to 高并发架构" href=https://reid00.github.io/en/posts/os_network/%E9%AB%98%E5%B9%B6%E5%8F%91%E6%9E%B6%E6%9E%84/></a></article><article class=post-entry><header class=entry-header><h2>板瓦工搭建VPS搭建vpn</h2></header><div class=entry-content><p>板瓦工以及产品介绍 该商家隶属于美国IT7公司旗下的一款便宜年付KVM架构的VPS主机商家，从2013年开始推出低价VPS主机配置进入市场，确实受到广大网友的喜欢，且在最近几年开始改变策略，取消低价配置，然后以高配置和优化线路速度。以前我们搬瓦工VPS主机的用户感觉可能并不是特别适应，因为以前喜欢他们是因为便宜，如今价格比较高，但是线路和速度比较好。
搬瓦工VPS商家支持支付宝、微信、PAYPAL、银联以及信用卡多种付款方式，这个也是很多国内用户选择的原因之一。目前最低配置是年付49.99美元，价格上肯定没有早年便宜，但是性价比在同行中还是具有一定优势的。搬瓦工VPS主机的特点在于线路还是不错的，而且带宽最高10Gbps，支持切换到其他机房，全部是自己操作。我们一定要正规使用。
**搬瓦工VPS当前库存查看列表：**https://www.laozuo.org/go/bandwagonhost-cart
搬瓦工vps主机方案分享 CN2 GIA ECOMMERCE（推荐） CPU：2核 内存：1GB 硬盘：20GB SSD 流量：1000GB 端口：2.5Gbps 架构：KVM+KiwiVM面板 IP数：1独立IP 系统：Linux 价格：$65.99/半年（购买） CPU：3核 内存：2GB 硬盘：40GB SSD 流量：2000GB 端口：2.5Gbps 架构：KVM+KiwiVM面板 IP数：1独立IP 系统：Linux 价格：$69.99/季度（购买） 这个配置方案，我们可以看到2.5Gbps带宽起步，最高达到10Gbps，同时我们可以看到一共有7个方案，根据配置不同有区别的。相比一般的配置方案，我们可以看到带宽确实比较高，而且是CN2 GIA优化线路，如果有需要大带宽方案的可以选择，而且这个方案可以切换到其他机房。
2、KVM普通线路（8机房可切CN2 GT)
CPU：2核
内存：1024MB
硬盘：20GB SSD
流量：1000GB
端口：1Gbps
架构：KVM+KiwiVM面板
IP数：1独立IP
系统：Linux
价格：$49.99/年（购买）
CPU：3核
内存：2048MB
硬盘：40GB SSD
流量：2000GB
端口：1Gbps
架构：KVM+KiwiVM面板
IP数：1独立IP
系统：Linux
价格：$27.99/季度（购买）
KVM普通方案有目前最低年付49.99方案，2018年12月份下架原来年付19.99方案。入门VPS可选方案，有8个机房可以切换，可以切换至单程CN2 GT线路。
3、CN2 GIA优化线路（三网直连双程CN2）
CPU：1核心
内存：512MB
硬盘：10GB SSD
流量：300GB
端口：1Gbps
架构：KVM+KiwiVM面板
IP数：1独立IP
系统：Linux
价格：$39.99/年（限量缺货）
CPU：2核心
内存：1024MB
硬盘：20GB SSD...</p></div><footer class=entry-footer><span title='2023-03-16 19:35:14 +0800 +0800'>2023-03-16</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;460 words&nbsp;·&nbsp;Reid</footer><a class=entry-link aria-label="post link to 板瓦工搭建VPS搭建vpn" href=https://reid00.github.io/en/posts/other/%E6%9D%BF%E7%93%A6%E5%B7%A5%E6%90%AD%E5%BB%BAvps%E6%90%AD%E5%BB%BAvpn/></a></article><article class=post-entry><header class=entry-header><h2>编码那些事</h2></header><div class=entry-content><p>一直以来，编码问题像幽灵一般，不少开发人员都受过它的困扰。
试想你请求一个数据，却得到一堆乱码，丈二和尚摸不着头脑。有同事质疑你的数据是乱码，虽然你很确定传了 UTF-8 ，却也无法自证清白，更别说帮同事 debug 了。
有时，靠着百度和一手瞎调的手艺，乱码也能解决。尽管如此，还是很羡慕那些骨灰级程序员。为什么他们每次都能犀利地指出问题，并快速修复呢？原因在于，他们早就把编码问题背后的各种来龙去脉搞清楚了。
本文从 ASCII 码说起，带你扒一扒编码背后那些事。相信搞清编码的原理后，你将不再畏惧任何编码问题。
从 ASCII 码说起 现代计算机技术从英文国家兴起，最先遇到的也是英文文本。英文文本一般由 26 个字母、 10 个数字以及若干符号组成，总数也不过 100 左右。
计算机中最基本的存储单位为 字节 ( byte )，由 8 个比特位( bit )组成，也叫做 八位字节 ( octet )。8 个比特位可以表示 $ 2^8 = 256 $ 个字符，看上去用字节来存储英文字符即可？
计算机先驱们也是这么想的。他们为每个英文字符编号，再加上一些控制符，形成了我们所熟知的 ASCII 码表。实际上，由于英文字符不多，他们只用了字节的后 7 位而已。
根据 ASCII 码表，由 01000001 这 8 个比特位组成的八位字节，代表字母 A 。
顺便提一下，比特本身没有意义，比特 在 上下文 ( context )中才构成信息。举个例子，对于内存中一个字节 01000001 ，你将它看做一个整数，它就是 65 ；将它作为一个英文字符，它就是字母 A ；你看待比特的方式，就是所谓的上下文。
所以，猜猜下面这个程序输出啥？
1 2 3 4 5 6 7 8 9 10 11 12 13 14 #include &lt;stdio....</p></div><footer class=entry-footer><span title='2023-03-16 19:35:14 +0800 +0800'>2023-03-16</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;727 words&nbsp;·&nbsp;Reid</footer><a class=entry-link aria-label="post link to 编码那些事" href=https://reid00.github.io/en/posts/langs_linux/%E7%BC%96%E7%A0%81%E9%82%A3%E4%BA%9B%E4%BA%8B/></a></article><article class=post-entry><header class=entry-header><h2>搜索引擎背后的经典数据结构和算法</h2></header><div class=entry-content><p>前言 我们每天都在用 Google, 百度这些搜索引擎，那大家有没想过搜索引擎是如何实现的呢，看似简单的搜索其实技术细节非常复杂，说搜索引擎是 IT 皇冠上的明珠也不为过，今天我们来就来简单过一下搜索引擎的原理，看看它是如何工作的，当然搜索引擎博大精深，一篇文章不可能完全介绍完，我们只会介绍它最重要的几个步骤，不过万变不离其宗，搜索引擎都离开这些重要步骤，剩下的无非是在其上添砖加瓦，所以掌握这些「关键路径」，能很好地达到观一斑而窥全貎的目的。
本文将会从以下几个部分来介绍搜索引擎，会深度剖析搜索引擎的工作原理及其中用到的一些经典数据结构和算法，相信大家看了肯定有收获。
搜索引擎系统架构图
搜索引擎工作原理详细剖析
搜索引擎系统架构图 搜索引擎整体架构图如下图所示，大致可以分为搜集，预处理，索引，查询这四步，每一步的技术细节都很多，我们将在下文中详细分析每一步的工作原理。 搜索引擎工作原理详细剖析 一、搜索 爬虫一开始是不知道该从哪里开始爬起的，所以我们可以给它一组优质种子网页的链接，比如新浪主页，腾讯主页等，这些主页比较知名，在 Alexa 排名上也非常靠前，拿到这些优质种子网页后，就对这些网页通过广度优先遍历不断遍历这些网页，爬取网页内容，提取出其中的链接，不断将其将入到待爬取队列，然后爬虫不断地从 url 的待爬取队列里提取出 url 进行爬取，重复以上过程…
当然了，只用一个爬虫是不够的，可以启动多个爬虫并行爬取，这样速度会快很多。
1、待爬取的 url 实现 待爬取 url 我们可以把它放到 Redis 里，保证了高性能，需要注意的是，Redis要开启持久化功能，这样支持断点续爬，如果 Redis 挂掉了，重启之后由于有持续久功能，可以从上一个待爬的 url 开始重新爬。
2、如何判重 如何避免网页的重复爬取呢，我们需要对 url 进行去重操作，去重怎么实现？可能有人说用散列表，将每个待抓取 url 存在散列表里，每次要加入待爬取 url 时都通过这个散列表来判断一下是否爬取过了，这样做确实没有问题，但我们需要注意到的是这样需要会出巨大的空间代价，有多大，我们简单算一下，假设有 10 亿 url （不要觉得 10 亿很大，像 Google, 百度这样的搜索引擎，它们要爬取的网页量级比 10 亿大得多），放在散列表里，需要多大存储空间呢？
我们假设每个网页 url 平均长度 64 字节，则 10 亿个 url 大约需要 60 G 内存，如果用散列表实现的话，由于散列表为了避免过多的冲突，需要较小的装载因子（假设哈希表要装载 10 个元素，实际可能要分配 20 个元素的空间，以避免哈希冲突），同时不管是用链式存储还是用红黑树来处理冲突，都要存储指针，各种这些加起来所需内存可能会超过 100 G，再加上冲突时需要在链表中比较字符串，性能上也是一个损耗，当然 100 G 对大型搜索引擎来说不是什么大问题，但其实还有一种方案可以实现远小于 100 G 的内存：布隆过滤器。...</p></div><footer class=entry-footer><span title='2023-03-16 19:35:13 +0800 +0800'>2023-03-16</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;280 words&nbsp;·&nbsp;Reid</footer><a class=entry-link aria-label="post link to 搜索引擎背后的经典数据结构和算法" href=https://reid00.github.io/en/posts/algo/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E8%83%8C%E5%90%8E%E7%9A%84%E7%BB%8F%E5%85%B8%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/></a></article><article class=post-entry><header class=entry-header><h2>数学中的十大悖论</h2></header><div class=entry-content><p>常见反直觉定理 生日悖论 假设房间里有23人，那么两个人生日是同天的概率将大于50%。我们很容易得出，任何一个特定的日子里某人过生日的概率是1/365。
所以这个理论看似是无法成立，但理论与现实差异正源自于：我们的唯一要求是两个人彼此拥有同一天生日即可，不限定在特定的一天。 否则，如果换做某人在某特定日期生日，例如2月19日，那么23个人中概率便仅为6.12%。
另一方面如果你在有23个人的房间挑选一人问他：“有人和你同一天生日吗？”答案很可能是否定的。 但如果重复询问其余22人，每问一次，你便会有更大机会得到肯定答复，最终这个概率是50.7%。 结论 当房间里有23人，那么存在生日相同的概率超过50%, 如果有60人，则超过99%
生日悖论的应用 日悖论普遍的应用于检测哈希函数：N 位长度的哈希表可能发生碰撞测试次数不是 2N 次而是只有 2N/2 次。这一结论被应用到破解密码哈希函数 (cryptographic hash function) 的 “生日攻击” 中。 生日问题所隐含的理论已经在 [Schnabel 1938] 名字叫做 “标记重捕法” (capture-recapture) 的统计试验得到应用，来估计湖里鱼的数量。 巴拿赫-塔尔斯基悖论(分球定理) 数学中，有一条极其基本的公理，叫做选择公理，许多数学内容都要基于这条定理才得以成立。 在1924年，数学家斯特·巴拿赫和阿尔弗莱德·塔斯基根据选择公理，得到一个奇怪的推论——分球定理。 该定理指出，一个三维实心球分成有限份，然后可以根据旋转和平移，组成和原来完全相同的两个实心球。没错，每一个和原来的一模一样。 分球定理太违反直觉，但它就是选择公理的严格推论，而且不容置疑的，除非你抛弃选择公理，但数学家会为此付出更大的代价。
在现实生活中我们没有任何办法能将一个物体凭空复制成两个。但事实上他却是成立的，这个结果似乎挑战了物理中的质量守恒定律，但似乎又是在说一个物体的质量可以凭空变为原来的两倍？ 但如若原质量是无限的话，翻倍后还是无限大，那么从这一层面出发来看这一理论也并没有打破物理法则。
有不同层次的无穷大(无穷大也有等级大小) 你可能从来想象不到，有一些无穷大比其他的无穷更大。无穷大应该被称为基数，并且一个无穷大如果比另一个无穷大拥有更大的基数，则说它比另一个无穷大要大。
在二十世纪以前，数学家们遇到无穷大都避而让之，认为要么哪里出了问题，要么结果是没有意义的。 直到1895年，康托尔建立超穷数理论，人们才得知无穷大也是有等级的，比如实数个数的无穷，就比整数个数的无穷的等级高。 还有许多关于无穷大的基数大大出乎我们的意料。举一个非常经典的例子：整数比奇数多吗？你可能会毫不犹豫的回答，那是当然！ 因为整数多出了一系列的偶数。但答案是否定的，他们拥有相同的基数，因而整数并不比奇数多。知道了这个道理，就不难回答这个问题了吧：有理数多于整数吗？不，有理数与整数相同多。 实数通常被认为是连续统，并且至今并能完全知道，是否有介于整数基数和连续统基数的无穷大？这个猜想被称为连续统猜想。
这也太违反直觉了，我们从来不把无穷大当作数，但是无穷大在超穷数理论中，却存在不同的等级。
哥德尔不完备定理 “可证”和“真”不是等价的 1931年，奥地利数学家哥德尔，提出一条震惊学术界的定理——哥德尔不完备定理。 该定理指出，我们目前的数学系统中，必定存在不能被证明也不能被证伪的定理。该定理一出，就粉碎了数学家几千年的梦想——即建立完善的数学系统，从一些基本的公理出发，推导出一切数学的定理和公式。
它的逻辑是这样的：
任何一个足够强的系统都存在一个命题，既不能被证明也不能被证伪（例如连续统假设） 任何一个足够强的系统都不能证明它自身是不推出矛盾，即便它不能被推出矛盾 以上两条定义即著名的哥德尔不完备定理。他的意义并不仅仅局限于数学，也给了我们深深地哲学启迪。
蒙提霍尔问题 三门问题亦称为蒙提霍尔问题，大致出自美国的电视游戏节目Let’s Make a Deal。问题名字来自该节目的主持人蒙提·霍尔。 参赛者会看见三扇关闭了的门，其中一扇的后面有一辆汽车，选中后面有车的那扇门可赢得该汽车，另外两扇门后面则各藏有一只山羊。 当参赛者选定了一扇门，但未去开启它的时候，节目主持人开启剩下两扇门的其中一扇，露出其中一只山羊。主持人其后会问参赛者要不要换另一扇仍然关上的门。 问题是：换另一扇门会否增加参赛者赢得汽车的机会率？ 不换门的话，赢得汽车的几率是1/3。换门的话，赢得汽车的几率是2/3。
这个问题亦被叫做蒙提霍尔悖论：虽然该问题的答案在逻辑上并不自相矛盾，但十分违反直觉。
巴塞尔问题 将自然数各自平方取倒数加在一起等于π²/6。 一般人都会觉得，左边这一坨自然数似乎和π（圆的周长与直径的比值）不会存在任何联系！然而它就这么发生了！
阿贝尔不可解定理 曼德勃罗集 德勃罗集是一个复数集，考虑函数f(z)=z²+c，c为复常数，在这为参数。 若从z=0开始不断的利用f(z)进行迭代，则凡是使得迭代结果不会跑向无穷大的c组成的集合被称为曼德勃罗集。规则不复杂，但你可能没预料到会得到这么复杂的图像。 当你放大曼德勃罗集时，你会又发现无限个小的曼德勃罗集，其中每个又亦是如此…（这种性质是分形所特有的） 这真的很契合那句俗话“大中有大，小中有小”，下面有一个关于放大他的视频，我想这绝对令人兴奋不已。 一维可以和二维甚至更高维度一一对应 按照我们的常识，二维比一维等级高，三维比四维等级高，比如线是一维的，所以线不能一一对应于面积。 但事实并非如此，康托尔证明了一维是可以一一对应高维的，也就是说一条线上的点，可以和一块面积甚至体积的点一一对应，或者说他们包含的点一样多。 证明: 在1890年，意大利数学家皮亚诺，就发明了一个函数，使得函数在实轴[0,1]上的取值，可以一一对应于单位正方形上的所有点，这条曲线叫做皮亚诺曲线。 这个性质的发现，暗示着人类对维度的主观认识，很可能是存在缺陷的。...</p></div><footer class=entry-footer><span title='2023-03-16 19:35:13 +0800 +0800'>2023-03-16</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;98 words&nbsp;·&nbsp;Reid</footer><a class=entry-link aria-label="post link to 数学中的十大悖论" href=https://reid00.github.io/en/posts/other/%E6%95%B0%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%8D%81%E5%A4%A7%E6%82%96%E8%AE%BA/></a></article><article class=post-entry><header class=entry-header><h2>常见的二进位运算技巧</h2></header><div class=entry-content><p>1. 位运算概述 从现代计算机中所有的数据二进制的形式存储在设备中。即 0、1 两种状态，计算机对二进制数据进行的运算(+、-、*、/)都是叫位运算，即将符号位共同参与运算的运算。
1 2 3 int a = 35; int b = 47; int c = a + b; 实际上运算如下: 计算两个数的和，因为在计算机中都是以二进制来进行运算，所以上面我们所给的 int 变量会在机器内部先转换为二进制在进行相加：
1 2 3 4 35: 0 0 1 0 0 0 1 1 47: 0 0 1 0 1 1 1 1 ———————————————————— 82: 0 1 0 1 0 0 1 0 所以，相比在代码中直接使用(+、-、*、/)运算符，合理的运用位运算更能显著提高代码在机器上的执行效率。
2. 位运算概览 3. 按位与运算符 定义：参加运算的两个数据，按二进制位进行"与"运算。 运算规则：
1 0&amp;0=0 0&amp;1=0 1&amp;0=0 1&amp;1=1 ==总结：两位同时为1，结果才为1，否则结果为0。==...</p></div><footer class=entry-footer><span title='2023-03-16 19:35:12 +0800 +0800'>2023-03-16</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;267 words&nbsp;·&nbsp;Reid</footer><a class=entry-link aria-label="post link to 常见的二进位运算技巧" href=https://reid00.github.io/en/posts/algo/%E5%B8%B8%E8%A7%81%E7%9A%84%E4%BA%8C%E8%BF%9B%E4%BD%8D%E8%BF%90%E7%AE%97%E6%8A%80%E5%B7%A7/></a></article><footer class=page-footer><nav class=pagination><a class=prev href=https://reid00.github.io/en/page/5/>« Prev</a>
<a class=next href=https://reid00.github.io/en/page/7/>Next »</a></nav></footer></main><footer class=footer><span>&copy; 2024 <a href=https://reid00.github.io/en/>Reid's Blog</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>