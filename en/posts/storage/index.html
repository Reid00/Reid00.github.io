<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>存储, 分布式相关的文章 | Reid's Blog</title><meta name=keywords content><meta name=description content="存储, 分布式相关的文章 - Reid's Blog"><meta name=author content="Reid"><link rel=canonical href=https://reid00.github.io/en/posts/storage/><link crossorigin=anonymous href=/assets/css/stylesheet.d7fb4cbf980fe688a21621b06a795933c4e6bb2d4070ec940667af1715d84af2.css integrity="sha256-1/tMv5gP5oiiFiGwanlZM8Tmuy1AcOyUBmevFxXYSvI=" rel="preload stylesheet" as=style><link rel=icon href=https://reid00.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://reid00.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://reid00.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://reid00.github.io/apple-touch-icon.png><link rel=mask-icon href=https://reid00.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://reid00.github.io/en/posts/storage/index.xml><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><head><meta name=referrer content="no-referrer"></head><script async src="https://www.googletagmanager.com/gtag/js?id=G-QRR6GRNQGK"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-QRR6GRNQGK",{anonymize_ip:!1})}</script><meta property="og:title" content="存储, 分布式相关的文章"><meta property="og:description" content="Reid's Personal Notes -- https://github.com/Reid00"><meta property="og:type" content="website"><meta property="og:url" content="https://reid00.github.io/en/posts/storage/"><meta property="og:image" content="https://i.loli.net/2021/09/26/3OMGXylm8HUYJ6p.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://i.loli.net/2021/09/26/3OMGXylm8HUYJ6p.png"><meta name=twitter:title content="存储, 分布式相关的文章"><meta name=twitter:description content="Reid's Personal Notes -- https://github.com/Reid00"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://reid00.github.io/en/posts/"},{"@type":"ListItem","position":2,"name":"存储, 分布式相关的文章","item":"https://reid00.github.io/en/posts/storage/"}]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://reid00.github.io/en/ accesskey=h title="Reid's Blog (Alt + H)">Reid's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://reid00.github.io/en/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://reid00.github.io/en/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://reid00.github.io/en/categories/ title=Categorys><span>Categorys</span></a></li><li><a href=https://reid00.github.io/en/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=https://reid00.github.io/en/>Home</a>&nbsp;»&nbsp;<a href=https://reid00.github.io/en/posts/>Posts</a></div><h1>存储, 分布式相关的文章
<a href=index.xml title=RSS aria-label=RSS><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" height="23"><path d="M4 11a9 9 0 019 9"/><path d="M4 4a16 16 0 0116 16"/><circle cx="5" cy="19" r="1"/></svg></a></h1></header><article class=post-entry><header class=entry-header><h2>Zookeeper一致保证</h2></header><div class=entry-content><p>Zookpeer 的先行一致性介绍 Zookeeper的确有一些一致性的保证，用来帮助那些使用基于Zookeeper开发应用程序的人，来理解他们的应用程序，以及理解当他们运行程序时，会发生什么。与线性一致一样，这些保证与序列有关。Zookeeper有两个主要的保证，它们在论文的2.3有提及。
写请求是线性一致的。 现在，你可以发现，它（Zookeeper）对于线性一致的定义与我的不太一样，因为Zookeeper只考虑写，不考虑读。这里的意思是，尽管客户端可以并发的发送写请求，然后Zookeeper表现的就像以某种顺序，一次只执行一个写请求，并且也符合写请求的实际时间。所以如果一个写请求在另一个写请求开始前就结束了，那么Zookeeper实际上也会先执行第一个写请求，再执行第二个写请求。所以，这里不包括读请求，单独看写请求是线性一致的。 Zookeeper并不是一个严格的读写系统。写请求通常也会跟着读请求。对于这种混合的读写请求，任何更改状态的操作相比其他更改状态的操作，都是线性一致的。
FIFO（First In First Out）客户端序列。 Zookeeper的另一个保证是，任何一个客户端的请求，都会按照客户端指定的顺序来执行，论文里称之为FIFO（First In First Out）客户端序列。
这里的意思是，如果一个特定的客户端发送了一个写请求之后是一个读请求或者任意请求，那么首先，所有的写请求会以这个客户端发送的相对顺序，加入到所有客户端的写请求中（满足保证1）。所以，如果一个客户端说，先完成这个写操作，再完成另一个写操作，之后是第三个写操作，那么在最终整体的写请求的序列中，可以看到这个客户端的写请求以相同顺序出现（虽然可能不是相邻的）。所以，对于写请求，最终会以客户端确定的顺序执行。
这里实际上是服务端需要考虑的问题，因为客户端是可以发送异步的写请求，也就是说客户端可以发送多个写请求给Zookeeper Leader节点，而不用等任何一个请求完成。Zookeeper论文并没有明确说明，但是可以假设，为了让Leader可以实际的按照客户端确定的顺序执行写请求，我设想，客户端实际上会对它的写请求打上序号，表明它先执行这个，再执行这个，第三个是这个，而Zookeeper Leader节点会遵从这个顺序。这里由于有这些异步的写请求变得非常有意思。
读请求 对于读请求，这里会更加复杂一些。我之前说过，读请求不需要经过Leader，只有写请求经过Leader，读请求只会到达某个副本。所以，读请求只能看到那个副本的Log对应的状态。对于读请求，我们应该这么考虑FIFO客户端序列，客户端会以某种顺序读某个数据，之后读第二个数据，之后是第三个数据，对于那个副本上的Log来说，每一个读请求必然要在Log的某个特定的点执行，或者说每个读请求都可以在Log一个特定的点观察到对应的状态。
然后，后续的读请求，必须要在不早于当前读请求对应的Log点执行。也就是一个客户端发起了两个读请求，如果第一个读请求在Log中的一个位置执行，那么第二个读请求只允许在第一个读请求对应的位置或者更后的位置执行。 第二个读请求不允许看到之前的状态，第二个读请求至少要看到第一个读请求的状态。这是一个极其重要的事实，我们会用它来实现正确的Zookeeper应用程序。
这里特别有意思的是，如果一个客户端正在与一个副本交互，客户端发送了一些读请求给这个副本，之后这个副本故障了，客户端需要将读请求发送给另一个副本。这时，尽管客户端切换到了一个新的副本，FIFO客户端序列仍然有效。所以这意味着，如果你知道在故障前，客户端在一个副本执行了一个读请求并看到了对应于Log中这个点的状态，
客户端请求副本发生变化 当客户端切换到了一个新的副本并且发起了另一个读请求，假设之前的读请求在这里执行， 那么尽管客户端切换到了一个新的副本，客户端的在新的副本的读请求，必须在Log这个点或者之后的点执行。
这里工作的原理是，每个Log条目都会被Leader打上zxid的标签，这些标签就是Log对应的条目号。任何时候一个副本回复一个客户端的读请求，首先这个读请求是在Log的某个特定点执行的，其次回复里面会带上zxid，对应的就是Log中执行点的前一条Log条目号。客户端会记住最高的zxid，当客户端发出一个请求到一个相同或者不同的副本时，它会在它的请求中带上这个最高的zxid。这样，其他的副本就知道，应该至少在Log中这个点或者之后执行这个读请求。这里有个有趣的场景，如果第二个副本并没有最新的Log，当它从客户端收到一个请求，客户端说，上一次我的读请求在其他副本Log的这个位置执行，
那么在获取到对应这个位置的Log之前，这个副本不能响应客户端请求。
我不是很清楚这里具体怎么工作，但是要么副本阻塞了对于客户端的响应，要么副本拒绝了客户端的读请求并说：我并不了解这些信息，去问问其他的副本，或者过会再来问我。 最终，如果这个副本连上了Leader，它会更新上最新的Log，到那个时候，这个副本就可以响应读请求了。好的，所以读请求都是有序的，它们的顺序与时间正相关。
更进一步，FIFO客户端请求序列是对一个客户端的所有读请求，写请求生效。所以，如果我发送一个写请求给Leader，在Leader commit这个请求之前需要消耗一些时间，所以我现在给Leader发了一个写请求，而Leader还没有处理完它，或者commit它。之后，我发送了一个读请求给某个副本。这个读请求需要暂缓一下，以确保FIFO客户端请求序列。读请求需要暂缓，直到这个副本发现之前的写请求已经执行了。这是FIFO客户端请求序列的必然结果，（对于某个特定的客户端）读写请求是线性一致的。
最明显的理解这种行为的方式是，如果一个客户端写了一份数据，例如向Leader发送了一个写请求，之后立即读同一份数据，并将读请求发送给了某一个副本，那么客户端需要看到自己刚刚写入的值。如果我写了某个变量为17，那么我之后读这个变量，返回的不是17，这会很奇怪，这表明系统并没有执行我的请求。因为如果执行了的话，写请求应该在读请求之前执行。所以，副本必然有一些有意思的行为来暂缓客户端，比如当客户端发送一个读请求说，我上一次发送给Leader的写请求对应了zxid是多少，这个副本必须等到自己看到对应zxid的写请求再执行读请求。
学生提问 学生提问：也就是说，从Zookeeper读到的数据不能保证是最新的？ Robert教授：完全正确。我认为你说的是，从一个副本读取的或许不是最新的数据，所以Leader或许已经向过半服务器发送了C，并commit了，过半服务器也执行了这个请求。但是这个副本并不在Leader的过半服务器中，所以或许这个副本没有最新的数据。这就是Zookeeper的工作方式，它并不保证我们可以看到最新的数据。Zookeeper可以保证读写有序，但是只针对一个客户端来说。所以，如果我发送了一个写请求，之后我读取相同的数据，Zookeeper系统可以保证读请求可以读到我之前写入的数据。但是，如果你发送了一个写请求，之后我读取相同的数据，并没有保证说我可以看到你写入的数据。这就是Zookeeper可以根据副本的数量加速读请求的基础。
学生提问：那么Zookeeper究竟是不是线性一致呢？ Robert教授：我认为Zookeeper不是线性一致的，但是又不是完全的非线性一致。首先，所有客户端发送的请求以一个特定的序列执行，所以，某种意义上来说，所有的写请求是线性一致的。同时，每一个客户端的所有请求或许也可以认为是线性一致的。尽管我不是很确定，Zookeeper的一致性保证的第二条可以理解为，单个客户端的请求是线性一致的。
学生提问：zxid必须要等到写请求执行完成才返回吗？ Robert教授：实际上，我不知道它具体怎么工作，但是这是个合理的假设。当我发送了异步的写请求，系统并没有执行这些请求，但是系统会回复我说，好的，我收到了你的写请求，如果它最后commit了，这将会是对应的zxid。所以这里是一个合理的假设，我实际上不知道这里怎么工作。之后如果客户端执行读请求，就可以告诉一个副本说，这个zxid是我之前发送的一个写请求。
学生提问：Log中的zxid怎么反应到key-value数据库的状态呢？ Robert教授：如果你向一个副本发送读请求，理论上，客户端会认为副本返回的实际上是Table中的值。所以，客户端说，我只想从这个Table读这一行，这个副本会将其当前状态中Table中对应的值和上次更新Table的zxid返回给客户端。 我不太确定，这里有两种可能，我认为任何一种都可以。第一个是，每个服务器可以跟踪修改每一行Table数值的写请求对应的zxid（这样可以读哪一行就返回相应的zxid）；另一个是，服务器可以为所有的读请求返回Log中最近一次commit的zxid，不论最近一次请求是不是更新了当前读取的Table中的行。因为，我们只需要确认客户端请求在Log中的执行点是一直向前推进，所以对于读请求，我们只需要返回大于修改了Table中对应行的写请求对应的zxid即可。
好的，这些是Zookeeper的一致性保证。
Zookeeper API Zookeeper的API设计使得它可以成为一个通用的服务，从而分担一个分布式系统所需要的大量工作。那么为什么Zookeeper的API是一个好的设计？具体来看，因为它实现了一个值得去了解的概念：mini-transaction.
我们回忆一下Zookeeper的特点：
Zookeeper基于（类似于）Raft框架，所以我们可以认为它是，当然它的确是容错的，它在发生网络分区的时候，也能有正确的行为。 当我们在分析各种Zookeeper的应用时，我们也需要记住Zookeeper有一些性能增强，使得读请求可以在任何副本被处理，因此，可能会返回旧数据。 另一方面，Zookeeper可以确保一次只处理一个写请求，并且所有的副本都能看到一致的写请求顺序。这样，所有副本的状态才能保证是一致的（写请求会改变状态，一致的写请求顺序可以保证状态一致）。 由一个客户端发出的所有读写请求会按照客户端发出的顺序执行。 一个特定客户端的连续请求，后来的请求总是能看到相比较于前一个请求相同或者更晚的状态（详见8.5 FIFO客户端序列）。 detail</p></div><footer class=entry-footer><span title='2023-10-11 18:00:57 +0800 +0800'>2023-10-11</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;Reid</footer><a class=entry-link aria-label="post link to Zookeeper一致保证" href=https://reid00.github.io/en/posts/storage/zookeeper%E4%B8%80%E8%87%B4%E4%BF%9D%E8%AF%81/></a></article><article class=post-entry><header class=entry-header><h2>知识图谱存储技术</h2></header><div class=entry-content><p>RDF和属性图 首先来介绍 RDF 和属性图。大家知道世界万物是普遍联系的，Internet 带来了信息的连通，IoT 带来了设备的连通，像微信、微博、抖音、快手这些 APP 带来了人际关系的连通。随着社交、零售、金融、电信、物流等行业的快速发展，当今社会支起了一张庞大而复杂的关系网，在人们的生产和生活过程中，每时每刻都产生着大量的数据。随着技术的发展，我们对这些数据的分析和使用也不再局限于从统计的角度进行一些相关性的分析，而是希望从关联的角度揭示数据的一些因果联系。这里的关联，指的是相互连接的 connectivity，而不是统计意义上的 correlation。
关联分析的场景也非常多，覆盖我们生活的方方面面。比如从社交网络分析里，我们可以做精准营销、好友推荐、舆情追踪等等；金融领域可以做信用卡反欺诈的分析，资金流向识别；零售领域，我们可以做用户 360 画像做商品实时推荐，返薅羊毛；电力领域，可以做电网的调度仿真、故障分析、电台因子计算；电信领域，可以做电信防骚扰，电信防诈骗；政企领域，可以做道路规划、智能交通，还有疫情精准防控；在制造业，我们可以做供应链管理、物流优化、产品溯源等；网络安全行业，可以做攻击溯源、调用链分析等等。
在做关联分析的时候，我们往往需要一个图模型来描述。常见的图模型分为 RDF 和属性图两种。RDF 图中用点来表示唯一标识的资源或者是字面量的值，边则用来表示谓词。点和边之间组成一个 SPO 的三元组。属性图中，点表示实体，边表示关系，属性是点或边上的一个键值对。
相比之下，RDF 的优势是可以支持多值属性，因为它的属性也是一个点，所以一个点连出去，可以有多值的属性。也可以通过四元组的方式前面加上一个图的描述，来实现动态图。并且 RDF 开始的比较早，所以有一个比较统一的标准。
属性图的优势在于它两点之间可以表示同类型的多条边，因为它在边上是可以有区分属性的，边上的属性值也能让边上的表达能力更丰富。并且它支持复杂的属性类型，比如 list、set、map 等。
随着行业的发展，我们看到越来越多的可能。知识图谱的表示在逐渐用属性图来完成。当然也有少量的图数据库是用 RDF 模型来做的，但是未来更多的新型图数据库都会用属性图模型。
图数据库存储的核心目标 完成一个图查询或者图分析的核心操作，就是邻居的迭代遍历。
单独的访问点或者边，或者上面的属性并不是这里的关键。仅仅是单独访问，使用传统的数据库也可以提供很好的性能。在关联分析当中，不论是从一个起始点若干跳数内的邻域网络进行分析，还是对全图进行一些完整的计算，最核心的操作都是迭代遍历某个点的所有边，也就是所谓邻居的迭代遍历。在关系型数据库中是依赖外键，通过建立索引等方式来完成的。
在图数据库中，会直接存储边数据，也就是所谓的实现 index-free adjacency。写入的时候，保证一个点和它直接相连的边总是存储在一起。查询的时候，迭代遍历一个点的所有邻居可以直接进行，不需要依赖于其它数据结构，从而可以大幅提升邻居迭代遍历的性能。
这里是跟关系型数据库做的一个深点查询的性能对比，用的是 who-trust-whom 的一个公开数据集，这个数据集也不是很大，约 7.5 万点，50 万边。我们想知道一个信任的人这样一个多跳关联的查询结果。使用关键性数据库的时候，对比了加索引和不加索引的情况。可以看出 2 跳的时候加索引可以明显提升关系型数据库的查询速度，到 3 跳的时候提升就不多了， 4 跳以上的时候加不加索引都会变得很慢。而使用图数据库，查询性能一直会保持在一个非常快的水平。这就是图数据库的 index-free adjacency 的特性，能够大幅提升邻居查询的速度。
图数据库的分类 根据实现免索引连接的方式，可以把图数据库分成三类。
第一类是使用原生图存储的方式，它的数据存储层就直接实现了免索引连接。上面的处理计算层和业务层都是以完全图的结构来描述，并且也不依赖于第三方存储组件，所以这种实现免索引连接的性能是最高效的。 第二种方式是非原生存储，数据存储层使用的是一个第三方的开源存储组件，但是它在处理过程中实现了近似免索引连接，在大多数情况下也能提供不错的性能。它的问题是由于使用了第三方存储组件，在某些场景下可能做得不是最优化。 第三种方式就是完全非原生的存储，底下可能是一个关系型数据库，或者是一个文档型或者其它类型的数据库，它的存储层其实并不是真正地实现了免索引连接，而是处理成通过索引或者一些其它技术手段，向上表达了一个图模型的查询接口。这种其实只是在接口层上实现了图的一个语义，而底下的存储和计算层都不是完全地使用免索引连接，所以它的性能也会相对低一些。 图数据库存储的主流技术方案 前文中已经明确了数据库存储的核心目标就是实现免索引连接。那么接下来就来看一些具体实现免索引连接的主流技术方案。
数组存储 首先我们能想到的最直接的一个方案，就是用一个数组把每个点上的边按照顺序一起存储。在这一存储方案中，点文件就是由一系列的点数据组成的。每个点的存储内容包括点的 ID、点的 Meta 信息，以及这个点的一系列属性。在边文件中，是按照起始点的顺序存储点上对应的边，每条边存储的内容包括终止点 ID、边的 Meta 信息、边的一系列属性。这里所谓的 Meta 信息包括点边的类型、方向，还有一些为了实现事务的额外字段，这对于整体的存储来说不是特别重要，在这里就不详细展开了。在这个存储方案中，可以直接从起始点开始遍历相邻边的所有数据，读取性能是非常高的。 数组存储劣势 这种存储需要处理的一个比较棘手的问题，就是数组变长的情况。这里的变长是由很多因素导致，比如两个点可能属性数量不一样，属性本身如果是字符串，长度也会不一样。属性长度不一样会导致每条边的存储空间也不一样，这样在边文件中就不能用一个简单的数组来进行寻址了。如果仅仅是属性导致的变长，还是有比较简单的解决方案的，比如可以把属性单独的再放到另一个存储文件中，这样点文件和边文件里面的内容，是不是定长的呢？其实也不一定，因为每个点上边的数量也是不一样的，所以在边文件里面，每个点触发的边序列的总长度也是不一样的。所以还是要处理数组变长的问题。
解决思路一般是两种：...</p></div><footer class=entry-footer><span title='2023-08-25 11:38:32 +0800 +0800'>2023-08-25</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;Reid</footer><a class=entry-link aria-label="post link to 知识图谱存储技术" href=https://reid00.github.io/en/posts/storage/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF/></a></article><article class=post-entry><header class=entry-header><h2>RocksDB Sstable</h2></header><div class=entry-content><p>概述 如我们之前提到的，leveldb是典型的LSM树(Log Structured-Merge Tree)实现，即一次leveldb的写入过程并不是直接将数据持久化到磁盘文件中，而是将写操作首先写入日志文件中，其次将写操作应用在memtable上。
当leveldb达到checkpoint点（memtable中的数据量超过了预设的阈值），会将当前memtable冻结成一个不可更改的内存数据库（immutable memory db），并且创建一个新的memtable供系统继续使用。
immutable memory db会在后台进行一次minor compaction，即将内存数据库中的数据持久化到磁盘文件中。
在这里我们暂时不展开讨论minor compaction相关的内容，读者可以简单地理解为将内存中的数据持久化到文件
leveldb（或者说LSM树）设计Minor Compaction的目的是为了：
有效地降低内存的使用率； 避免日志文件过大，系统恢复时间过长； 当memory db的数据被持久化到文件中时，leveldb将以一定规则进行文件组织，这种文件格式成为sstable。在本文中将详细地介绍sstable的文件格式以及相关读写操作。
SStable文件格式 物理结构 为了提高整体的读写效率，一个sstable文件按照固定大小进行块划分，默认每个块的大小为4KiB。每个Block中，除了存储数据以外，还会存储两个额外的辅助字段：
压缩类型 CRC校验码 压缩类型说明了Block中存储的数据是否进行了数据压缩，若是，采用了哪种算法进行压缩。leveldb中默认采用Snappy算法进行压缩。 CRC校验码是循环冗余校验校验码，校验范围包括数据以及压缩类型。 逻辑结构 在逻辑上，根据功能不同，leveldb在逻辑上又将sstable分为：
data block: 用来存储key value数据对； filter block: 用来存储一些过滤器相关的数据（布隆过滤器），但是若用户不指定leveldb使用过滤器，leveldb在该block中不会存储任何内容； meta Index block: 用来存储filter block的索引信息（索引信息指在该sstable文件中的偏移量以及数据长度）； index block：index block中用来存储每个data block的索引信息； footer: 用来存储meta index block及index block的索引信息； 注意，1-4类型的区块，其物理结构都是如1.1节所示，每个区块都会有自己的压缩信息以及CRC校验码信息。
data block结构 data block中存储的数据是leveldb中的keyvalue键值对。其中一个data block中的数据部分（不包括压缩类型、CRC校验码）按逻辑又以下图进行划分： 第一部分用来存储keyvalue数据。由于sstable中所有的keyvalue对都是严格按序存储的，为了节省存储空间，leveldb并不会为每一对keyvalue对都存储完整的key值，而是存储与上一个key非共享的部分，避免了key重复内容的存储。
每间隔若干个keyvalue对，将为该条记录重新存储一个完整的key。重复该过程（默认间隔值为16），每个重新存储完整key的点称之为Restart point。
每间隔若干个keyvalue对，将为该条记录重新存储一个完整的key。重复该过程（默认间隔值为16），每个重新存储完整key的点称之为Restart point。
每个数据项的格式如下图所示： 一个entry分为5部分内容：
与前一条记录key共享部分的长度； 与前一条记录key不共享部分的长度； value长度； 与前一条记录key非共享的内容； value内容； 例如：
1 2 3 4 restart_interval=2 entry one : key=deck,value=v1 entry two : key=dock,value=v2 entry three: key=duck,value=v3 三组entry按上图的格式进行存储。值得注意的是restart_interval为2，因此每隔两个entry都会有一条数据作为restart point点的数据项，存储完整key值。因此entry3存储了完整的key。...</p></div><footer class=entry-footer><span title='2023-03-16 19:35:09 +0800 +0800'>2023-03-16</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;Reid</footer><a class=entry-link aria-label="post link to RocksDB Sstable" href=https://reid00.github.io/en/posts/storage/rocksdb-sstable/></a></article><article class=post-entry><header class=entry-header><h2>RocksDB</h2></header><div class=entry-content><p>简介 RocksDB 是由 Facebook 基于 LevelDB 开发的一款提供键值存储与读写功能的 LSM-tree 架构引擎。用户写入的键值对会先写入磁盘上的 WAL (Write Ahead Log)，然后再写入内存中的跳表（SkipList，这部分结构又被称作 MemTable）。LSM-tree 引擎由于将用户的随机修改（插入）转化为了对 WAL 文件的顺序写，因此具有比 B 树类存储引擎更高的写吞吐。
内存中的数据达到一定阈值后，会刷到磁盘上生成 SST 文件 (Sorted String Table)，SST 又分为多层（默认至多 6 层），每一层的数据达到一定阈值后会挑选一部分 SST 合并到下一层，每一层的数据是上一层的 10 倍（因此 90% 的数据存储在最后一层）。
RocksDB 允许用户创建多个 ColumnFamily ，这些 ColumnFamily 各自拥有独立的内存跳表以及 SST 文件，但是共享同一个 WAL 文件，这样的好处是可以根据应用特点为不同的 ColumnFamily 选择不同的配置，但是又没有增加对 WAL 的写次数。
rocksdb 和 leveldb对比优势 Leveldb是单线程合并文件，Rocksdb可以支持多线程合并文件，充分利用多核的特性，加快文件合并的速度，避免文件合并期间引起系统停顿 Leveldb只有一个Memtable，若Memtable满了还没有来得及持久化，则会引起系统停顿，Rocksdb可以根据需要开辟多个Memtable； Leveldb只能获取单个K-V，Rocksdb支持一次获取多个K-V。 Levledb不支持备份，Rocksdb支持全量和备份。 架构 RocksDB 是基于 LSM-Tree 的。Rocksdb结构图如下: LSM-Tree 能将离散的随机写请求都转换成批量的顺序写请求（WAL + Compaction），以此提高写性能。 sst文件是在硬盘上的。SST files按照key 排序，且每个文件的key range互相不重叠。为了check一个key可能存在于哪一个一个SST file中，RocksDB并没有依次遍历每一个SST file，然后去检查key是否在这个file的key range 内，而是执行二分搜索算法（FileMetaData....</p></div><footer class=entry-footer><span title='2023-03-16 19:35:08 +0800 +0800'>2023-03-16</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;Reid</footer><a class=entry-link aria-label="post link to RocksDB" href=https://reid00.github.io/en/posts/storage/rocksdb/></a></article><article class=post-entry><header class=entry-header><h2>MySql高频面试问题</h2></header><div class=entry-content><p>本文主要受众为开发人员,所以不涉及到MySQL的服务部署等操作,且内容较多,大家准备好耐心和瓜子矿泉水。
前一阵系统的学习了一下MySQL,也有一些实际操作经验,偶然看到一篇和MySQL相关的面试文章,发现其中的一些问题自己也回答不好,虽然知识点大部分都知道,但是无法将知识串联起来。
因此决定搞一个MySQL灵魂100问,试着用回答问题的方式,让自己对知识点的理解更加深入一点。
此文不会事无巨细的从select的用法开始讲解mysql,主要针对的是开发人员需要知道的一些MySQL的知识点
主要包括索引,事务,优化等方面,以在面试中高频的问句形式给出答案。
MySQL 重要笔记 三万字、91道MySQL面试题（收藏版）
https://mp.weixin.qq.com/s/KRWyl-zU1Cd6sxbya4dP_g
书写高质量SQL的30条建议
https://mp.weixin.qq.com/s/nM6fwEyi2VZeRMWtdZGpGQ
数据分析面试必备SQL语句+语法
https://mp.weixin.qq.com/s/8UZAaDyB38gsZANPLxNKgg
索引相关 关于MySQL的索引,曾经进行过一次总结,文章链接在这里 Mysql索引原理及其优化.
1. 什么是索引?
索引是一种数据结构,可以帮助我们快速的进行数据的查找.
2. 索引是个什么样的数据结构呢?
索引的数据结构和具体存储引擎的实现有关, 在MySQL中使用较多的索引有Hash索引,B+树索引等,而我们经常使用的InnoDB存储引擎的默认索引实现为:B+树索引.
3. Hash索引和B+树所有有什么区别或者说优劣呢?
首先要知道Hash索引和B+树索引的底层实现原理:
hash索引底层就是hash表,进行查找时,调用一次hash函数就可以获取到相应的键值,之后进行回表查询获得实际数据.B+树底层实现是多路平衡查找树.
对于每一次的查询都是从根节点出发,查找到叶子节点方可以获得所查键值,然后根据查询判断是否需要回表查询数据.
那么可以看出他们有以下的不同:
hash索引进行等值查询更快(一般情况下),但是却无法进行范围查询. 因为在hash索引中经过hash函数建立索引之后,索引的顺序与原顺序无法保持一致,不能支持范围查询.
而B+树的的所有节点皆遵循(左节点小于父节点,右节点大于父节点,多叉树也类似),天然支持范围.
hash索引不支持使用索引进行排序,原理同上.
hash索引不支持模糊查询以及多列索引的最左前缀匹配.原理也是因为hash函数的不可预测.AAAA和AAAAB的索引没有相关性.
hash索引任何时候都避免不了回表查询数据,而B+树在符合某些条件(聚簇索引,覆盖索引等)的时候可以只通过索引完成查询.
hash索引虽然在等值查询上较快,但是不稳定.性能不可预测,当某个键值存在大量重复的时候,发生hash碰撞,此时效率可能极差.而B+树的查询效率比较稳定,对于所有的查询都是从根节点到叶子节点,且树的高度较低.
因此,在大多数情况下,直接选择B+树索引可以获得稳定且较好的查询速度.而不需要使用hash索引.
4. 上面提到了B+树在满足聚簇索引和覆盖索引的时候不需要回表查询数据,什么是聚簇索引?
在B+树的索引中,叶子节点可能存储了当前的key值,也可能存储了当前的key值以及整行的数据,这就是聚簇索引和非聚簇索引.
在InnoDB中,只有主键索引是聚簇索引,如果没有主键,则挑选一个唯一键建立聚簇索引.如果没有唯一键,则隐式的生成一个键来建立聚簇索引.
当查询使用聚簇索引时,在对应的叶子节点,可以获取到整行数据,因此不用再次进行回表查询.
5. 非聚簇索引一定会回表查询吗?
不一定,这涉及到查询语句所要求的字段是否全部命中了索引,如果全部命中了索引,那么就不必再进行回表查询.
举个简单的例子,假设我们在员工表的年龄上建立了索引,那么当进行select age from employee where age &lt; 20的查询时,在索引的叶子节点上,已经包含了age信息,不会再次进行回表查询.
6. 在建立索引的时候,都有哪些需要考虑的因素呢?
建立索引的时候一般要考虑到字段的使用频率,经常作为条件进行查询的字段比较适合.如果需要建立联合索引的话,还需要考虑联合索引中的顺序.
此外也要考虑其他方面,比如防止过多的所有对表造成太大的压力.这些都和实际的表结构以及查询方式有关.
7. 联合索引是什么?为什么需要注意联合索引中的顺序?
MySQL可以使用多个字段同时建立一个索引,叫做联合索引.在联合索引中,如果想要命中索引,需要按照建立索引时的字段顺序挨个使用,否则无法命中索引.
具体原因为:
MySQL使用索引时需要索引有序,假设现在建立了"name,age,school"的联合索引
那么索引的排序为: 先按照name排序,如果name相同,则按照age排序,如果age的值也相等,则按照school进行排序.
当进行查询时,此时索引仅仅按照name严格有序,因此必须首先使用name字段进行等值查询,之后对于匹配到的列而言,其按照age字段严格有序,此时可以使用age字段用做索引查找,以此类推.
因此在建立联合索引的时候应该注意索引列的顺序,一般情况下,将查询需求频繁或者字段选择性高的列放在前面.此外可以根据特例的查询或者表结构进行单独的调整.
8. 创建的索引有没有被使用到?或者说怎么才可以知道这条语句运行很慢的原因?
MySQL提供了explain命令来查看语句的执行计划,MySQL在执行某个语句之前,会将该语句过一遍查询优化器,之后会拿到对语句的分析,也就是执行计划,其中包含了许多信息.
可以通过其中和索引有关的信息来分析是否命中了索引,例如possilbe_key,key,key_len等字段,分别说明了此语句可能会使用的索引,实际使用的索引以及使用的索引长度....</p></div><footer class=entry-footer><span title='2023-03-16 19:35:07 +0800 +0800'>2023-03-16</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;Reid</footer><a class=entry-link aria-label="post link to MySql高频面试问题" href=https://reid00.github.io/en/posts/storage/mysql%E9%AB%98%E9%A2%91%E9%9D%A2%E8%AF%95%E9%97%AE%E9%A2%98/></a></article><article class=post-entry><header class=entry-header><h2>MySql索引介绍</h2></header><div class=entry-content><p>什么是索引，索引的作用 当我们要在新华字典里查某个字（如「先」）具体含义的时候，通常都会拿起一本新华字典来查，你可以先从头到尾查询每一页是否有「先」这个字，这样做（对应数据库中的全表扫描）确实能找到，但效率无疑是非常低下的，更高效的方相信大家也都知道，就是在首页的索引里先查找「先」对应的页数，然后直接跳到相应的页面查找，这样查询时候大大减少了，可以为是 O(1)。
数据库中的索引也是类似的，通过索引定位到要读取的页，大大减少了需要扫描的行数，能极大的提升效率，简而言之，索引主要有以下几个作用:
即上述所说，索引能极大地减少扫描行数 索引可以帮助服务器避免排序和临时表 索引可以将随机 IO 变成顺序 IO MySQL中索引的存储类型有两种：BTREE和HASH，具体和表的存储引擎相关；
MyISAM和InnoDB存储引擎只支持BTREE索引，MEMORY/HEAP存储引擎可以支持HASH和BTREE索引。
第一点上文已经解释了，我们来看下第二点和第三点
先来看第二点，假设我们不用索引，试想运行如下语句
1 select * from user order by age desc 则 MySQL 的流程是这样的，扫描所有行，把所有行加载到内存后，再按 age 排序生成一张临时表，再把这表排序后将相应行返回给客户端，更糟的，如果这张临时表的大小大于 tmp_table_size 的值（默认为 16 M），内存临时表会转为磁盘临时表，性能会更差，如果加了索引，索引本身是有序的 ，所以从磁盘读的行数本身就是按 age 排序好的，也就不会生成临时表，就不用再额外排序 ，无疑提升了性能。
再来看随机 IO 和顺序 IO。先来解释下这两个概念。
相信不少人应该吃过旋转火锅，服务员把一盘盘的菜放在旋转传输带上，然后等到这些菜转到我们面前，我们就可以拿到菜了，假设装一圈需要 4 分钟，则最短等待时间是 0（即菜就在你跟前），最长等待时间是 4 分钟（菜刚好在你跟前错过），那么平均等待时间即为 2 分钟，假设我们现在要拿四盘菜，这四盘菜随机分配在传输带上，则可知拿到这四盘菜的平均等待时间是 8 分钟（随机 IO），如果这四盘菜刚好紧邻着排在一起，则等待时间只需 2 分钟（顺序 IO）。
上述中传输带就类比磁道，磁道上的菜就类比扇区（sector）中的信息，磁盘块（block）是由多个相邻的扇区组成的，是操作系统读取的最小单元，这样如果信息能以 block 的形式聚集在一起，就能极大减少磁盘 IO 时间,这就是顺序 IO 带来的性能提升，下文中我们将会看到 B+ 树索引就起到这样的作用。
如图示：多个扇区组成了一个 block，如果要读的信息都在这个 block 中，则只需一次 IO 读
而如果信息在一个磁道中, 分散地分布在各个扇区中，或者分布在不同磁道的扇区上（寻道时间是随机IO主要瓶颈所在），将会造成随机 IO，影响性能。...</p></div><footer class=entry-footer><span title='2023-03-16 19:35:06 +0800 +0800'>2023-03-16</span>&nbsp;·&nbsp;5 min&nbsp;·&nbsp;Reid</footer><a class=entry-link aria-label="post link to MySql索引介绍" href=https://reid00.github.io/en/posts/storage/mysql%E7%B4%A2%E5%BC%95%E4%BB%8B%E7%BB%8D/></a></article><article class=post-entry><header class=entry-header><h2>MySql索引优化</h2></header><div class=entry-content><p>数据库表结构：
1 2 3 4 5 6 7 8 9 create table user ( id int primary key, name varchar(20), sex varchar(5), index(name) )engine=innodb; select id,name where name='shenjian' select id,name,sex where name='shenjian' 多查询了一个属性，为何检索过程完全不同？
什么是回表查询？
什么是索引覆盖？
如何实现索引覆盖？
哪些场景，可以利用索引覆盖来优化SQL？
一、什么是回表查询？ 这先要从InnoDB的索引实现说起，InnoDB有两大类索引：
聚集索引(clustered index) 普通索引(secondary index) **InnoDB聚集索引和普通索引有什么差异？
**
InnoDB聚集索引的叶子节点存储行记录，因此， InnoDB必须要有，且只有一个聚集索引：
（1）如果表定义了PK，则PK就是聚集索引；
（2）如果表没有定义PK，则第一个not NULL unique列是聚集索引；
（3）否则，InnoDB会创建一个隐藏的row-id作为聚集索引；
画外音：所以PK查询非常快，直接定位行记录。
InnoDB普通索引的叶子节点存储主键值。
画外音：注意，不是存储行记录头指针，MyISAM的索引叶子节点存储记录指针。
举个栗子，不妨设有表：
t(id PK, name KEY, sex, flag);
画外音：id是聚集索引，name是普通索引。
表中有四条记录：
1, shenjian, m, A
3, zhangsan, m, A...</p></div><footer class=entry-footer><span title='2023-03-16 19:35:06 +0800 +0800'>2023-03-16</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;Reid</footer><a class=entry-link aria-label="post link to MySql索引优化" href=https://reid00.github.io/en/posts/storage/mysql%E7%B4%A2%E5%BC%95%E4%BC%98%E5%8C%96/></a></article><article class=post-entry><header class=entry-header><h2>MySql事务</h2></header><div class=entry-content><p>『浅入深出』MySQL 中事务的实现 https://draveness.me/mysql-transaction/
MySQL 中如何实现事务隔离 https://www.cnblogs.com/fengzheng/p/12557762.html
详解一条 SQL 的执行过程
https://juejin.cn/post/6931606328129355790
首先说读未提交，它是性能最好，也可以说它是最野蛮的方式，因为它压根儿就不加锁，所以根本谈不上什么隔离效果，可以理解为没有隔离。
再来说串行化。读的时候加共享锁，也就是其他事务可以并发读，但是不能写。写的时候加排它锁，其他事务不能并发写也不能并发读。
最后说读提交和可重复读。这两种隔离级别是比较复杂的，既要允许一定的并发，又想要兼顾的解决问题。
实现可重复读 为了解决不可重复读，或者为了实现可重复读，MySQL 采用了 MVVC (多版本并发控制) 的方式。
我们在数据库表中看到的一行记录可能实际上有多个版本，每个版本的记录除了有数据本身外，还要有一个表示版本的字段，记为 row trx_id，而这个字段就是使其产生的事务的 id，事务 ID 记为 transaction id，它在事务开始的时候向事务系统申请，按时间先后顺序递增。
按照上面这张图理解，一行记录现在有 3 个版本，每一个版本都记录这使其产生的事务 ID，比如事务A的transaction id 是100，那么版本1的row trx_id 就是 100，同理版本2和版本3。
在上面介绍读提交和可重复读的时候都提到了一个词，叫做快照，学名叫做一致性视图，这也是可重复读和不可重复读的关键，可重复读是在事务开始的时候生成一个当前事务全局性的快照，而读提交则是每次执行语句的时候都重新生成一次快照。
对于一个快照来说，它能够读到那些版本数据，要遵循以下规则：
当前事务内的更新，可以读到； 版本未提交，不能读到； 版本已提交，但是却在快照创建后提交的，不能读到； 版本已提交，且是在快照创建前提交的，可以读到； 利用上面的规则，再返回去套用到读提交和可重复读的那两张图上就很清晰了。还是要强调，两者主要的区别就是在快照的创建上，可重复读仅在事务开始是创建一次，而读提交每次执行语句的时候都要重新创建一次。
并发写问题 存在这的情况，两个事务，对同一条数据做修改。最后结果应该是哪个事务的结果呢，肯定要是时间靠后的那个对不对。并且更新之前要先读数据，这里所说的读和上面说到的读不一样，更新之前的读叫做“当前读”，总是当前版本的数据，也就是多版本中最新一次提交的那版。
假设事务A执行 update 操作， update 的时候要对所修改的行加行锁，这个行锁会在提交之后才释放。而在事务A提交之前，事务B也想 update 这行数据，于是申请行锁，但是由于已经被事务A占有，事务B是申请不到的，此时，事务B就会一直处于等待状态，直到事务A提交，事务B才能继续执行，如果事务A的时间太长，那么事务B很有可能出现超时异常。如下图所示。
加锁的过程要分有索引和无索引两种情况，比如下面这条语句
1 update user set age=11 where id = 1 id 是这张表的主键，是有索引的情况，那么 MySQL 直接就在索引数中找到了这行数据，然后干净利落的加上行锁就可以了。
而下面这条语句
1 update user set age=11 where age=10 表中并没有为 age 字段设置索引，所以， MySQL 无法直接定位到这行数据。那怎么办呢，当然也不是加表锁了。MySQL 会为这张表中所有行加行锁，没错，是所有行。但是呢，在加上行锁后，MySQL 会进行一遍过滤，发现不满足的行就释放锁，最终只留下符合条件的行。虽然最终只为符合条件的行加了锁，但是这一锁一释放的过程对性能也是影响极大的。所以，如果是大表的话，建议合理设计索引，如果真的出现这种情况，那很难保证并发度。...</p></div><footer class=entry-footer><span title='2023-03-16 19:35:05 +0800 +0800'>2023-03-16</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;Reid</footer><a class=entry-link aria-label="post link to MySql事务" href=https://reid00.github.io/en/posts/storage/mysql%E4%BA%8B%E5%8A%A1/></a></article><article class=post-entry><header class=entry-header><h2>MySql语句优化</h2></header><div class=entry-content><p>一，SQL语句性能优化 对查询进行优化，应尽量避免全表扫描，首先应考虑在 where 及 order by 涉及的列上建立索引。
应尽量避免在 where 子句中对字段进行 null 值判断，创建表时NULL是默认值，但大多数时候应该使用NOT NULL，或者使用一个特殊的值，如0，-1作为默 认值。
应尽量避免在 where 子句中使用!=或&lt;>操作符， MySQL只有对以下操作符才使用索引：&lt;，&lt;=，=，>，>=，BETWEEN，IN，以及某些时候的LIKE
应尽量避免在 where 子句中使用 or 来连接条件， 否则将导致引擎放弃使用索引而进行全表扫描， 可以 使用UNION合并查询： select id from t where num=10 union all select id from t where num=20
in 和 not in 也要慎用，否则会导致全表扫描，对于连续的数值，能用 between 就不要用 in 了：Select id from t where num between 1 and 3
下面的查询也将导致全表扫描：select id from t where name like ‘%abc%’ 或者select id from t where name like ‘%abc’若要提高效率，可以考虑全文检索。而select id from t where name like ‘abc%’ 才用到索引...</p></div><footer class=entry-footer><span title='2023-03-16 19:35:05 +0800 +0800'>2023-03-16</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;Reid</footer><a class=entry-link aria-label="post link to MySql语句优化" href=https://reid00.github.io/en/posts/storage/mysql%E8%AF%AD%E5%8F%A5%E4%BC%98%E5%8C%96/></a></article><article class=post-entry><header class=entry-header><h2>LSM Tree</h2></header><div class=entry-content><p>简介LSM Tree MySQL、etcd 等存储系统都是面向读多写少场景的，其底层大都采用 B-Tree 及其变种数据结构。而 LSM-Tree 则解决了另一个应用场景——写多读少时面临的问题。在面对亿级的海量数据的存储和检索的场景下，我们通常选择强力的 NoSQL 数据库，如 Hbase、RocksDB 等，它们的文件组织方式，都是仿照 LSM-Tree 实现的。 reference
LSM-Tree 全称是 Log Structured Merge Tree，是一种分层、有序、面向磁盘的数据结构，其核心思想是充分利用磁盘的顺序写性能要远高于随机写性能这一特性，将批量的随机写转化为一次性的顺序写。
从上图可以直观地看出，磁盘的顺序访问速度至少比随机 I/O 快三个数量级，甚至顺序访问磁盘比随机访问主内存还要快。这意味着要尽可能避免随机 I/O 操作，顺序访问非常值得我们去探讨与设计。
LSM-Tree 围绕这一原理进行设计和优化，通过消去随机的更新操作来达到这个目的，以此让写性能达到最优，同时为那些长期具有高更新频率的文件提供低成本的索引机制，减少查询时的开销。
Two-Component LSM-Tree LSM-Tree 可以由两个或多个类树的数据结构组件构成，本小节我们先介绍较为简单的两组件情况。 两组件 LSM-Tree（Two-Component LSM-Tree）在内存中有一个 C0 组件，它可以是 AVL 或 SkipList 等结构，所有写入首先写到 C0 中。而磁盘上有一个 C1 组件，当 C0 组件的大小达到阈值时，就需要进行 Rolling Merge，将内存中的内容合并到 C1 中。两组件 LSM-Tree 的写操作流程如下：
当有写操作时，会先将数据追加写到日志文件中，以备必要时恢复； 然后将数据写入位于内存的 C0 组件，通过某种数据结构保持 Key 有序； 内存中的数据定时或按固定大小刷新到磁盘，更新操作只写到内存，并不更新磁盘上已有文件； 随着写操作越来越多，磁盘上积累的文件也越来越多，这些文件不可写但有序，所以我们定时对文件进行合并（Compaction）操作，消除冗余数据，减少文件数量。 类似于普通的日志写入方式，这种数据结构的写入，全部都是以Append的模式追加，不存在删除和修改。对于任何应用来说，那些会导致索引值发生变化的数据更新都是繁琐且耗时的，但是这样的更新却可以被 LSM-Tree 轻松地解决，将该更新操作看做是一个删除操作加上一个插入操作。
C1 组件是为顺序性的磁盘访问优化过的，可以是 B-Tree 一类的数据结构（LevelDB 中的实现是 SSTable），所有的节点都是 100% 填充，为了有效利用磁盘，在根节点之下的所有的单页面节点都会被打包放到连续的多页面磁盘块（Multi-Page Block）上。对于 Rolling Merge 和长区间检索的情况将会使用 Multi-Page Block I/O，这样就可以有效减少磁盘旋臂的移动；而在匹配性的查找中会使用 Single-Page I/O，以最小化缓存量。通常根节点只有一个单页面，而其它节点使用 256KB 的 Multi-Page Block。...</p></div><footer class=entry-footer><span title='2023-03-16 19:35:04 +0800 +0800'>2023-03-16</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;Reid</footer><a class=entry-link aria-label="post link to LSM Tree" href=https://reid00.github.io/en/posts/storage/lsm-tree/></a></article><footer class=page-footer><nav class=pagination><a class=next href=https://reid00.github.io/en/posts/storage/page/2/>Next »</a></nav></footer></main><footer class=footer><span>&copy; 2023 <a href=https://reid00.github.io/en/>Reid's Blog</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>