<!doctype html><html lang=en dir=auto><head><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><meta name=referrer content="no-referrer-when-downgrade"></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://reid00.github.io/en/ accesskey=h title="Reid's Blog (Alt + H)">Reid's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li></ul></div></div><ul id=menu><li><a href=https://reid00.github.io/en/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://reid00.github.io/en/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://reid00.github.io/en/categories/ title=Categorys><span>Categorys</span></a></li><li><a href=https://reid00.github.io/en/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://reid00.github.io/en/>Home</a>&nbsp;»&nbsp;<a href=https://reid00.github.io/en/posts/>Posts</a>&nbsp;»&nbsp;<a href=https://reid00.github.io/en/posts/ml/>机器学习，深度学习，知识图谱相关</a></div><h1 class=post-title>KNN算法</h1><div class=post-description>KNN算法</div><div class=post-meta><span title='2023-03-16 19:35:18 +0800 +0800'>2023-03-16 19:35</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;156 words&nbsp;·&nbsp;Reid</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#summary aria-label=Summary>Summary</a></li><li><a href=#%e8%af%a6%e7%bb%86%e4%bb%8b%e7%bb%8d aria-label=详细介绍>详细介绍</a></li><li><a href=#%e5%b8%b8%e8%a7%81%e9%97%ae%e9%a2%98 aria-label=常见问题>常见问题</a><ul><li><a href=#1-k%e5%80%bc%e8%ae%be%e5%ae%9a%e4%b8%ba%e5%a4%9a%e5%a4%a7 aria-label="1. K值设定为多大？">1. K值设定为多大？</a></li><li><a href=#2-%e7%b1%bb%e5%88%ab%e5%a6%82%e4%bd%95%e5%88%a4%e5%ae%9a%e6%9c%80%e5%90%88%e9%80%82 aria-label="2. 类别如何判定最合适？">2. 类别如何判定最合适？</a></li><li><a href=#3-%e5%a6%82%e4%bd%95%e9%80%89%e6%8b%a9%e5%90%88%e9%80%82%e7%9a%84%e8%b7%9d%e7%a6%bb%e8%a1%a1%e9%87%8f aria-label="3. 如何选择合适的距离衡量？">3. 如何选择合适的距离衡量？</a></li><li><a href=#4-%e8%ae%ad%e7%bb%83%e6%a0%b7%e6%9c%ac%e6%98%af%e5%90%a6%e8%a6%81%e4%b8%80%e8%a7%86%e5%90%8c%e4%bb%81 aria-label="4. 训练样本是否要一视同仁？">4. 训练样本是否要一视同仁？</a></li><li><a href=#5-%e6%80%a7%e8%83%bd%e9%97%ae%e9%a2%98 aria-label="5. 性能问题？">5. 性能问题？</a></li><li><a href=#6-%e8%83%bd%e5%90%a6%e5%a4%a7%e5%b9%85%e5%87%8f%e5%b0%91%e8%ae%ad%e7%bb%83%e6%a0%b7%e6%9c%ac%e9%87%8f%e5%90%8c%e6%97%b6%e5%8f%88%e4%bf%9d%e6%8c%81%e5%88%86%e7%b1%bb%e7%b2%be%e5%ba%a6 aria-label="6. 能否大幅减少训练样本量，同时又保持分类精度？">6. 能否大幅减少训练样本量，同时又保持分类精度？</a></li></ul></li><li><a href=#%e7%ae%97%e6%b3%95%e5%ae%9e%e4%be%8b aria-label=算法实例>算法实例</a></li></ul></div></details></div><div class=post-content><h1 id=summary>Summary<a hidden class=anchor aria-hidden=true href=#summary>#</a></h1><p>简单的说，k-近邻算法采用测量不同特征值之间的距离方法进行分类。 它的思路是：如果一个样本在特征空间中的k个最相似(即特征空间中最邻近)的样本中的大多数属于某一个类别，则该样本也属于这个类别，其中K通常是不大于20的整数。KNN算法中，所选择的邻居都是已经正确分类的对象。该方法在定类决策上只依据最邻近的一个或者几个样本的类别来决定待分样本所属的类别。</p><blockquote><p>优点：精度高、对异常值不敏感、无数据输入假定。</p><p>缺点：计算复杂度高、空间复杂度高。</p><p>适用数据范围：数值型和标称型。</p></blockquote><h1 id=详细介绍>详细介绍<a hidden class=anchor aria-hidden=true href=#详细介绍>#</a></h1><p>下面通过一个简单的例子说明一下：如下图，绿色圆要被决定赋予哪个类，是红色三角形还是蓝色四方形？如果K=3，由于红色三角形所占比例为2/3，绿色圆将被赋予红色三角形那个类，如果K=5，由于蓝色四方形比例为3/5，因此绿色圆被赋予蓝色四方形类。</p><p><img loading=lazy src=https://raw.githubusercontent.com/Reid00/image-host/main/20220607/image.70ipeauyubc0.webp alt=img></p><p>由此也说明了KNN算法的结果很大程度取决于K的选择。</p><p>在KNN中，通过计算对象间距离来作为各个对象之间的非相似性指标，避免了对象之间的匹配问题，在这里距离一般使用欧氏距离或曼哈顿距离：</p><p><img loading=lazy src=https://raw.githubusercontent.com/Reid00/image-host/main/20220607/image.24oujnvo6ucg.webp alt=img></p><p>**接下来对KNN算法的思想总结一下：**就是在训练集中数据和标签已知的情况下，输入测试数据，将测试数据的特征与训练集中对应的特征进行相互比较，找到训练集中与之最为相似的前K个数据，则该测试数据对应的类别就是K个数据中出现次数最多的那个分类，其算法的描述为：</p><p>1）计算测试数据与各个训练数据之间的距离；</p><p>2）按照距离的递增关系进行排序；</p><p>3）选取距离最小的K个点；</p><p>4）确定前K个点所在类别的出现频率；</p><p>5）返回前K个点中出现频率最高的类别作为测试数据的预测分类。</p><h1 id=常见问题>常见问题<a hidden class=anchor aria-hidden=true href=#常见问题>#</a></h1><h2 id=1-k值设定为多大>1. K值设定为多大？<a hidden class=anchor aria-hidden=true href=#1-k值设定为多大>#</a></h2><p>K太小，分类结果易受噪声点影响；k太大，近邻中又可能包含太多的其它类别的点。（对距离加权，可以降低k值设定的影响）
k值通常是采用交叉检验来确定（以k=1为基准）
经验规则：k一般低于训练样本数的平方根</p><h2 id=2-类别如何判定最合适>2. 类别如何判定最合适？<a hidden class=anchor aria-hidden=true href=#2-类别如何判定最合适>#</a></h2><p>投票法没有考虑近邻的距离的远近，距离更近的近邻也许更应该决定最终的分类，所以加权投票法更恰当一些。</p><h2 id=3-如何选择合适的距离衡量>3. 如何选择合适的距离衡量？<a hidden class=anchor aria-hidden=true href=#3-如何选择合适的距离衡量>#</a></h2><p>高维度对距离衡量的影响：众所周知当变量数越多，欧式距离的区分能力就越差。
变量值域对距离的影响：值域越大的变量常常会在距离计算中占据主导作用，因此应先对变量进行标准化。</p><h2 id=4-训练样本是否要一视同仁>4. 训练样本是否要一视同仁？<a hidden class=anchor aria-hidden=true href=#4-训练样本是否要一视同仁>#</a></h2><p>在训练集中，有些样本可能是更值得依赖的。
可以给不同的样本施加不同的权重，加强依赖样本的权重，降低不可信赖样本的影响。</p><h2 id=5-性能问题>5. 性能问题？<a hidden class=anchor aria-hidden=true href=#5-性能问题>#</a></h2><p>KNN是一种懒惰算法，平时不好好学习，考试（对测试样本分类）时才临阵磨枪（临时去找k个近邻）。
懒惰的后果：构造模型很简单，但在对测试样本分类地的系统开销大，因为要扫描全部训练样本并计算距离。
已经有一些方法提高计算的效率，例如压缩训练样本量等。</p><h2 id=6-能否大幅减少训练样本量同时又保持分类精度>6. 能否大幅减少训练样本量，同时又保持分类精度？<a hidden class=anchor aria-hidden=true href=#6-能否大幅减少训练样本量同时又保持分类精度>#</a></h2><p>浓缩技术(condensing)
编辑技术(editing)</p><h1 id=算法实例>算法实例<a hidden class=anchor aria-hidden=true href=#算法实例>#</a></h1><p>如scikit-learn中的KNN算法使用:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1>#coding:utf-8</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn</span> <span class=kn>import</span> <span class=n>datasets</span> <span class=c1>#sk-learn 内置数据库</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=s1>&#39;&#39;&#39;KNN算法&#39;&#39;&#39;</span>
</span></span><span class=line><span class=cl><span class=n>iris</span> <span class=o>=</span> <span class=n>datasets</span><span class=o>.</span><span class=n>load_iris</span><span class=p>()</span> <span class=c1>#内置的鸢尾花卉数据集</span>
</span></span><span class=line><span class=cl><span class=c1>#数据集包含150个数据集，分为3类，每类50个数据,</span>
</span></span><span class=line><span class=cl><span class=c1>#可通过花萼长度，花萼宽度，花瓣长度，花瓣宽度4个特征预测鸢尾花卉属于</span>
</span></span><span class=line><span class=cl><span class=c1>#(Setosa，Versicolour，Virginica)三个种类中的哪一类</span>
</span></span><span class=line><span class=cl><span class=n>iris_X</span><span class=p>,</span><span class=n>iris_y</span> <span class=o>=</span> <span class=n>iris</span><span class=o>.</span><span class=n>data</span><span class=p>,</span><span class=n>iris</span><span class=o>.</span><span class=n>target</span> <span class=c1>#数据集及其对应的分类标签</span>
</span></span><span class=line><span class=cl><span class=c1># 将数据集随机分为训练数据集和测试数据集</span>
</span></span><span class=line><span class=cl><span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>seed</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>indices</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>permutation</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>iris_X</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=c1>#用于训练模型</span>
</span></span><span class=line><span class=cl><span class=n>iris_X_train</span> <span class=o>=</span> <span class=n>iris_X</span><span class=p>[</span><span class=n>indices</span><span class=p>[:</span><span class=o>-</span><span class=mi>10</span><span class=p>]]</span>
</span></span><span class=line><span class=cl><span class=n>iris_y_train</span> <span class=o>=</span> <span class=n>iris_y</span><span class=p>[</span><span class=n>indices</span><span class=p>[:</span><span class=o>-</span><span class=mi>10</span><span class=p>]]</span>
</span></span><span class=line><span class=cl><span class=c1>#用于测试模型</span>
</span></span><span class=line><span class=cl><span class=n>iris_X_test</span>  <span class=o>=</span> <span class=n>iris_X</span><span class=p>[</span><span class=n>indices</span><span class=p>[</span><span class=o>-</span><span class=mi>10</span><span class=p>:]]</span>
</span></span><span class=line><span class=cl><span class=n>iris_y_test</span>  <span class=o>=</span> <span class=n>iris_y</span><span class=p>[</span><span class=n>indices</span><span class=p>[</span><span class=o>-</span><span class=mi>10</span><span class=p>:]]</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.neighbors</span> <span class=kn>import</span> <span class=n>KNeighborsClassifier</span>
</span></span><span class=line><span class=cl><span class=n>knn</span> <span class=o>=</span> <span class=n>KNeighborsClassifier</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>knn</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>iris_X_train</span><span class=p>,</span><span class=n>iris_y_train</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>prediction</span> <span class=o>=</span> <span class=n>knn</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>iris_X_test</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>score</span> <span class=o>=</span> <span class=n>knn</span><span class=o>.</span><span class=n>score</span><span class=p>(</span><span class=n>iris_X_test</span><span class=p>,</span><span class=n>iris_y_test</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span> <span class=s1>&#39;真实分类标签:&#39;</span><span class=o>+</span><span class=nb>str</span><span class=p>(</span><span class=n>iris_y_test</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span> <span class=s1>&#39;模型分类结果:&#39;</span><span class=o>+</span><span class=nb>str</span><span class=p>(</span><span class=n>prediction</span><span class=p>)</span><span class=o>+</span><span class=s1>&#39;</span><span class=se>\n</span><span class=s1>算法准确度:&#39;</span><span class=o>+</span><span class=nb>str</span><span class=p>(</span><span class=n>score</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>输出结果:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>真实分类标签</span><span class=p>:[</span><span class=mi>1</span> <span class=mi>1</span> <span class=mi>1</span> <span class=mi>0</span> <span class=mi>0</span> <span class=mi>0</span> <span class=mi>2</span> <span class=mi>1</span> <span class=mi>2</span> <span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>模型分类结果</span><span class=p>:[</span><span class=mi>1</span> <span class=mi>2</span> <span class=mi>1</span> <span class=mi>0</span> <span class=mi>0</span> <span class=mi>0</span> <span class=mi>2</span> <span class=mi>1</span> <span class=mi>2</span> <span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>算法准确度</span><span class=p>:</span><span class=mf>0.9</span>
</span></span></code></pre></td></tr></table></div></div></div><footer class=post-footer><ul class=post-tags><li><a href=https://reid00.github.io/en/tags/knn/>KNN</a></li></ul><nav class=paginav><a class=prev href=https://reid00.github.io/en/posts/ml/%E5%86%B3%E7%AD%96%E6%A0%91/><span class=title>« Prev</span><br><span>决策树</span>
</a><a class=next href=https://reid00.github.io/en/posts/ml/l1l2%E6%AD%A3%E5%88%99/><span class=title>Next »</span><br><span>L1L2正则</span></a></nav></footer><script src=https://utteranc.es/client.js repo=Reid00/hugo-blog-talks issue-term=pathname label=Comment theme=github-light crossorigin=anonymous async></script></article></main><span id=busuanzi_container_site_pv>访问量<span id=busuanzi_value_site_pv></span>次
</span><span id=busuanzi_container_site_uv>访客数<span id=busuanzi_value_site_uv></span>人次</span></body></html>