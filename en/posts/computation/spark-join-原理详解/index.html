<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Spark Join 原理详解 | Reid's Blog</title>
<meta name=keywords content="Spark,Join"><meta name=description content="Spark Join 原理详解"><meta name=author content="Reid"><link rel=canonical href=https://reid00.github.io/en/posts/computation/spark-join-%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3/><link crossorigin=anonymous href=/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z+V9+cO1A=" rel="preload stylesheet" as=style><link rel=icon href=https://reid00.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://reid00.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://reid00.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://reid00.github.io/apple-touch-icon.png><link rel=mask-icon href=https://reid00.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://reid00.github.io/en/posts/computation/spark-join-%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><head><meta name=referrer content="no-referrer"></head><script async src="https://www.googletagmanager.com/gtag/js?id=G-QRR6GRNQGK"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-QRR6GRNQGK")}</script><meta property="og:title" content="Spark Join 原理详解"><meta property="og:description" content="Spark Join 原理详解"><meta property="og:type" content="article"><meta property="og:url" content="https://reid00.github.io/en/posts/computation/spark-join-%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3/"><meta property="og:image" content="https://i.loli.net/2021/09/26/3OMGXylm8HUYJ6p.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-03-16T19:34:54+08:00"><meta property="article:modified_time" content="2023-03-16T19:34:54+08:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://i.loli.net/2021/09/26/3OMGXylm8HUYJ6p.png"><meta name=twitter:title content="Spark Join 原理详解"><meta name=twitter:description content="Spark Join 原理详解"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://reid00.github.io/en/posts/"},{"@type":"ListItem","position":2,"name":"计算相关的记录，如Spark Flink 等","item":"https://reid00.github.io/en/posts/computation/"},{"@type":"ListItem","position":3,"name":"Spark Join 原理详解","item":"https://reid00.github.io/en/posts/computation/spark-join-%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Spark Join 原理详解","name":"Spark Join 原理详解","description":"Spark Join 原理详解","keywords":["Spark","Join"],"articleBody":"介绍 Join大致包括三个要素：Join方式、Join条件以及过滤条件。其中过滤条件也可以通过AND语句放在Join条件中。 Spark支持的Join 包括:\ninner join left outer join right outer join full outer join left semi join left anti join Join 的基本流程 总体上来说，Join的基本实现流程如下图所示，Spark将参与Join的两张表抽象为流式遍历表(streamIter)和查找表(buildIter)，通常streamIter为大表，buildIter为小表，我们不用担心哪个表为streamIter，哪个表为buildIter，这个spark会根据join语句自动帮我们完成。 在实际计算时，spark会基于streamIter来遍历，每次取出streamIter中的一条记录rowA，根据Join条件计算keyA，然后根据该keyA去buildIter中查找所有满足Join条件(keyB==keyA)的记录rowBs，并将rowBs中每条记录分别与rowAjoin得到join后的记录，最后根据过滤条件得到最终join的记录。\n从上述计算过程中不难发现，对于每条来自streamIter的记录，都要去buildIter中查找匹配的记录，所以buildIter一定要是查找性能较优的数据结构 如Hash Table。spark提供了三种join实现：sort merge join、broadcast join以及hash join。\nHash join实现 spark提供了hash join实现方式，在shuffle read阶段不对记录排序，反正来自两格表的具有相同key的记录会在同一个分区，只是在分区内不排序，将来自buildIter的记录放到hash表中，以便查找，如下图所示。\n由于Spark是一个分布式的计算引擎，可以通过分区的形式将大批量的数据划分成n份较小的数据集进行并行计算。这种思想应用到Join上便是Shuffle Hash Join了。利用key相同必然分区相同的这个原理，SparkSQL将较大表的join分而治之，先将表划分成n个分区，在对buildlter查找表和streamlter表进行Hash Join。 Shuffle Hash Join分为两步： 对两张表分别按照join keys进行重分区，即shuffle，目的是为了让有相同join keys值的记录分到对应的分区中 对 对应分区中的数据进行join，此处先将小表分区构造为一张hash表，然后根据大表分区中记录的join keys值拿出来进行匹配 不难发现，要将来自buildIter的记录放到hash表中，那么每个分区来自buildIter的记录不能太大，否则就存不下，默认情况下hash join的实现是关闭状态，如果要使用hash join，必须满足以下四个条件：\nbuildIter总体估计大小超过spark.sql.autoBroadcastJoinThreshold设定的值，即不满足broadcast join条件 开启尝试使用hash join的开关，spark.sql.join.preferSortMergeJoin=false 每个分区的平均大小不超过spark.sql.autoBroadcastJoinThreshold设定的值，即shuffle read阶段每个分区来自buildIter的记录要能放到内存中 streamIter的大小是buildIter三倍以上 Sort Merge Join 实现 上面介绍的实现对于一定大小的表比较适用，但当两个表都非常大时，显然无论适用哪种都会对计算内存造成很大压力。这是因为join时两者采取的都是hash join，是将一侧的数据完全加载到内存中，使用hash code取join keys值相等的记录进行连接。\n要让两条记录能join到一起，首先需要将具有相同key的记录在同一个分区，所以通常来说，需要做一次shuffle，map阶段根据join条件确定每条记录的key，基于该key做shuffle write，将可能join到一起的记录分到同一个分区中，这样在shuffle read阶段就可以将两个表中具有相同key的记录拉到同一个分区处理。前面我们也提到，对于buildIter一定要是查找性能较优的数据结构，通常我们能想到hash表，但是对于一张较大的表来说，不可能将所有记录全部放到hash表中，SparkSQL采用了一种全新的方案来对表进行Join，即Sort Merge Join。这种实现方式不用将一侧数据全部加载后再进行hash join，但需要在join前将数据排序，如下图所示： 三个步骤: shuffle阶段：或者说shuffle write 阶段，将两张大表根据join key进行重新分区，两张表数据会分布到整个集群，以便分布式并行处理 sort阶段：对单个分区节点的两表数据，分别进行排序 merge阶段：或者说shuffle read 阶段，对排好序的两张分区表数据执行join操作。join操作很简单，分别遍历两个有序序列，碰到相同join key就merge输出，否则取更小一边\n在shuffle read阶段，分别对streamIter和buildIter进行merge sort，在遍历streamIter时，对于每条记录，都采用顺序查找的方式从buildIter查找对应的记录，由于两个表都是排序的，每次处理完streamIter的一条记录后，对于streamIter的下一条记录，只需从buildIter中上一次查找结束的位置开始查找，所以说每次在buildIter中查找不必重头开始，整体上来说，查找性能还是较优的。\n仔细分析的话会发现，sort-merge join的代价并不比shuffle hash join小，反而是多了很多。那为什么SparkSQL还会在两张大表的场景下选择使用sort-merge join算法呢？这和Spark的shuffle实现有关，目前spark的shuffle实现都适用sort-based shuffle算法，因此在经过shuffle之后partition数据都是按照key排序的。因此理论上可以认为数据经过shuffle之后是不需要sort的，可以直接merge。\nBroadcast Join实现 为了能具有相同key的记录分到同一个分区，我们通常是做shuffle，而shuffle在Spark中是比较耗时的操作，我们应该尽可能的设计Spark应用使其避免大量的shuffle。。那么如果buildIter是一个非常小的表，那么其实就没有必要大动干戈做shuffle了，直接将buildIter广播到每个计算节点，然后将buildIter放到hash表中，如下图所示。 在执行上，主要可以分为以下两步：\nbroadcast阶段：将小表广播分发到大表所在的所有主机。分发方式可以有driver分发，或者采用p2p方式。 hash join阶段：在每个executor上执行单机版hash join，小表映射，大表试探； Broadcast Join的条件有以下几个：\n被广播的表需要小于spark.sql.autoBroadcastJoinThreshold所配置的值，默认是10M （或者加了broadcast join的hint） 基表不能被广播，比如left outer join时，只能广播右表 Hive Join Hive中的Join可分为Common Join（Reduce阶段完成join）和Map Join（Map阶段完成join）。\nHive Common Join 如果不指定MapJoin或者不符合MapJoin的条件，那么Hive解析器会默认把执行Common Join，即在Reduce阶段完成join。整个过程包含Map、Shuffle、Reduce阶段。\nMap阶段 读取源表的数据，Map输出时候以Join on条件中的列为key，如果Join有多个关联键，则以这些关联键的组合作为key；Map输出的value为join之后所关心的(select或者where中需要用到的)列，同时在value中还会包含表的Tag信息，用于标明此value对应哪个表。\nShuffle阶段 根据key的值进行hash，并将key/value按照hash值推送至不同的reduce中，这样确保两个表中相同的key位于同一个reduce中。\nReduce阶段 根据key的值完成join操作，期间通过Tag来识别不同表中的数据。\n1 2 3 SELECT a.id,a.dept,b.age FROM a join b ON (a.id = b.id); Hive Map Join MapJoin通常用于一个很小的表和一个大表进行join的场景，具体小表有多小，由参数hive.mapjoin.smalltable.filesize来决定，默认值为25M。满足条件的话Hive在执行时候会自动转化为MapJoin，或使用hint提示 /*+ mapjoin(table) */执行MapJoin。 如上图中的流程，首先Task A在客户端本地执行，负责扫描小表b的数据，将其转换成一个HashTable的数据结构，并写入本地的文件中，之后将该文件加载到DistributeCache中。 接下来的Task B任务是一个没有Reduce的MapReduce，启动MapTasks扫描大表a，在Map阶段，根据a的每一条记录去和DistributeCache中b表对应的HashTable关联，并直接输出结果，因为没有Reduce，所以有多少个Map Task，就有多少个结果文件。 注意：Map JOIN不适合FULL/RIGHT OUTER JOIN。\n","wordCount":"3766","inLanguage":"en","image":"https://i.loli.net/2021/09/26/3OMGXylm8HUYJ6p.png","datePublished":"2023-03-16T19:34:54+08:00","dateModified":"2023-03-16T19:34:54+08:00","author":[{"@type":"Person","name":"Reid"}],"mainEntityOfPage":{"@type":"WebPage","@id":"https://reid00.github.io/en/posts/computation/spark-join-%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3/"},"publisher":{"@type":"Organization","name":"Reid's Blog","logo":{"@type":"ImageObject","url":"https://reid00.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://reid00.github.io/en/ accesskey=h title="Reid's Blog (Alt + H)">Reid's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://reid00.github.io/en/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://reid00.github.io/en/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://reid00.github.io/en/categories/ title=Categorys><span>Categorys</span></a></li><li><a href=https://reid00.github.io/en/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://reid00.github.io/en/>Home</a>&nbsp;»&nbsp;<a href=https://reid00.github.io/en/posts/>Posts</a>&nbsp;»&nbsp;<a href=https://reid00.github.io/en/posts/computation/>计算相关的记录，如Spark Flink 等</a></div><h1 class="post-title entry-hint-parent">Spark Join 原理详解</h1><div class=post-description>Spark Join 原理详解</div><div class=post-meta><span title='2023-03-16 19:34:54 +0800 +0800'>2023-03-16 19:34</span>&nbsp;·&nbsp;8 min&nbsp;·&nbsp;3766 words&nbsp;·&nbsp;Reid</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#%e4%bb%8b%e7%bb%8d aria-label=介绍>介绍</a></li><li><a href=#join-%e7%9a%84%e5%9f%ba%e6%9c%ac%e6%b5%81%e7%a8%8b aria-label="Join 的基本流程">Join 的基本流程</a></li><li><a href=#hash-join%e5%ae%9e%e7%8e%b0 aria-label="Hash join实现">Hash join实现</a><ul><li><a href=#shuffle-hash-join%e5%88%86%e4%b8%ba%e4%b8%a4%e6%ad%a5 aria-label="Shuffle Hash Join分为两步：">Shuffle Hash Join分为两步：</a></li></ul></li><li><a href=#sort-merge-join-%e5%ae%9e%e7%8e%b0 aria-label="Sort Merge Join 实现">Sort Merge Join 实现</a></li><li><a href=#broadcast-join%e5%ae%9e%e7%8e%b0 aria-label="Broadcast Join实现">Broadcast Join实现</a></li><li><a href=#hive-join aria-label="Hive Join">Hive Join</a><ul><li><a href=#hive-common-join aria-label="Hive Common Join">Hive Common Join</a></li><li><a href=#hive-map-join aria-label="Hive Map Join">Hive Map Join</a></li></ul></li></ul></div></details></div><div class=post-content><h2 id=介绍>介绍<a hidden class=anchor aria-hidden=true href=#介绍>#</a></h2><p>Join大致包括三个要素：Join方式、Join条件以及过滤条件。其中过滤条件也可以通过AND语句放在Join条件中。
<img loading=lazy src=https://github.com/Reid00/image-host/raw/main/20221216/image.3auv97qmulk0.webp alt=join>
Spark支持的Join 包括:</p><ul><li>inner join</li><li>left outer join</li><li>right outer join</li><li>full outer join</li><li>left semi join</li><li>left anti join</li></ul><h2 id=join-的基本流程>Join 的基本流程<a hidden class=anchor aria-hidden=true href=#join-的基本流程>#</a></h2><p>总体上来说，Join的基本实现流程如下图所示，Spark将参与Join的两张表抽象为流式遍历表(streamIter)和查找表(buildIter)，通常streamIter为大表，buildIter为小表，我们不用担心哪个表为streamIter，哪个表为buildIter，这个spark会根据join语句自动帮我们完成。
<img loading=lazy src=https://github.com/Reid00/image-host/raw/main/20221216/image.4hvszw2v3nc0.webp alt=流程></p><p>在实际计算时，spark会<code>基于streamIter</code>来遍历，每次取出streamIter中的一条记录rowA，根据Join条件计算keyA，然后根据该keyA去buildIter中查找所有满足Join条件(keyB==keyA)的记录rowBs，并将rowBs中每条记录分别与rowAjoin得到join后的记录，最后根据过滤条件得到最终join的记录。</p><p>从上述计算过程中不难发现，对于每条来自streamIter的记录，都要去buildIter中查找匹配的记录，所以<code>buildIter一定要是查找性能较优的数据结构 如Hash Table</code>。spark提供了三种join实现：sort merge join、broadcast join以及hash join。</p><h2 id=hash-join实现>Hash join实现<a hidden class=anchor aria-hidden=true href=#hash-join实现>#</a></h2><p>spark提供了hash join实现方式，在shuffle read阶段不对记录排序，反正来自两格表的具有相同key的记录会在同一个分区，只是在分区内不排序，将来自buildIter的记录放到hash表中，以便查找，如下图所示。</p><p>由于Spark是一个分布式的计算引擎，可以通过分区的形式将大批量的数据划分成n份较小的数据集进行并行计算。这种思想应用到Join上便是Shuffle Hash Join了。利用key相同必然分区相同的这个原理，SparkSQL将较大表的join分而治之，先将表划分成n个分区，在对buildlter查找表和streamlter表进行Hash Join。
<img loading=lazy src=https://github.com/Reid00/image-host/raw/main/20221216/image.360e1g4bv760.webp alt=hasJoin></p><h3 id=shuffle-hash-join分为两步>Shuffle Hash Join分为两步：<a hidden class=anchor aria-hidden=true href=#shuffle-hash-join分为两步>#</a></h3><ol><li>对两张表分别按照join keys进行重分区，即shuffle，目的是为了让有相同join keys值的记录分到对应的分区中</li><li>对 对应分区中的数据进行join，此处先将小表分区构造为一张hash表，然后根据大表分区中记录的join keys值拿出来进行匹配</li></ol><p>不难发现，要将来自buildIter的记录放到hash表中，那么每个分区来自buildIter的记录不能太大，否则就存不下，默认情况下hash join的实现是关闭状态，如果要使用hash join，必须满足以下四个条件：</p><ul><li>buildIter总体估计大小超过spark.sql.autoBroadcastJoinThreshold设定的值，即不满足broadcast join条件</li><li>开启尝试使用hash join的开关，spark.sql.join.preferSortMergeJoin=false</li><li>每个分区的平均大小不超过spark.sql.autoBroadcastJoinThreshold设定的值，即shuffle read阶段每个分区来自buildIter的记录要能放到内存中</li><li>streamIter的大小是buildIter三倍以上</li></ul><h2 id=sort-merge-join-实现>Sort Merge Join 实现<a hidden class=anchor aria-hidden=true href=#sort-merge-join-实现>#</a></h2><p>上面介绍的实现对于一定大小的表比较适用，但当两个表都非常大时，显然无论适用哪种都会对计算内存造成很大压力。这是因为join时两者采取的都是hash join，是将一侧的数据完全加载到内存中，使用hash code取join keys值相等的记录进行连接。</p><p>要让两条记录能join到一起，首先需要将具有相同key的记录在同一个分区，所以通常来说，需要做一次shuffle，map阶段根据join条件确定每条记录的key，基于该key做shuffle write，将可能join到一起的记录分到同一个分区中，这样在shuffle read阶段就可以将两个表中具有相同key的记录拉到同一个分区处理。前面我们也提到，对于buildIter一定要是查找性能较优的数据结构，通常我们能想到hash表，但是对于一张较大的表来说，不可能将所有记录全部放到hash表中，SparkSQL采用了一种全新的方案来对表进行Join，即Sort Merge Join。这种实现方式不用将一侧数据全部加载后再进行hash join，但需要在join前将数据排序，如下图所示：
<img loading=lazy src=https://github.com/Reid00/image-host/raw/main/20221216/image.17azw5lad074.webp alt=sortMerge></p><p>三个步骤:
<strong>shuffle阶段</strong>：或者说shuffle write 阶段，将两张大表根据join key进行重新分区，两张表数据会分布到整个集群，以便分布式并行处理
<strong>sort阶段</strong>：对单个分区节点的两表数据，分别进行排序
<strong>merge阶段</strong>：或者说shuffle read 阶段，对排好序的两张分区表数据执行join操作。join操作很简单，分别遍历两个有序序列，碰到相同join key就merge输出，否则取更小一边</p><p>在shuffle read阶段，分别对streamIter和buildIter进行merge sort，在遍历streamIter时，对于每条记录，都采用顺序查找的方式从buildIter查找对应的记录，由于两个表都是排序的，每次处理完streamIter的一条记录后，对于streamIter的下一条记录，只需从buildIter中上一次查找结束的位置开始查找，所以说每次在buildIter中查找不必重头开始，整体上来说，查找性能还是较优的。</p><p>仔细分析的话会发现，sort-merge join的代价并不比shuffle hash join小，反而是多了很多。那为什么SparkSQL还会在两张大表的场景下选择使用sort-merge join算法呢？这和Spark的shuffle实现有关，目前spark的shuffle实现都适用sort-based shuffle算法，因此在经过shuffle之后partition数据都是按照key排序的。因此理论上可以认为数据经过shuffle之后是不需要sort的，可以直接merge。</p><h2 id=broadcast-join实现>Broadcast Join实现<a hidden class=anchor aria-hidden=true href=#broadcast-join实现>#</a></h2><p>为了能具有相同key的记录分到同一个分区，我们通常是做shuffle，而shuffle在Spark中是比较耗时的操作，我们应该尽可能的设计Spark应用使其避免大量的shuffle。。那么如果buildIter是一个非常小的表，那么其实就没有必要大动干戈做shuffle了，直接将buildIter广播到每个计算节点，然后将buildIter放到hash表中，如下图所示。
<img loading=lazy src=https://github.com/Reid00/image-host/raw/main/20221216/image.5v9djh5ouq80.webp alt=broadcast></p><p>在执行上，主要可以分为以下两步：</p><ol><li>broadcast阶段：将小表广播分发到大表所在的所有主机。分发方式可以有driver分发，或者采用p2p方式。</li><li>hash join阶段：在每个executor上执行单机版hash join，小表映射，大表试探；</li></ol><p>Broadcast Join的条件有以下几个：</p><ol><li>被广播的表需要小于spark.sql.autoBroadcastJoinThreshold所配置的值，默认是10M （或者加了broadcast join的hint）</li><li>基表不能被广播，比如left outer join时，只能广播右表</li></ol><h2 id=hive-join>Hive Join<a hidden class=anchor aria-hidden=true href=#hive-join>#</a></h2><p>Hive中的Join可分为Common Join（Reduce阶段完成join）和Map Join（Map阶段完成join）。</p><h3 id=hive-common-join>Hive Common Join<a hidden class=anchor aria-hidden=true href=#hive-common-join>#</a></h3><p>如果不指定MapJoin或者不符合MapJoin的条件，那么Hive解析器会默认把执行Common Join，即在Reduce阶段完成join。整个过程包含Map、Shuffle、Reduce阶段。</p><ul><li><p>Map阶段
读取源表的数据，Map输出时候以Join on条件中的列为key，如果Join有多个关联键，则以这些关联键的组合作为key；Map输出的value为join之后所关心的(select或者where中需要用到的)列，同时在value中还会包含表的Tag信息，用于标明此value对应哪个表。</p></li><li><p>Shuffle阶段
根据key的值进行hash，并将key/value按照hash值推送至不同的reduce中，这样确保两个表中相同的key位于同一个reduce中。</p></li><li><p>Reduce阶段
根据key的值完成join操作，期间通过Tag来识别不同表中的数据。</p></li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-sql data-lang=sql><span class=line><span class=cl><span class=k>SELECT</span><span class=w> </span><span class=n>a</span><span class=p>.</span><span class=n>id</span><span class=p>,</span><span class=n>a</span><span class=p>.</span><span class=n>dept</span><span class=p>,</span><span class=n>b</span><span class=p>.</span><span class=n>age</span><span class=w> 
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>FROM</span><span class=w> </span><span class=n>a</span><span class=w> </span><span class=k>join</span><span class=w> </span><span class=n>b</span><span class=w> 
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>ON</span><span class=w> </span><span class=p>(</span><span class=n>a</span><span class=p>.</span><span class=n>id</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>b</span><span class=p>.</span><span class=n>id</span><span class=p>);</span><span class=w>
</span></span></span></code></pre></td></tr></table></div></div><p><img loading=lazy src=https://github.com/Reid00/image-host/raw/main/20221216/image.5rzbfv75s340.webp alt="Common Join"></p><h3 id=hive-map-join>Hive Map Join<a hidden class=anchor aria-hidden=true href=#hive-map-join>#</a></h3><p>MapJoin通常用于一个很小的表和一个大表进行join的场景，具体小表有多小，由参数hive.mapjoin.smalltable.filesize来决定，默认值为25M。满足条件的话Hive在执行时候会自动转化为MapJoin，或使用hint提示 /*+ mapjoin(table) */执行MapJoin。
<img loading=lazy src=https://github.com/Reid00/image-host/raw/main/20221216/image.4sz2rswtp9y0.webp alt=MapJoin></p><p>如上图中的流程，首先Task A在客户端本地执行，负责扫描小表b的数据，将其转换成一个HashTable的数据结构，并写入本地的文件中，之后将该文件加载到DistributeCache中。
接下来的Task B任务是一个没有Reduce的MapReduce，启动MapTasks扫描大表a，在Map阶段，根据a的每一条记录去和DistributeCache中b表对应的HashTable关联，并直接输出结果，因为没有Reduce，所以有多少个Map Task，就有多少个结果文件。
注意：Map JOIN不适合FULL/RIGHT OUTER JOIN。</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://reid00.github.io/en/tags/spark/>Spark</a></li><li><a href=https://reid00.github.io/en/tags/join/>Join</a></li></ul><nav class=paginav><a class=prev href=https://reid00.github.io/en/posts/langs_linux/go-function-option-%E5%87%BD%E6%95%B0%E9%80%89%E9%A1%B9%E6%A8%A1%E5%BC%8F/><span class=title>« Prev</span><br><span>Go Function Option 函数选项模式</span>
</a><a class=next href=https://reid00.github.io/en/posts/os_network/http-502-%E9%97%AE%E9%A2%98-%E6%8E%92%E6%9F%A5/><span class=title>Next »</span><br><span>Http 502 问题 排查</span></a></nav></footer><script src=https://utteranc.es/client.js repo=Reid00/hugo-blog-talks issue-term=pathname label=Comment theme=github-light crossorigin=anonymous async></script></article></main><footer class=footer><span>&copy; 2024 <a href=https://reid00.github.io/en/>Reid's Blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>