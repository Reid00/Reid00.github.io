<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>ES面试题 | Reid's Blog</title><meta name=keywords content="ES,面试"><meta name=description content="ElasticSearch面试题 1.为什么要使用Elasticsearch? 因为在我们商城中的数据，将来会非常多，所以采用以往的模糊查询，模糊查询前置配置，会放弃索引，导致商品查询是全表扫面，在百万级别的数据库中，效率非常低下，而我们使用ES做一个全文索引，我们将经常查询的商品的某些字段，比如说商品名，描述、价格还有id这些字段我们放入我们索引库里，可以提高查询速度。
2.Elasticsearch是如何实现Master选举的？ Elasticsearch的选主是ZenDiscovery模块负责的，主要包含Ping（节点之间通过这个RPC来发现彼此）和Unicast（单播模块包含一个主机列表以控制哪些节点需要ping通）这两部分；
对所有可以成为master的节点（node.master: true）根据nodeId字典排序，每次选举每个节点都把自己所知道节点排一次序，然后选出第一个（第0位）节点，暂且认为它是master节点。 如果对某个节点的投票数达到一定的值（可以成为master节点数n/2+1）并且该节点自己也选举自己，那这个节点就是master。否则重新选举一直到满足上述条件。 补充：master节点的职责主要包括集群、节点和索引的管理，不负责文档级别的管理；data节点可以关闭http功能。 3.Elasticsearch中的节点（比如共20个），其中的10个选了一个master，另外10个选了另一个master，怎么办？ 当集群master候选数量不小于3个时，可以通过设置最少投票通过数量（discovery.zen.minimum_master_nodes）超过所有候选节点一半以上来解决脑裂问题； 当候选数量为两个时，只能修改为唯一的一个master候选，其他作为data节点，避免脑裂问题。
4.详细描述一下Elasticsearch索引文档的过程。 协调节点默认使用文档ID参与计算（也支持通过routing），以便为路由提供合适的分片。 shard = hash(document_id) % (num_of_primary_shards) 当分片所在的节点接收到来自协调节点的请求后，会将请求写入到Memory Buffer，然后定时（默认是每隔1秒）写入到Filesystem Cache，这个从Momery Buffer到Filesystem Cache的过程就叫做refresh； 当然在某些情况下，存在Momery Buffer和Filesystem Cache的数据可能会丢失，ES是通过translog的机制来保证数据的可靠性的。其实现机制是接收到请求后，同时也会写入到translog中，当Filesystem cache中的数据写入到磁盘中时，才会清除掉，这个过程叫做flush； 在flush过程中，内存中的缓冲将被清除，内容被写入一个新段，段的fsync将创建一个新的提交点，并将内容刷新到磁盘，旧的translog将被删除并开始一个新的translog。 flush触发的时机是定时触发（默认30分钟）或者translog变得太大（默认为512M）时；
5.详细描述一下Elasticsearch更新和删除文档的过程 删除和更新也都是写操作，但是Elasticsearch中的文档是不可变的，因此不能被删除或者改动以展示其变更； 磁盘上的每个段都有一个相应的.del文件。当删除请求发送后，文档并没有真的被删除，而是在.del文件中被标记为删除。该文档依然能匹配查询，但是会在结果中被过滤掉。当段合并时，在.del文件中被标记为删除的文档将不会被写入新段。 在新的文档被创建时，Elasticsearch会为该文档指定一个版本号，当执行更新时，旧版本的文档在.del文件中被标记为删除，新版本的文档被索引到一个新段。旧版本的文档依然能匹配查询，但是会在结果中被过滤掉。
6.详细描述一下Elasticsearch搜索的过程 搜索被执行成一个两阶段过程，我们称之为 Query Then Fetch； 在初始查询阶段时，查询会广播到索引中每一个分片拷贝（主分片或者副本分片）。 每个分片在本地执行搜索并构建一个匹配文档的大小为 from + size 的优先队列。PS：在搜索的时候是会查询Filesystem Cache的，但是有部分数据还在Memory Buffer，所以搜索是近实时的。 每个分片返回各自优先队列中 所有文档的 ID 和排序值 给协调节点，它合并这些值到自己的优先队列中来产生一个全局排序后的结果列表。 接下来就是 取回阶段，协调节点辨别出哪些文档需要被取回并向相关的分片提交多个 GET 请求。每个分片加载并 丰富 文档，如果有需要的话，接着返回文档给协调节点。一旦所有的文档都被取回了，协调节点返回结果给客户端。 补充：Query Then Fetch的搜索类型在文档相关性打分的时候参考的是本分片的数据，这样在文档数量较少的时候可能不够准确，DFS Query Then Fetch增加了一个预查询的处理，询问Term和Document frequency，这个评分更准确，但是性能会变差。
9.Elasticsearch对于大数据量（上亿量级）的聚合如何实现？ Elasticsearch 提供的首个近似聚合是cardinality 度量。它提供一个字段的基数，即该字段的distinct或者unique值的数目。它是基于HLL算法的。HLL 会先对我们的输入作哈希运算，然后根据哈希运算的结果中的 bits 做概率估算从而得到基数。其特点是：可配置的精度，用来控制内存的使用（更精确 ＝ 更多内存）；小的数据集精度是非常高的；我们可以通过配置参数，来设置去重需要的固定内存使用量。无论数千还是数十亿的唯一值，内存使用量只与你配置的精确度相关 ."><meta name=author content="Reid"><link rel=canonical href=https://reid00.github.io/post/es%E9%9D%A2%E8%AF%95%E9%A2%98/><link crossorigin=anonymous href=/assets/css/stylesheet.d7fb4cbf980fe688a21621b06a795933c4e6bb2d4070ec940667af1715d84af2.css integrity="sha256-1/tMv5gP5oiiFiGwanlZM8Tmuy1AcOyUBmevFxXYSvI=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://reid00.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://reid00.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://reid00.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://reid00.github.io/apple-touch-icon.png><link rel=mask-icon href=https://reid00.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-QRR6GRNQGK"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag('js',new Date),gtag('config','G-QRR6GRNQGK',{anonymize_ip:!1})}</script><meta property="og:title" content="ES面试题"><meta property="og:description" content="ElasticSearch面试题 1.为什么要使用Elasticsearch? 因为在我们商城中的数据，将来会非常多，所以采用以往的模糊查询，模糊查询前置配置，会放弃索引，导致商品查询是全表扫面，在百万级别的数据库中，效率非常低下，而我们使用ES做一个全文索引，我们将经常查询的商品的某些字段，比如说商品名，描述、价格还有id这些字段我们放入我们索引库里，可以提高查询速度。
2.Elasticsearch是如何实现Master选举的？ Elasticsearch的选主是ZenDiscovery模块负责的，主要包含Ping（节点之间通过这个RPC来发现彼此）和Unicast（单播模块包含一个主机列表以控制哪些节点需要ping通）这两部分；
对所有可以成为master的节点（node.master: true）根据nodeId字典排序，每次选举每个节点都把自己所知道节点排一次序，然后选出第一个（第0位）节点，暂且认为它是master节点。 如果对某个节点的投票数达到一定的值（可以成为master节点数n/2+1）并且该节点自己也选举自己，那这个节点就是master。否则重新选举一直到满足上述条件。 补充：master节点的职责主要包括集群、节点和索引的管理，不负责文档级别的管理；data节点可以关闭http功能。 3.Elasticsearch中的节点（比如共20个），其中的10个选了一个master，另外10个选了另一个master，怎么办？ 当集群master候选数量不小于3个时，可以通过设置最少投票通过数量（discovery.zen.minimum_master_nodes）超过所有候选节点一半以上来解决脑裂问题； 当候选数量为两个时，只能修改为唯一的一个master候选，其他作为data节点，避免脑裂问题。
4.详细描述一下Elasticsearch索引文档的过程。 协调节点默认使用文档ID参与计算（也支持通过routing），以便为路由提供合适的分片。 shard = hash(document_id) % (num_of_primary_shards) 当分片所在的节点接收到来自协调节点的请求后，会将请求写入到Memory Buffer，然后定时（默认是每隔1秒）写入到Filesystem Cache，这个从Momery Buffer到Filesystem Cache的过程就叫做refresh； 当然在某些情况下，存在Momery Buffer和Filesystem Cache的数据可能会丢失，ES是通过translog的机制来保证数据的可靠性的。其实现机制是接收到请求后，同时也会写入到translog中，当Filesystem cache中的数据写入到磁盘中时，才会清除掉，这个过程叫做flush； 在flush过程中，内存中的缓冲将被清除，内容被写入一个新段，段的fsync将创建一个新的提交点，并将内容刷新到磁盘，旧的translog将被删除并开始一个新的translog。 flush触发的时机是定时触发（默认30分钟）或者translog变得太大（默认为512M）时；
5.详细描述一下Elasticsearch更新和删除文档的过程 删除和更新也都是写操作，但是Elasticsearch中的文档是不可变的，因此不能被删除或者改动以展示其变更； 磁盘上的每个段都有一个相应的.del文件。当删除请求发送后，文档并没有真的被删除，而是在.del文件中被标记为删除。该文档依然能匹配查询，但是会在结果中被过滤掉。当段合并时，在.del文件中被标记为删除的文档将不会被写入新段。 在新的文档被创建时，Elasticsearch会为该文档指定一个版本号，当执行更新时，旧版本的文档在.del文件中被标记为删除，新版本的文档被索引到一个新段。旧版本的文档依然能匹配查询，但是会在结果中被过滤掉。
6.详细描述一下Elasticsearch搜索的过程 搜索被执行成一个两阶段过程，我们称之为 Query Then Fetch； 在初始查询阶段时，查询会广播到索引中每一个分片拷贝（主分片或者副本分片）。 每个分片在本地执行搜索并构建一个匹配文档的大小为 from + size 的优先队列。PS：在搜索的时候是会查询Filesystem Cache的，但是有部分数据还在Memory Buffer，所以搜索是近实时的。 每个分片返回各自优先队列中 所有文档的 ID 和排序值 给协调节点，它合并这些值到自己的优先队列中来产生一个全局排序后的结果列表。 接下来就是 取回阶段，协调节点辨别出哪些文档需要被取回并向相关的分片提交多个 GET 请求。每个分片加载并 丰富 文档，如果有需要的话，接着返回文档给协调节点。一旦所有的文档都被取回了，协调节点返回结果给客户端。 补充：Query Then Fetch的搜索类型在文档相关性打分的时候参考的是本分片的数据，这样在文档数量较少的时候可能不够准确，DFS Query Then Fetch增加了一个预查询的处理，询问Term和Document frequency，这个评分更准确，但是性能会变差。
9.Elasticsearch对于大数据量（上亿量级）的聚合如何实现？ Elasticsearch 提供的首个近似聚合是cardinality 度量。它提供一个字段的基数，即该字段的distinct或者unique值的数目。它是基于HLL算法的。HLL 会先对我们的输入作哈希运算，然后根据哈希运算的结果中的 bits 做概率估算从而得到基数。其特点是：可配置的精度，用来控制内存的使用（更精确 ＝ 更多内存）；小的数据集精度是非常高的；我们可以通过配置参数，来设置去重需要的固定内存使用量。无论数千还是数十亿的唯一值，内存使用量只与你配置的精确度相关 ."><meta property="og:type" content="article"><meta property="og:url" content="https://reid00.github.io/post/es%E9%9D%A2%E8%AF%95%E9%A2%98/"><meta property="og:image" content="https://i.loli.net/2021/09/26/3OMGXylm8HUYJ6p.png"><meta property="article:section" content="post"><meta property="article:published_time" content="2022-06-08T14:15:28+08:00"><meta property="article:modified_time" content="2022-06-08T14:15:28+08:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://i.loli.net/2021/09/26/3OMGXylm8HUYJ6p.png"><meta name=twitter:title content="ES面试题"><meta name=twitter:description content="ElasticSearch面试题 1.为什么要使用Elasticsearch? 因为在我们商城中的数据，将来会非常多，所以采用以往的模糊查询，模糊查询前置配置，会放弃索引，导致商品查询是全表扫面，在百万级别的数据库中，效率非常低下，而我们使用ES做一个全文索引，我们将经常查询的商品的某些字段，比如说商品名，描述、价格还有id这些字段我们放入我们索引库里，可以提高查询速度。
2.Elasticsearch是如何实现Master选举的？ Elasticsearch的选主是ZenDiscovery模块负责的，主要包含Ping（节点之间通过这个RPC来发现彼此）和Unicast（单播模块包含一个主机列表以控制哪些节点需要ping通）这两部分；
对所有可以成为master的节点（node.master: true）根据nodeId字典排序，每次选举每个节点都把自己所知道节点排一次序，然后选出第一个（第0位）节点，暂且认为它是master节点。 如果对某个节点的投票数达到一定的值（可以成为master节点数n/2+1）并且该节点自己也选举自己，那这个节点就是master。否则重新选举一直到满足上述条件。 补充：master节点的职责主要包括集群、节点和索引的管理，不负责文档级别的管理；data节点可以关闭http功能。 3.Elasticsearch中的节点（比如共20个），其中的10个选了一个master，另外10个选了另一个master，怎么办？ 当集群master候选数量不小于3个时，可以通过设置最少投票通过数量（discovery.zen.minimum_master_nodes）超过所有候选节点一半以上来解决脑裂问题； 当候选数量为两个时，只能修改为唯一的一个master候选，其他作为data节点，避免脑裂问题。
4.详细描述一下Elasticsearch索引文档的过程。 协调节点默认使用文档ID参与计算（也支持通过routing），以便为路由提供合适的分片。 shard = hash(document_id) % (num_of_primary_shards) 当分片所在的节点接收到来自协调节点的请求后，会将请求写入到Memory Buffer，然后定时（默认是每隔1秒）写入到Filesystem Cache，这个从Momery Buffer到Filesystem Cache的过程就叫做refresh； 当然在某些情况下，存在Momery Buffer和Filesystem Cache的数据可能会丢失，ES是通过translog的机制来保证数据的可靠性的。其实现机制是接收到请求后，同时也会写入到translog中，当Filesystem cache中的数据写入到磁盘中时，才会清除掉，这个过程叫做flush； 在flush过程中，内存中的缓冲将被清除，内容被写入一个新段，段的fsync将创建一个新的提交点，并将内容刷新到磁盘，旧的translog将被删除并开始一个新的translog。 flush触发的时机是定时触发（默认30分钟）或者translog变得太大（默认为512M）时；
5.详细描述一下Elasticsearch更新和删除文档的过程 删除和更新也都是写操作，但是Elasticsearch中的文档是不可变的，因此不能被删除或者改动以展示其变更； 磁盘上的每个段都有一个相应的.del文件。当删除请求发送后，文档并没有真的被删除，而是在.del文件中被标记为删除。该文档依然能匹配查询，但是会在结果中被过滤掉。当段合并时，在.del文件中被标记为删除的文档将不会被写入新段。 在新的文档被创建时，Elasticsearch会为该文档指定一个版本号，当执行更新时，旧版本的文档在.del文件中被标记为删除，新版本的文档被索引到一个新段。旧版本的文档依然能匹配查询，但是会在结果中被过滤掉。
6.详细描述一下Elasticsearch搜索的过程 搜索被执行成一个两阶段过程，我们称之为 Query Then Fetch； 在初始查询阶段时，查询会广播到索引中每一个分片拷贝（主分片或者副本分片）。 每个分片在本地执行搜索并构建一个匹配文档的大小为 from + size 的优先队列。PS：在搜索的时候是会查询Filesystem Cache的，但是有部分数据还在Memory Buffer，所以搜索是近实时的。 每个分片返回各自优先队列中 所有文档的 ID 和排序值 给协调节点，它合并这些值到自己的优先队列中来产生一个全局排序后的结果列表。 接下来就是 取回阶段，协调节点辨别出哪些文档需要被取回并向相关的分片提交多个 GET 请求。每个分片加载并 丰富 文档，如果有需要的话，接着返回文档给协调节点。一旦所有的文档都被取回了，协调节点返回结果给客户端。 补充：Query Then Fetch的搜索类型在文档相关性打分的时候参考的是本分片的数据，这样在文档数量较少的时候可能不够准确，DFS Query Then Fetch增加了一个预查询的处理，询问Term和Document frequency，这个评分更准确，但是性能会变差。
9.Elasticsearch对于大数据量（上亿量级）的聚合如何实现？ Elasticsearch 提供的首个近似聚合是cardinality 度量。它提供一个字段的基数，即该字段的distinct或者unique值的数目。它是基于HLL算法的。HLL 会先对我们的输入作哈希运算，然后根据哈希运算的结果中的 bits 做概率估算从而得到基数。其特点是：可配置的精度，用来控制内存的使用（更精确 ＝ 更多内存）；小的数据集精度是非常高的；我们可以通过配置参数，来设置去重需要的固定内存使用量。无论数千还是数十亿的唯一值，内存使用量只与你配置的精确度相关 ."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://reid00.github.io/post/"},{"@type":"ListItem","position":2,"name":"ES面试题","item":"https://reid00.github.io/post/es%E9%9D%A2%E8%AF%95%E9%A2%98/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"ES面试题","name":"ES面试题","description":"ElasticSearch面试题 1.为什么要使用Elasticsearch? 因为在我们商城中的数据，将来会非常多，所以采用以往的模糊查询，模糊查询前置配置，会放弃索引，导致商品查询是全表扫面，在百万级别的数据库中，效率非常低下，而我们使用ES做一个全文索引，我们将经常查询的商品的某些字段，比如说商品名，描述、价格还有id这些字段我们放入我们索引库里，可以提高查询速度。\n2.Elasticsearch是如何实现Master选举的？ Elasticsearch的选主是ZenDiscovery模块负责的，主要包含Ping（节点之间通过这个RPC来发现彼此）和Unicast（单播模块包含一个主机列表以控制哪些节点需要ping通）这两部分；\n对所有可以成为master的节点（node.master: true）根据nodeId字典排序，每次选举每个节点都把自己所知道节点排一次序，然后选出第一个（第0位）节点，暂且认为它是master节点。 如果对某个节点的投票数达到一定的值（可以成为master节点数n/2+1）并且该节点自己也选举自己，那这个节点就是master。否则重新选举一直到满足上述条件。 补充：master节点的职责主要包括集群、节点和索引的管理，不负责文档级别的管理；data节点可以关闭http功能。 3.Elasticsearch中的节点（比如共20个），其中的10个选了一个master，另外10个选了另一个master，怎么办？ 当集群master候选数量不小于3个时，可以通过设置最少投票通过数量（discovery.zen.minimum_master_nodes）超过所有候选节点一半以上来解决脑裂问题； 当候选数量为两个时，只能修改为唯一的一个master候选，其他作为data节点，避免脑裂问题。\n4.详细描述一下Elasticsearch索引文档的过程。 协调节点默认使用文档ID参与计算（也支持通过routing），以便为路由提供合适的分片。 shard = hash(document_id) % (num_of_primary_shards) 当分片所在的节点接收到来自协调节点的请求后，会将请求写入到Memory Buffer，然后定时（默认是每隔1秒）写入到Filesystem Cache，这个从Momery Buffer到Filesystem Cache的过程就叫做refresh； 当然在某些情况下，存在Momery Buffer和Filesystem Cache的数据可能会丢失，ES是通过translog的机制来保证数据的可靠性的。其实现机制是接收到请求后，同时也会写入到translog中，当Filesystem cache中的数据写入到磁盘中时，才会清除掉，这个过程叫做flush； 在flush过程中，内存中的缓冲将被清除，内容被写入一个新段，段的fsync将创建一个新的提交点，并将内容刷新到磁盘，旧的translog将被删除并开始一个新的translog。 flush触发的时机是定时触发（默认30分钟）或者translog变得太大（默认为512M）时；\n5.详细描述一下Elasticsearch更新和删除文档的过程 删除和更新也都是写操作，但是Elasticsearch中的文档是不可变的，因此不能被删除或者改动以展示其变更； 磁盘上的每个段都有一个相应的.del文件。当删除请求发送后，文档并没有真的被删除，而是在.del文件中被标记为删除。该文档依然能匹配查询，但是会在结果中被过滤掉。当段合并时，在.del文件中被标记为删除的文档将不会被写入新段。 在新的文档被创建时，Elasticsearch会为该文档指定一个版本号，当执行更新时，旧版本的文档在.del文件中被标记为删除，新版本的文档被索引到一个新段。旧版本的文档依然能匹配查询，但是会在结果中被过滤掉。\n6.详细描述一下Elasticsearch搜索的过程 搜索被执行成一个两阶段过程，我们称之为 Query Then Fetch； 在初始查询阶段时，查询会广播到索引中每一个分片拷贝（主分片或者副本分片）。 每个分片在本地执行搜索并构建一个匹配文档的大小为 from + size 的优先队列。PS：在搜索的时候是会查询Filesystem Cache的，但是有部分数据还在Memory Buffer，所以搜索是近实时的。 每个分片返回各自优先队列中 所有文档的 ID 和排序值 给协调节点，它合并这些值到自己的优先队列中来产生一个全局排序后的结果列表。 接下来就是 取回阶段，协调节点辨别出哪些文档需要被取回并向相关的分片提交多个 GET 请求。每个分片加载并 丰富 文档，如果有需要的话，接着返回文档给协调节点。一旦所有的文档都被取回了，协调节点返回结果给客户端。 补充：Query Then Fetch的搜索类型在文档相关性打分的时候参考的是本分片的数据，这样在文档数量较少的时候可能不够准确，DFS Query Then Fetch增加了一个预查询的处理，询问Term和Document frequency，这个评分更准确，但是性能会变差。\n9.Elasticsearch对于大数据量（上亿量级）的聚合如何实现？ Elasticsearch 提供的首个近似聚合是cardinality 度量。它提供一个字段的基数，即该字段的distinct或者unique值的数目。它是基于HLL算法的。HLL 会先对我们的输入作哈希运算，然后根据哈希运算的结果中的 bits 做概率估算从而得到基数。其特点是：可配置的精度，用来控制内存的使用（更精确 ＝ 更多内存）；小的数据集精度是非常高的；我们可以通过配置参数，来设置去重需要的固定内存使用量。无论数千还是数十亿的唯一值，内存使用量只与你配置的精确度相关 .","keywords":["ES","面试"],"articleBody":"ElasticSearch面试题 1.为什么要使用Elasticsearch? 因为在我们商城中的数据，将来会非常多，所以采用以往的模糊查询，模糊查询前置配置，会放弃索引，导致商品查询是全表扫面，在百万级别的数据库中，效率非常低下，而我们使用ES做一个全文索引，我们将经常查询的商品的某些字段，比如说商品名，描述、价格还有id这些字段我们放入我们索引库里，可以提高查询速度。\n2.Elasticsearch是如何实现Master选举的？ Elasticsearch的选主是ZenDiscovery模块负责的，主要包含Ping（节点之间通过这个RPC来发现彼此）和Unicast（单播模块包含一个主机列表以控制哪些节点需要ping通）这两部分；\n对所有可以成为master的节点（node.master: true）根据nodeId字典排序，每次选举每个节点都把自己所知道节点排一次序，然后选出第一个（第0位）节点，暂且认为它是master节点。 如果对某个节点的投票数达到一定的值（可以成为master节点数n/2+1）并且该节点自己也选举自己，那这个节点就是master。否则重新选举一直到满足上述条件。 补充：master节点的职责主要包括集群、节点和索引的管理，不负责文档级别的管理；data节点可以关闭http功能。 3.Elasticsearch中的节点（比如共20个），其中的10个选了一个master，另外10个选了另一个master，怎么办？ 当集群master候选数量不小于3个时，可以通过设置最少投票通过数量（discovery.zen.minimum_master_nodes）超过所有候选节点一半以上来解决脑裂问题； 当候选数量为两个时，只能修改为唯一的一个master候选，其他作为data节点，避免脑裂问题。\n4.详细描述一下Elasticsearch索引文档的过程。 协调节点默认使用文档ID参与计算（也支持通过routing），以便为路由提供合适的分片。 shard = hash(document_id) % (num_of_primary_shards) 当分片所在的节点接收到来自协调节点的请求后，会将请求写入到Memory Buffer，然后定时（默认是每隔1秒）写入到Filesystem Cache，这个从Momery Buffer到Filesystem Cache的过程就叫做refresh； 当然在某些情况下，存在Momery Buffer和Filesystem Cache的数据可能会丢失，ES是通过translog的机制来保证数据的可靠性的。其实现机制是接收到请求后，同时也会写入到translog中，当Filesystem cache中的数据写入到磁盘中时，才会清除掉，这个过程叫做flush； 在flush过程中，内存中的缓冲将被清除，内容被写入一个新段，段的fsync将创建一个新的提交点，并将内容刷新到磁盘，旧的translog将被删除并开始一个新的translog。 flush触发的时机是定时触发（默认30分钟）或者translog变得太大（默认为512M）时；\n5.详细描述一下Elasticsearch更新和删除文档的过程 删除和更新也都是写操作，但是Elasticsearch中的文档是不可变的，因此不能被删除或者改动以展示其变更； 磁盘上的每个段都有一个相应的.del文件。当删除请求发送后，文档并没有真的被删除，而是在.del文件中被标记为删除。该文档依然能匹配查询，但是会在结果中被过滤掉。当段合并时，在.del文件中被标记为删除的文档将不会被写入新段。 在新的文档被创建时，Elasticsearch会为该文档指定一个版本号，当执行更新时，旧版本的文档在.del文件中被标记为删除，新版本的文档被索引到一个新段。旧版本的文档依然能匹配查询，但是会在结果中被过滤掉。\n6.详细描述一下Elasticsearch搜索的过程 搜索被执行成一个两阶段过程，我们称之为 Query Then Fetch； 在初始查询阶段时，查询会广播到索引中每一个分片拷贝（主分片或者副本分片）。 每个分片在本地执行搜索并构建一个匹配文档的大小为 from + size 的优先队列。PS：在搜索的时候是会查询Filesystem Cache的，但是有部分数据还在Memory Buffer，所以搜索是近实时的。 每个分片返回各自优先队列中 所有文档的 ID 和排序值 给协调节点，它合并这些值到自己的优先队列中来产生一个全局排序后的结果列表。 接下来就是 取回阶段，协调节点辨别出哪些文档需要被取回并向相关的分片提交多个 GET 请求。每个分片加载并 丰富 文档，如果有需要的话，接着返回文档给协调节点。一旦所有的文档都被取回了，协调节点返回结果给客户端。 补充：Query Then Fetch的搜索类型在文档相关性打分的时候参考的是本分片的数据，这样在文档数量较少的时候可能不够准确，DFS Query Then Fetch增加了一个预查询的处理，询问Term和Document frequency，这个评分更准确，但是性能会变差。\n9.Elasticsearch对于大数据量（上亿量级）的聚合如何实现？ Elasticsearch 提供的首个近似聚合是cardinality 度量。它提供一个字段的基数，即该字段的distinct或者unique值的数目。它是基于HLL算法的。HLL 会先对我们的输入作哈希运算，然后根据哈希运算的结果中的 bits 做概率估算从而得到基数。其特点是：可配置的精度，用来控制内存的使用（更精确 ＝ 更多内存）；小的数据集精度是非常高的；我们可以通过配置参数，来设置去重需要的固定内存使用量。无论数千还是数十亿的唯一值，内存使用量只与你配置的精确度相关 .\n10.在并发情况下，Elasticsearch如果保证读写一致？ 可以通过版本号使用乐观并发控制，以确保新版本不会被旧版本覆盖，由应用层来处理具体的冲突； 另外对于写操作，一致性级别支持quorum/one/all，默认为quorum，即只有当大多数分片可用时才允许写操作。但即使大多数可用，也可能存在因为网络等原因导致写入副本失败，这样该副本被认为故障，分片将会在一个不同的节点上重建。 对于读操作，可以设置replication为sync(默认)，这使得操作在主分片和副本分片都完成后才会返回；如果设置replication为async时，也可以通过设置搜索请求参数_preference为primary来查询主分片，确保文档是最新版本。\n14.ElasticSearch中的集群、节点、索引、文档、类型是什么？ 群集是一个或多个节点（服务器）的集合，它们共同保存您的整个数据，并提供跨所有节点的联合索引和搜索功能。群集由唯一名称标识，默认情况下为“elasticsearch”。此名称很重要，因为如果节点设置为按名称加入群集，则该节点只能是群集的一部分。 节点是属于集群一部分的单个服务器。它存储数据并参与群集索引和搜索功能。 索引就像关系数据库中的“数据库”。它有一个定义多种类型的映射。索引是逻辑名称空间，映射到一个或多个主分片，并且可以有零个或多个副本分片。 MySQL =\u003e数据库 ElasticSearch =\u003e索引 文档类似于关系数据库中的一行。不同之处在于索引中的每个文档可以具有不同的结构（字段），但是对于通用字段应该具有相同的数据类型。 MySQL =\u003e Databases =\u003e Tables =\u003e Columns / Rows ElasticSearch =\u003e Indices =\u003e Types =\u003e具有属性的文档 类型是索引的逻辑类别/分区，其语义完全取决于用户。\n15.ElasticSearch中的分片是什么? 在大多数环境中，每个节点都在单独的盒子或虚拟机上运行。\n索引 - 在Elasticsearch中，索引是文档的集合。 分片 -因为Elasticsearch是一个分布式搜索引擎，所以索引通常被分割成分布在多个节点上的被称为分片的元素。\n问题四：\nElasticSearch中的集群、节点、索引、文档、类型是什么？\n群集是一个或多个节点（服务器）的集合，它们共同保存您的整个数据，并提供跨所有节点的联合索引和搜索功能。群集由唯一名称标识，默认情况下为“elasticsearch”。此名称很重要，因为如果节点设置为按名称加入群集，则该节点只能是群集的一部分。 节点是属于集群一部分的单个服务器。它存储数据并参与群集索引和搜索功能。 索引就像关系数据库中的“数据库”。它有一个定义多种类型的映射。索引是逻辑名称空间，映射到一个或多个主分片，并且可以有零个或多个副本分片。 MySQL =\u003e数据库 ElasticSearch =\u003e索引 文档类似于关系数据库中的一行。不同之处在于索引中的每个文档可以具有不同的结构（字段），但是对于通用字段应该具有相同的数据类型。 MySQL =\u003e Databases =\u003e Tables =\u003e Columns / Rows ElasticSearch =\u003e Indices =\u003e Types =\u003e具有属性的文档 类型是索引的逻辑类别/分区，其语义完全取决于用户。 问题五：\nElasticSearch是否有架构？\nElasticSearch可以有一个架构。架构是描述文档类型以及如何处理文档的不同字段的一个或多个字段的描述。Elasticsearch中的架构是一种映射，它描述了JSON文档中的字段及其数据类型，以及它们应该如何在Lucene索引中进行索引。因此，在Elasticsearch术语中，我们通常将此模式称为“映射”。\nElasticsearch具有架构灵活的能力，这意味着可以在不明确提供架构的情况下索引文档。如果未指定映射，则默认情况下，Elasticsearch会在索引期间检测文档中的新字段时动态生成一个映射。\n问题六：\nElasticSearch中的分片是什么？\n在大多数环境中，每个节点都在单独的盒子或虚拟机上运行。\n索引 - 在Elasticsearch中，索引是文档的集合。 分片 -因为Elasticsearch是一个分布式搜索引擎，所以索引通常被分割成分布在多个节点上的被称为分片的元素。 问题七：\nElasticSearch中的副本是什么？\n一个索引被分解成碎片以便于分发和扩展。副本是分片的副本。一个节点是一个属于一个集群的ElasticSearch的运行实例。一个集群由一个或多个共享相同集群名称的节点组成。\n问题八：\nElasticSearch中的分析器是什么？\n在ElasticSearch中索引数据时，数据由为索引定义的Analyzer在内部进行转换。 分析器由一个Tokenizer和零个或多个TokenFilter组成。编译器可以在一个或多个CharFilter之前。分析模块允许您在逻辑名称下注册分析器，然后可以在映射定义或某些API中引用它们。\nElasticsearch附带了许多可以随时使用的预建分析器。或者，您可以组合内置的字符过滤器，编译器和过滤器器来创建自定义分析器。\n问题九：\n什么是ElasticSearch中的编译器？\n编译器用于将字符串分解为术语或标记流。一个简单的编译器可能会将字符串拆分为任何遇到空格或标点的地方。Elasticsearch有许多内置标记器，可用于构建自定义分析器。\n问题十一：\n启用属性，索引和存储的用途是什么？\nenabled属性适用于各类ElasticSearch特定/创建领域，如index和size。用户提供的字段没有“已启用”属性。 存储意味着数据由Lucene存储，如果询问，将返回这些数据。\n存储字段不一定是可搜索的。默认情况下，字段不存储，但源文件是完整的。因为您希望使用默认值(这是有意义的)，所以不要设置store属性 该指数属性用于搜索。\n索引属性只能用于搜索。只有索引域可以进行搜索。差异的原因是在分析期间对索引字段进行了转换，因此如果需要的话，您不能检索原始数据。\n（网络搜集-博客园）\n第二部分面试题 es 写入数据的工作原理是什么啊？es 查询数据的工作原理是什么啊？底层的 lucene 介绍一下呗？倒排索引了解吗？\n面试官心理分析 问这个，其实面试官就是要看看你了解不了解 es 的一些基本原理，因为用 es 无非就是写入数据，搜索数据。你要是不明白你发起一个写入和搜索请求的时候，es 在干什么，那你真的是……对 es 基本就是个黑盒，你还能干啥？你唯一能干的就是用 es 的 api 读写数据了。要是出点什么问题，你啥都不知道，那还能指望你什么呢？\nes 写数据过程 客户端选择一个 node 发送请求过去，这个 node 就是 coordinating node（协调节点）。 coordinating node 对 document 进行路由，将请求转发给对应的 node（有 primary shard）。[路由的算法是？] 实际的 node 上的 primary shard 处理请求，然后将数据同步到 replica node。 coordinating node 如果发现 primary node 和所有 replica node 都搞定之后，就返回响应结果给客户端。 es 读数据过程 可以通过 doc id 来查询，会根据 doc id 进行 hash，判断出来当时把 doc id 分配到了哪个 shard 上面去，从那个 shard 去查询。\n客户端发送请求到任意一个 node，成为 coordinate node。 coordinate node 对 doc id 进行哈希路由，将请求转发到对应的 node，此时会使用 round-robin随机轮询算法，在 primary shard 以及其所有 replica 中随机选择一个，让读请求负载均衡。 接收请求的 node 返回 document 给 coordinate node。 coordinate node 返回 document 给客户端。 写请求是写入 primary shard，然后同步给所有的 replica shard；读请求可以从 primary shard 或 replica shard 读取，采用的是随机轮询算法。\nes 搜索数据过程[是指search?search和普通docid get的背后逻辑不一样？] es 最强大的是做全文检索，就是比如你有三条数据：\njava真好玩儿啊 java好难学啊 j2ee特别牛 你根据 java 关键词来搜索，将包含 java的 document 给搜索出来。es 就会给你返回：java真好玩儿啊，java好难学啊。\n客户端发送请求到一个 coordinate node。 协调节点将搜索请求转发到所有的 shard 对应的 primary shard 或 replica shard，都可以。 query phase：每个 shard 将自己的搜索结果（其实就是一些 doc id）返回给协调节点，由协调节点进行数据的合并、排序、分页等操作，产出最终结果。 fetch phase：接着由协调节点根据 doc id 去各个节点上拉取实际的 document 数据，最终返回给客户端。 写数据底层原理 1）document先写入导内存buffer中，同时写translog日志\n2)）https://www.elastic.co/guide/cn/elasticsearch/guide/current/near-real-time.html\nrefresh操作所以近实时搜索：写入和打开一个新段(一个追加的倒排索引)的轻量的过程叫做 *refresh* 。每隔一秒钟把buffer中的数据创建一个新的segment，这里新段会被先写入到文件系统缓存–这一步代价会比较低，稍后再被刷新到磁盘–这一步代价比较高。不过只要文件已经在缓存中， 就可以像其它文件一样被打开和读取了，内存buffer被清空。此时，新segment 中的文件就可以被搜索了，这就意味着document从被写入到可以被搜索需要一秒种，如果要更改这个属性，可以执行以下操作\nPUT /my_index { “settings”: { “refresh_interval”: “30s” } } 3）https://www.elastic.co/guide/cn/elasticsearch/guide/current/translog.html\nflush操作导致持久化变更：执行一个提交并且截断 translog 的行为在 Elasticsearch 被称作一次 *flush。*刷新（refresh）完成后, 缓存被清空但是事务日志不会。translog日志也会越来越多，当translog日志大小大于一个阀值时候或30分钟，会出发flush操作。\n所有在内存缓冲区的文档都被写入一个新的段。 缓冲区被清空。 一个提交点被写入硬盘。（表明有哪些segment commit了） 文件系统缓存通过 fsync 到磁盘。 老的 translog 被删除。 分片每30分钟被自动刷新（flush），或者在 translog 太大的时候也会刷新。也可以用_flush命令手动执行。\ntranslog每隔5秒会被写入磁盘（所以如果这5s，数据在cache而且log没持久化会丢失）。在一次增删改操作之后translog只有在replica和primary shard都成功才会成功，如果要提高操作速度，可以设置成异步的\nPUT /my_index { “settings”: { “index.translog.durability”: “async” ,\n“index.translog.sync_interval”:“5s” } }\n所以总结是有三个批次操作，一秒做一次refresh保证近实时搜索，5秒做一次translog持久化保证数据未持久化前留底，30分钟做一次数据持久化。\n2.基于translog和commit point的数据恢复\n在磁盘上会有一个上次持久化的commit point，translog上有一个commit point，根据这两个commit point，会把translog中的变更记录进行回放，重新执行之前的操作\n3.不变形下的删除和更新原理\nhttps://www.elastic.co/guide/cn/elasticsearch/guide/current/dynamic-indices.html#deletes-and-updates\n一个文档被 “删除” 时，它实际上只是在 .del 文件中被 标记 删除。一个被标记删除的文档仍然可以被查询匹配到， 但它会在最终结果被返回前从结果集中移除。\n文档更新也是类似的操作方式：当一个文档被更新时，旧版本文档被标记删除，文档的新版本被索引到一个新的段中。 可能两个版本的文档都会被一个查询匹配到，但被删除的那个旧版本文档在结果集返回前就已经被移除。\n段合并的时候会将那些旧的已删除文档 从文件系统中清除。 被删除的文档（或被更新文档的旧版本）不会被拷贝到新的大段中。\n4.merge操作，段合并\nhttps://www.elastic.co/guide/cn/elasticsearch/guide/current/merge-process.html\n由于每秒会把buffer刷到segment中，所以segment会很多，为了防止这种情况出现，es内部会不断把一些相似大小的segment合并，并且物理删除del的segment。\n当然也可以手动执行\nPOST /my_index/_optimize?max_num_segments=1，尽量不要手动执行，让它自动默认执行就可以了\n5.当你正在建立一个大的新索引时（相当于直接全部写入buffer，先不refresh，写完再refresh），可以先关闭自动刷新，待开始使用该索引时，再把它们调回来：\n1 2 3 4 5 PUT /my_logs/_settings { \"refresh_interval\": -1 } PUT /my_logs/_settings { \"refresh_interval\": \"1s\" } 底层 lucene 简单来说，lucene 就是一个 jar 包，里面包含了封装好的各种建立倒排索引的算法代码。我们用 Java 开发的时候，引入 lucene jar，然后基于 lucene 的 api 去开发就可以了。\n通过 lucene，我们可以将已有的数据建立索引，lucene 会在本地磁盘上面，给我们组织索引的数据结构。\n倒排索引 在搜索引擎中，每个文档都有一个对应的文档 ID，文档内容被表示为一系列关键词的集合。例如，文档 1 经过分词，提取了 20 个关键词，每个关键词都会记录它在文档中出现的次数和出现位置。\n那么，倒排索引就是关键词到文档 ID 的映射，每个关键词都对应着一系列的文件，这些文件中都出现了关键词。\n举个栗子。\n有以下文档：\n对文档进行分词之后，得到以下倒排索引。\n另外，实用的倒排索引还可以记录更多的信息，比如文档频率信息，表示在文档集合中有多少个文档包含某个单词。\n那么，有了倒排索引，搜索引擎可以很方便地响应用户的查询。比如用户输入查询 Facebook，搜索系统查找倒排索引，从中读出包含这个单词的文档，这些文档就是提供给用户的搜索结果。\n要注意倒排索引的两个重要细节：\n倒排索引中的所有词项对应一个或多个文档 倒排索引中的词项根据字典顺序升序排列 上面只是一个简单的例子，并没有严格按照字典顺序升序排列。\n参考:\nhttps://zhuanlan.zhihu.com/p/139762008 https://zhuanlan.zhihu.com/p/102500311 ","wordCount":"454","inLanguage":"en","datePublished":"2022-06-08T14:15:28+08:00","dateModified":"2022-06-08T14:15:28+08:00","author":[{"@type":"Person","name":"Reid"}],"mainEntityOfPage":{"@type":"WebPage","@id":"https://reid00.github.io/post/es%E9%9D%A2%E8%AF%95%E9%A2%98/"},"publisher":{"@type":"Organization","name":"Reid's Blog","logo":{"@type":"ImageObject","url":"https://reid00.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add('dark'):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove('dark'):window.matchMedia('(prefers-color-scheme: dark)').matches&&document.body.classList.add('dark')</script><header class=header><nav class=nav><div class=logo><a href=https://reid00.github.io/ accesskey=h title="Reid's Blog (Alt + H)">Reid's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://reid00.github.io/archives title=Archive><span>Archive</span></a></li><li><a href=https://reid00.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://reid00.github.io/categories/ title=Categorys><span>Categorys</span></a></li><li><a href=https://reid00.github.io/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://reid00.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://reid00.github.io/post/>Posts</a></div><h1 class=post-title>ES面试题</h1><div class=post-meta><span title='2022-06-08 14:15:28 +0800 +0800'>2022-06-08</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;Reid</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#elasticsearch%e9%9d%a2%e8%af%95%e9%a2%98 aria-label=ElasticSearch面试题>ElasticSearch面试题</a><ul><ul><li><a href=#1%e4%b8%ba%e4%bb%80%e4%b9%88%e8%a6%81%e4%bd%bf%e7%94%a8elasticsearch aria-label=1.为什么要使用Elasticsearch?><strong>1.为什么要使用Elasticsearch?</strong></a></li><li><a href=#2elasticsearch%e6%98%af%e5%a6%82%e4%bd%95%e5%ae%9e%e7%8e%b0master%e9%80%89%e4%b8%be%e7%9a%84 aria-label=2.Elasticsearch是如何实现Master选举的？><strong>2.Elasticsearch是如何实现Master选举的？</strong></a></li><li><a href=#3elasticsearch%e4%b8%ad%e7%9a%84%e8%8a%82%e7%82%b9%e6%af%94%e5%a6%82%e5%85%b120%e4%b8%aa%e5%85%b6%e4%b8%ad%e7%9a%8410%e4%b8%aa%e9%80%89%e4%ba%86%e4%b8%80%e4%b8%aamaster%e5%8f%a6%e5%a4%9610%e4%b8%aa%e9%80%89%e4%ba%86%e5%8f%a6%e4%b8%80%e4%b8%aamaster%e6%80%8e%e4%b9%88%e5%8a%9e aria-label=3.Elasticsearch中的节点（比如共20个），其中的10个选了一个master，另外10个选了另一个master，怎么办？><strong>3.Elasticsearch中的节点（比如共20个），其中的10个选了一个master，另外10个选了另一个master，怎么办？</strong></a></li><li><a href=#4%e8%af%a6%e7%bb%86%e6%8f%8f%e8%bf%b0%e4%b8%80%e4%b8%8belasticsearch%e7%b4%a2%e5%bc%95%e6%96%87%e6%a1%a3%e7%9a%84%e8%bf%87%e7%a8%8b aria-label=4.详细描述一下Elasticsearch索引文档的过程。><strong>4.详细描述一下Elasticsearch索引文档的过程。</strong></a></li><li><a href=#5%e8%af%a6%e7%bb%86%e6%8f%8f%e8%bf%b0%e4%b8%80%e4%b8%8belasticsearch%e6%9b%b4%e6%96%b0%e5%92%8c%e5%88%a0%e9%99%a4%e6%96%87%e6%a1%a3%e7%9a%84%e8%bf%87%e7%a8%8b aria-label=5.详细描述一下Elasticsearch更新和删除文档的过程><strong>5.详细描述一下Elasticsearch更新和删除文档的过程</strong></a></li><li><a href=#6%e8%af%a6%e7%bb%86%e6%8f%8f%e8%bf%b0%e4%b8%80%e4%b8%8belasticsearch%e6%90%9c%e7%b4%a2%e7%9a%84%e8%bf%87%e7%a8%8b aria-label=6.详细描述一下Elasticsearch搜索的过程><strong>6.详细描述一下Elasticsearch搜索的过程</strong></a></li><li><a href=#9elasticsearch%e5%af%b9%e4%ba%8e%e5%a4%a7%e6%95%b0%e6%8d%ae%e9%87%8f%e4%b8%8a%e4%ba%bf%e9%87%8f%e7%ba%a7%e7%9a%84%e8%81%9a%e5%90%88%e5%a6%82%e4%bd%95%e5%ae%9e%e7%8e%b0 aria-label=9.Elasticsearch对于大数据量（上亿量级）的聚合如何实现？><strong>9.Elasticsearch对于大数据量（上亿量级）的聚合如何实现？</strong></a></li><li><a href=#10%e5%9c%a8%e5%b9%b6%e5%8f%91%e6%83%85%e5%86%b5%e4%b8%8belasticsearch%e5%a6%82%e6%9e%9c%e4%bf%9d%e8%af%81%e8%af%bb%e5%86%99%e4%b8%80%e8%87%b4 aria-label=10.在并发情况下，Elasticsearch如果保证读写一致？><strong>10.在并发情况下，Elasticsearch如果保证读写一致？</strong></a></li><li><a href=#14elasticsearch%e4%b8%ad%e7%9a%84%e9%9b%86%e7%be%a4%e8%8a%82%e7%82%b9%e7%b4%a2%e5%bc%95%e6%96%87%e6%a1%a3%e7%b1%bb%e5%9e%8b%e6%98%af%e4%bb%80%e4%b9%88 aria-label=14.ElasticSearch中的集群、节点、索引、文档、类型是什么？><strong>14.ElasticSearch中的集群、节点、索引、文档、类型是什么？</strong></a></li><li><a href=#15elasticsearch%e4%b8%ad%e7%9a%84%e5%88%86%e7%89%87%e6%98%af%e4%bb%80%e4%b9%88 aria-label=15.ElasticSearch中的分片是什么?><strong>15.ElasticSearch中的分片是什么?</strong></a></li></ul><li><a href=#%e7%ac%ac%e4%ba%8c%e9%83%a8%e5%88%86%e9%9d%a2%e8%af%95%e9%a2%98 aria-label=第二部分面试题>第二部分面试题</a></li><li><a href=#%e9%9d%a2%e8%af%95%e5%ae%98%e5%bf%83%e7%90%86%e5%88%86%e6%9e%90 aria-label=面试官心理分析>面试官心理分析</a><ul><li><a href=#es-%e5%86%99%e6%95%b0%e6%8d%ae%e8%bf%87%e7%a8%8b aria-label="es 写数据过程">es 写数据过程</a></li></ul></li><li><a href=#es-%e8%af%bb%e6%95%b0%e6%8d%ae%e8%bf%87%e7%a8%8b aria-label="es 读数据过程">es 读数据过程</a></li><li><a href=#es-%e6%90%9c%e7%b4%a2%e6%95%b0%e6%8d%ae%e8%bf%87%e7%a8%8b%e6%98%af%e6%8c%87searchsearch%e5%92%8c%e6%99%ae%e9%80%9adocid-get%e7%9a%84%e8%83%8c%e5%90%8e%e9%80%bb%e8%be%91%e4%b8%8d%e4%b8%80%e6%a0%b7 aria-label="es 搜索数据过程[是指search?search和普通docid get的背后逻辑不一样？]">es 搜索数据过程[是指search?search和普通docid get的背后逻辑不一样？]</a><ul><li><a href=#%e5%86%99%e6%95%b0%e6%8d%ae%e5%ba%95%e5%b1%82%e5%8e%9f%e7%90%86 aria-label=写数据底层原理>写数据底层原理</a></li><li><a href=#%e5%ba%95%e5%b1%82-lucene aria-label="底层 lucene">底层 lucene</a></li><li><a href=#%e5%80%92%e6%8e%92%e7%b4%a2%e5%bc%95 aria-label=倒排索引>倒排索引</a></li></ul></li></ul></li></ul></div></details></div><div class=post-content><h1 id=elasticsearch面试题>ElasticSearch面试题<a hidden class=anchor aria-hidden=true href=#elasticsearch面试题>#</a></h1><h3 id=1为什么要使用elasticsearch><strong>1.为什么要使用Elasticsearch?</strong><a hidden class=anchor aria-hidden=true href=#1为什么要使用elasticsearch>#</a></h3><p>因为在我们商城中的数据，将来会非常多，所以采用以往的模糊查询，模糊查询前置配置，会放弃索引，导致商品查询是全表扫面，在百万级别的数据库中，效率非常低下，而我们使用ES做一个全文索引，我们将经常查询的商品的某些字段，比如说商品名，描述、价格还有id这些字段我们放入我们索引库里，可以提高查询速度。</p><h3 id=2elasticsearch是如何实现master选举的><strong>2.Elasticsearch是如何实现Master选举的？</strong><a hidden class=anchor aria-hidden=true href=#2elasticsearch是如何实现master选举的>#</a></h3><p>Elasticsearch的选主是ZenDiscovery模块负责的，主要包含Ping（节点之间通过这个RPC来发现彼此）和Unicast（单播模块包含一个主机列表以控制哪些节点需要ping通）这两部分；</p><ul><li>对所有可以成为master的节点（node.master: true）根据nodeId字典排序，每次选举每个节点都把自己所知道节点排一次序，然后选出第一个（第0位）节点，暂且认为它是master节点。</li><li>如果对某个节点的投票数达到一定的值（可以成为master节点数n/2+1）并且该节点自己也选举自己，那这个节点就是master。否则重新选举一直到满足上述条件。
补充：master节点的职责主要包括集群、节点和索引的管理，不负责文档级别的管理；data节点可以关闭http功能。</li></ul><h3 id=3elasticsearch中的节点比如共20个其中的10个选了一个master另外10个选了另一个master怎么办><strong>3.Elasticsearch中的节点（比如共20个），其中的10个选了一个master，另外10个选了另一个master，怎么办？</strong><a hidden class=anchor aria-hidden=true href=#3elasticsearch中的节点比如共20个其中的10个选了一个master另外10个选了另一个master怎么办>#</a></h3><p>当集群master候选数量不小于3个时，可以通过设置最少投票通过数量（discovery.zen.minimum_master_nodes）超过所有候选节点一半以上来解决脑裂问题；
当候选数量为两个时，只能修改为唯一的一个master候选，其他作为data节点，避免脑裂问题。</p><h3 id=4详细描述一下elasticsearch索引文档的过程><strong>4.详细描述一下Elasticsearch索引文档的过程。</strong><a hidden class=anchor aria-hidden=true href=#4详细描述一下elasticsearch索引文档的过程>#</a></h3><p>协调节点默认使用文档ID参与计算（也支持通过routing），以便为路由提供合适的分片。
shard = hash(document_id) % (num_of_primary_shards)
当分片所在的节点接收到来自协调节点的请求后，会将请求写入到Memory Buffer，然后定时（默认是每隔1秒）写入到Filesystem Cache，这个从Momery Buffer到Filesystem Cache的过程就叫做refresh；
当然在某些情况下，存在Momery Buffer和Filesystem Cache的数据可能会丢失，ES是通过translog的机制来保证数据的可靠性的。其实现机制是接收到请求后，同时也会写入到translog中，当Filesystem cache中的数据写入到磁盘中时，才会清除掉，这个过程叫做flush；
在flush过程中，内存中的缓冲将被清除，内容被写入一个新段，段的fsync将创建一个新的提交点，并将内容刷新到磁盘，旧的translog将被删除并开始一个新的translog。
flush触发的时机是定时触发（默认30分钟）或者translog变得太大（默认为512M）时；</p><h3 id=5详细描述一下elasticsearch更新和删除文档的过程><strong>5.详细描述一下Elasticsearch更新和删除文档的过程</strong><a hidden class=anchor aria-hidden=true href=#5详细描述一下elasticsearch更新和删除文档的过程>#</a></h3><p>删除和更新也都是写操作，但是Elasticsearch中的文档是不可变的，因此不能被删除或者改动以展示其变更；
磁盘上的每个段都有一个相应的.del文件。当删除请求发送后，文档并没有真的被删除，而是在.del文件中被标记为删除。该文档依然能匹配查询，但是会在结果中被过滤掉。当段合并时，在.del文件中被标记为删除的文档将不会被写入新段。
在新的文档被创建时，Elasticsearch会为该文档指定一个版本号，当执行更新时，旧版本的文档在.del文件中被标记为删除，新版本的文档被索引到一个新段。旧版本的文档依然能匹配查询，但是会在结果中被过滤掉。</p><h3 id=6详细描述一下elasticsearch搜索的过程><strong>6.详细描述一下Elasticsearch搜索的过程</strong><a hidden class=anchor aria-hidden=true href=#6详细描述一下elasticsearch搜索的过程>#</a></h3><p>搜索被执行成一个两阶段过程，我们称之为 Query Then Fetch；
在初始查询阶段时，查询会广播到索引中每一个分片拷贝（主分片或者副本分片）。 每个分片在本地执行搜索并构建一个匹配文档的大小为 from + size 的优先队列。PS：在搜索的时候是会查询Filesystem Cache的，但是有部分数据还在Memory Buffer，所以搜索是近实时的。
每个分片返回各自优先队列中 所有文档的 ID 和排序值 给协调节点，它合并这些值到自己的优先队列中来产生一个全局排序后的结果列表。
接下来就是 取回阶段，协调节点辨别出哪些文档需要被取回并向相关的分片提交多个 GET 请求。每个分片加载并 丰富 文档，如果有需要的话，接着返回文档给协调节点。一旦所有的文档都被取回了，协调节点返回结果给客户端。
补充：Query Then Fetch的搜索类型在文档相关性打分的时候参考的是本分片的数据，这样在文档数量较少的时候可能不够准确，DFS Query Then Fetch增加了一个预查询的处理，询问Term和Document frequency，这个评分更准确，但是性能会变差。</p><h3 id=9elasticsearch对于大数据量上亿量级的聚合如何实现><strong>9.Elasticsearch对于大数据量（上亿量级）的聚合如何实现？</strong><a hidden class=anchor aria-hidden=true href=#9elasticsearch对于大数据量上亿量级的聚合如何实现>#</a></h3><p>Elasticsearch 提供的首个近似聚合是cardinality 度量。它提供一个字段的基数，即该字段的distinct或者unique值的数目。它是基于HLL算法的。HLL 会先对我们的输入作哈希运算，然后根据哈希运算的结果中的 bits 做概率估算从而得到基数。其特点是：可配置的精度，用来控制内存的使用（更精确 ＝ 更多内存）；小的数据集精度是非常高的；我们可以通过配置参数，来设置去重需要的固定内存使用量。无论数千还是数十亿的唯一值，内存使用量只与你配置的精确度相关 .</p><h3 id=10在并发情况下elasticsearch如果保证读写一致><strong>10.在并发情况下，Elasticsearch如果保证读写一致？</strong><a hidden class=anchor aria-hidden=true href=#10在并发情况下elasticsearch如果保证读写一致>#</a></h3><p>可以通过版本号使用乐观并发控制，以确保新版本不会被旧版本覆盖，由应用层来处理具体的冲突；
另外对于写操作，一致性级别支持quorum/one/all，默认为quorum，即只有当大多数分片可用时才允许写操作。但即使大多数可用，也可能存在因为网络等原因导致写入副本失败，这样该副本被认为故障，分片将会在一个不同的节点上重建。
对于读操作，可以设置replication为sync(默认)，这使得操作在主分片和副本分片都完成后才会返回；如果设置replication为async时，也可以通过设置搜索请求参数_preference为primary来查询主分片，确保文档是最新版本。</p><h3 id=14elasticsearch中的集群节点索引文档类型是什么><strong>14.ElasticSearch中的集群、节点、索引、文档、类型是什么？</strong><a hidden class=anchor aria-hidden=true href=#14elasticsearch中的集群节点索引文档类型是什么>#</a></h3><p>群集是一个或多个节点（服务器）的集合，它们共同保存您的整个数据，并提供跨所有节点的联合索引和搜索功能。群集由唯一名称标识，默认情况下为“elasticsearch”。此名称很重要，因为如果节点设置为按名称加入群集，则该节点只能是群集的一部分。
节点是属于集群一部分的单个服务器。它存储数据并参与群集索引和搜索功能。
索引就像关系数据库中的“数据库”。它有一个定义多种类型的映射。索引是逻辑名称空间，映射到一个或多个主分片，并且可以有零个或多个副本分片。 MySQL =>数据库 ElasticSearch =>索引
文档类似于关系数据库中的一行。不同之处在于索引中的每个文档可以具有不同的结构（字段），但是对于通用字段应该具有相同的数据类型。 MySQL => Databases => 　 Tables => Columns / Rows ElasticSearch => Indices => Types =>具有属性的文档
类型是索引的逻辑类别/分区，其语义完全取决于用户。</p><h3 id=15elasticsearch中的分片是什么><strong>15.ElasticSearch中的分片是什么?</strong><a hidden class=anchor aria-hidden=true href=#15elasticsearch中的分片是什么>#</a></h3><p>在大多数环境中，每个节点都在单独的盒子或虚拟机上运行。</p><p>索引 - 在Elasticsearch中，索引是文档的集合。
分片 -因为Elasticsearch是一个分布式搜索引擎，所以索引通常被分割成分布在多个节点上的被称为分片的元素。</p><p>问题四：</p><p>ElasticSearch中的集群、节点、索引、文档、类型是什么？</p><ul><li>群集是一个或多个节点（服务器）的集合，它们共同保存您的整个数据，并提供跨所有节点的联合索引和搜索功能。群集由唯一名称标识，默认情况下为“elasticsearch”。此名称很重要，因为如果节点设置为按名称加入群集，则该节点只能是群集的一部分。</li><li>节点是属于集群一部分的单个服务器。它存储数据并参与群集索引和搜索功能。</li><li>索引就像关系数据库中的“数据库”。它有一个定义多种类型的映射。索引是逻辑名称空间，映射到一个或多个主分片，并且可以有零个或多个副本分片。 MySQL =>数据库 ElasticSearch =>索引</li><li>文档类似于关系数据库中的一行。不同之处在于索引中的每个文档可以具有不同的结构（字段），但是对于通用字段应该具有相同的数据类型。 MySQL => Databases => Tables => Columns / Rows ElasticSearch => Indices => Types =>具有属性的文档</li><li>类型是索引的逻辑类别/分区，其语义完全取决于用户。</li></ul><p>问题五：</p><p>ElasticSearch是否有架构？</p><p>ElasticSearch可以有一个架构。架构是描述文档类型以及如何处理文档的不同字段的一个或多个字段的描述。Elasticsearch中的架构是一种映射，它描述了JSON文档中的字段及其数据类型，以及它们应该如何在Lucene索引中进行索引。因此，在Elasticsearch术语中，我们通常将此模式称为“映射”。</p><p>Elasticsearch具有架构灵活的能力，这意味着可以在不明确提供架构的情况下索引文档。如果未指定映射，则默认情况下，Elasticsearch会在索引期间检测文档中的新字段时动态生成一个映射。</p><p>问题六：</p><p>ElasticSearch中的分片是什么？</p><p>在大多数环境中，每个节点都在单独的盒子或虚拟机上运行。</p><ul><li>索引 - 在Elasticsearch中，索引是文档的集合。</li><li>分片 -因为Elasticsearch是一个分布式搜索引擎，所以索引通常被分割成分布在多个节点上的被称为分片的元素。</li></ul><p>问题七：</p><p>ElasticSearch中的副本是什么？</p><p>一个索引被分解成碎片以便于分发和扩展。副本是分片的副本。一个节点是一个属于一个集群的ElasticSearch的运行实例。一个集群由一个或多个共享相同集群名称的节点组成。</p><p>问题八：</p><p>ElasticSearch中的分析器是什么？</p><p>在ElasticSearch中索引数据时，数据由为索引定义的Analyzer在内部进行转换。 分析器由一个Tokenizer和零个或多个TokenFilter组成。编译器可以在一个或多个CharFilter之前。分析模块允许您在逻辑名称下注册分析器，然后可以在映射定义或某些API中引用它们。</p><p>Elasticsearch附带了许多可以随时使用的预建分析器。或者，您可以组合内置的字符过滤器，编译器和过滤器器来创建自定义分析器。</p><p>问题九：</p><p>什么是ElasticSearch中的编译器？</p><p>编译器用于将字符串分解为术语或标记流。一个简单的编译器可能会将字符串拆分为任何遇到空格或标点的地方。Elasticsearch有许多内置标记器，可用于构建自定义分析器。</p><p>问题十一：</p><p>启用属性，索引和存储的用途是什么？</p><p>enabled属性适用于各类ElasticSearch特定/创建领域，如index和size。用户提供的字段没有“已启用”属性。 存储意味着数据由Lucene存储，如果询问，将返回这些数据。</p><p>存储字段不一定是可搜索的。默认情况下，字段不存储，但源文件是完整的。因为您希望使用默认值(这是有意义的)，所以不要设置store属性 该指数属性用于搜索。</p><p>索引属性只能用于搜索。只有索引域可以进行搜索。差异的原因是在分析期间对索引字段进行了转换，因此如果需要的话，您不能检索原始数据。</p><p>（网络搜集-博客园）</p><h2 id=第二部分面试题>第二部分面试题<a hidden class=anchor aria-hidden=true href=#第二部分面试题>#</a></h2><p>es 写入数据的工作原理是什么啊？es 查询数据的工作原理是什么啊？底层的 lucene 介绍一下呗？倒排索引了解吗？</p><h2 id=面试官心理分析>面试官心理分析<a hidden class=anchor aria-hidden=true href=#面试官心理分析>#</a></h2><p>问这个，其实面试官就是要看看你了解不了解 es 的一些基本原理，因为用 es 无非就是写入数据，搜索数据。你要是不明白你发起一个写入和搜索请求的时候，es 在干什么，那你真的是&mldr;&mldr;对 es 基本就是个黑盒，你还能干啥？你唯一能干的就是用 es 的 api 读写数据了。要是出点什么问题，你啥都不知道，那还能指望你什么呢？</p><h3 id=es-写数据过程>es 写数据过程<a hidden class=anchor aria-hidden=true href=#es-写数据过程>#</a></h3><ul><li>客户端选择一个 node 发送请求过去，这个 node 就是 <code>coordinating node</code>（协调节点）。</li><li><code>coordinating node</code> 对 document 进行路由，将请求转发给对应的 node（有 primary shard）。[路由的算法是？]</li><li>实际的 node 上的 <code>primary shard</code> 处理请求，然后将数据同步到 <code>replica node</code>。</li><li><code>coordinating node</code> 如果发现 <code>primary node</code> 和所有 <code>replica node</code> 都搞定之后，就返回响应结果给客户端。</li></ul><p><img loading=lazy src=https://pic3.zhimg.com/80/v2-cc0056ae85d31c55053443995ca0da92_720w.jpg alt=img></p><h2 id=es-读数据过程>es 读数据过程<a hidden class=anchor aria-hidden=true href=#es-读数据过程>#</a></h2><p>可以通过 <code>doc id</code> 来查询，会根据 <code>doc id</code> 进行 hash，判断出来当时把 <code>doc id</code> 分配到了哪个 shard 上面去，从那个 shard 去查询。</p><ul><li>客户端发送请求到任意一个 node，成为 <code>coordinate node</code>。</li><li><code>coordinate node</code> 对 <code>doc id</code> 进行哈希路由，将请求转发到对应的 node，此时会使用 <code>round-robin</code>随机轮询算法，在 <code>primary shard</code> 以及其所有 replica 中随机选择一个，让读请求负载均衡。</li><li>接收请求的 node 返回 document 给 <code>coordinate node</code>。</li><li><code>coordinate node</code> 返回 document 给客户端。</li></ul><p><em><strong>写请求是写入 primary shard，然后同步给所有的 replica shard；读请求可以从 primary shard 或 replica shard 读取，采用的是随机轮询算法。</strong></em></p><h2 id=es-搜索数据过程是指searchsearch和普通docid-get的背后逻辑不一样>es 搜索数据过程[是指search?search和普通docid get的背后逻辑不一样？]<a hidden class=anchor aria-hidden=true href=#es-搜索数据过程是指searchsearch和普通docid-get的背后逻辑不一样>#</a></h2><p>es 最强大的是做全文检索，就是比如你有三条数据：</p><ul><li><code>java真好玩儿啊</code></li><li><code>java好难学啊</code></li><li><code>j2ee特别牛</code></li></ul><p>你根据 <code>java</code> 关键词来搜索，将包含 <code>java</code>的 <code>document</code> 给搜索出来。es 就会给你返回：java真好玩儿啊，java好难学啊。</p><ul><li>客户端发送请求到一个 <code>coordinate node</code>。</li><li>协调节点将搜索请求转发到所有的 shard 对应的 <code>primary shard</code> 或 <code>replica shard</code>，都可以。</li><li>query phase：每个 shard 将自己的搜索结果（其实就是一些 <code>doc id</code>）返回给协调节点，由协调节点进行数据的合并、排序、分页等操作，产出最终结果。</li><li>fetch phase：接着由协调节点根据 <code>doc id</code> 去各个节点上拉取实际的 <code>document</code> 数据，最终返回给客户端。</li></ul><h3 id=写数据底层原理>写数据底层原理<a hidden class=anchor aria-hidden=true href=#写数据底层原理>#</a></h3><p>1）document先写入导内存buffer中，同时写translog日志</p><p>2)）<a href="https://link.zhihu.com/?target=https%3A//www.elastic.co/guide/cn/elasticsearch/guide/current/near-real-time.html">https://www.elastic.co/guide/cn/elasticsearch/guide/current/near-real-time.html</a></p><p>refresh操作所以近实时搜索：<strong>写入和打开一个新段(<strong>一个追加的倒排索引</strong>)的轻量的过程叫做 *refresh*</strong> 。<strong>每隔一秒钟</strong>把buffer中的数据<strong>创建一个新的segment，<strong>这里</strong>新段会被先写入到文件系统缓存</strong>&ndash;这一步代价会比较低，稍后再被刷新到磁盘&ndash;这一步代价比较高。不过<strong>只要文件已经在缓存中， 就可以像其它文件一样被打开和读取</strong>了，内存buffer被清空。此时，新segment 中的文件就<strong>可以被搜索</strong>了，这就意味着document从被写入到可以被搜索需要一秒种，如果要更改这个属性，可以执行以下操作</p><p>PUT /my_index
{
&ldquo;settings&rdquo;: {
&ldquo;<strong>refresh_interval</strong>&rdquo;: &ldquo;30s&rdquo;
}
}
3）<a href="https://link.zhihu.com/?target=https%3A//www.elastic.co/guide/cn/elasticsearch/guide/current/translog.html">https://www.elastic.co/guide/cn/elasticsearch/guide/current/translog.html</a></p><p>flush操作导致持久化变更：<strong>执行一个提交并且截断 translog 的行为在 Elasticsearch 被称作一次</strong> *<strong>flush</strong>。*刷新（refresh）完成后, 缓存被清空但是事务日志不会。translog日志也会越来越多，当translog日志大小大于一个阀值时候或30分钟，会出发flush操作。</p><ul><li>所有在内存缓冲区的文档都被写入一个新的段。</li><li>缓冲区被清空。</li><li>一个提交点被写入硬盘。（表明有哪些segment commit了）</li><li>文件系统缓存通过 <code>fsync</code> 到磁盘。</li><li>老的 translog 被删除。</li></ul><p>分片每30分钟被自动刷新（flush），或者在 translog 太大的时候也会刷新。也<strong>可以用_flush命令手动执行</strong>。</p><p><strong>translog每隔5秒会被写入磁盘（所以如果这5s，数据在cache而且log没持久化会丢失）</strong>。在一次增删改操作之后translog只有在replica和primary shard都成功才会成功，如果要提高操作速度，可以设置成异步的</p><p>PUT /my_index
{
&ldquo;settings&rdquo;: {
&ldquo;index.translog.durability&rdquo;: &ldquo;async&rdquo; ,</p><p>&ldquo;index.translog.sync_interval&rdquo;:&ldquo;5s&rdquo;
}
}</p><p>所以总结是有三个批次操作，一秒做一次refresh保证近实时搜索，5秒做一次translog持久化保证数据未持久化前留底，30分钟做一次数据持久化。</p><p>2.基于translog和commit point的数据恢复</p><p>在磁盘上会有一个上次持久化的commit point，translog上有一个commit point，根据这两个commit point，会把translog中的变更记录进行回放，重新执行之前的操作</p><p>3.不变形下的删除和更新原理</p><p><a href="https://link.zhihu.com/?target=https%3A//www.elastic.co/guide/cn/elasticsearch/guide/current/dynamic-indices.html%23deletes-and-updates">https://www.elastic.co/guide/cn/elasticsearch/guide/current/dynamic-indices.html#deletes-and-updates</a></p><p>一个文档被 “删除” 时，它实际上只是在 <code>.del</code> 文件中被 <em>标记</em> 删除。一个被标记删除的文档仍然可以被查询匹配到， 但它会在最终结果被返回前从结果集中移除。</p><p>文档更新也是类似的操作方式：当一个文档被更新时，旧版本文档被标记删除，文档的新版本被索引到一个新的段中。 可能两个版本的文档都会被一个查询匹配到，但被删除的那个旧版本文档在结果集返回前就已经被移除。</p><p>段合并的时候会将那些旧的已删除文档 从文件系统中清除。 被删除的文档（或被更新文档的旧版本）不会被拷贝到新的大段中。</p><p>4.merge操作，段合并</p><p><a href="https://link.zhihu.com/?target=https%3A//www.elastic.co/guide/cn/elasticsearch/guide/current/merge-process.html">https://www.elastic.co/guide/cn/elasticsearch/guide/current/merge-process.html</a></p><p>由于每秒会把buffer刷到segment中，所以segment会很多，为了防止这种情况出现，es内部会不断把一些相似大小的segment合并，并且物理删除del的segment。</p><p>当然也可以手动执行</p><p>POST /my_index/_optimize?max_num_segments=1，尽量不要手动执行，让它自动默认执行就可以了</p><p>5.当你正在建立一个大的新索引时（相当于直接全部写入buffer，先不refresh，写完再refresh），可以先关闭自动刷新，待开始使用该索引时，再把它们调回来：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>PUT /my_logs/_settings
</span></span><span class=line><span class=cl>{ &#34;refresh_interval&#34;: -1 } 
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>PUT /my_logs/_settings
</span></span><span class=line><span class=cl>{ &#34;refresh_interval&#34;: &#34;1s&#34; } 
</span></span></code></pre></td></tr></table></div></div><h3 id=底层-lucene>底层 lucene<a hidden class=anchor aria-hidden=true href=#底层-lucene>#</a></h3><p>简单来说，lucene 就是一个 jar 包，里面包含了封装好的各种建立倒排索引的算法代码。我们用 Java 开发的时候，引入 lucene jar，然后基于 lucene 的 api 去开发就可以了。</p><p>通过 lucene，我们可以将已有的数据建立索引，lucene 会在本地磁盘上面，给我们组织索引的数据结构。</p><h3 id=倒排索引>倒排索引<a hidden class=anchor aria-hidden=true href=#倒排索引>#</a></h3><p>在搜索引擎中，每个文档都有一个对应的文档 ID，文档内容被表示为一系列关键词的集合。例如，文档 1 经过分词，提取了 20 个关键词，每个关键词都会记录它在文档中出现的次数和出现位置。</p><p>那么，倒排索引就是关键词到文档 ID 的映射，每个关键词都对应着一系列的文件，这些文件中都出现了关键词。</p><p>举个栗子。</p><p>有以下文档：</p><p><img loading=lazy src=https://pic2.zhimg.com/80/v2-8b51780cc522107e86095c483df72629_720w.jpg alt=img></p><p>对文档进行分词之后，得到以下倒排索引。</p><p><img loading=lazy src=https://pic2.zhimg.com/80/v2-d447a5e95e31a6bf5a8df21df9078375_720w.jpg alt=img></p><p>另外，实用的倒排索引还可以记录更多的信息，比如文档频率信息，表示在文档集合中有多少个文档包含某个单词。</p><p>那么，有了倒排索引，搜索引擎可以很方便地响应用户的查询。比如用户输入查询 <code>Facebook</code>，搜索系统查找倒排索引，从中读出包含这个单词的文档，这些文档就是提供给用户的搜索结果。</p><p>要注意倒排索引的两个重要细节：</p><ul><li>倒排索引中的所有词项对应一个或多个文档</li><li>倒排索引中的词项根据字典顺序升序排列</li></ul><p>上面只是一个简单的例子，并没有严格按照字典顺序升序排列。</p><hr><p>参考:</p><ol><li><a href=https://zhuanlan.zhihu.com/p/139762008>https://zhuanlan.zhihu.com/p/139762008</a></li><li><a href=https://zhuanlan.zhihu.com/p/102500311>https://zhuanlan.zhihu.com/p/102500311</a></li></ol></div><footer class=post-footer><ul class=post-tags><li><a href=https://reid00.github.io/tags/es/>ES</a></li><li><a href=https://reid00.github.io/tags/%E9%9D%A2%E8%AF%95/>面试</a></li></ul><nav class=paginav><a class=prev href=https://reid00.github.io/post/%E6%95%B0%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%8D%81%E5%A4%A7%E6%82%96%E8%AE%BA/><span class=title>« Prev</span><br><span>数学中的十大悖论</span></a>
<a class=next href=https://reid00.github.io/post/ml/gbdt+lr/><span class=title>Next »</span><br><span>GBDT+LR</span></a></nav></footer><script src=https://utteranc.es/client.js repo=Reid00/hugo-blog-talks issue-term=pathname label=Comment theme=github-light crossorigin=anonymous async></script></article></main><footer class=footer><span>&copy; 2022 <a href=https://reid00.github.io/>Reid's Blog</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById('menu');menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(t){t.preventDefault();var e=this.getAttribute("href").substr(1);window.matchMedia('(prefers-reduced-motion: reduce)').matches?document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView({behavior:"smooth"}),e==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${e}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove('dark'),localStorage.setItem("pref-theme",'light')):(document.body.classList.add('dark'),localStorage.setItem("pref-theme",'dark'))})</script><script>document.querySelectorAll('pre > code').forEach(t=>{const n=t.parentNode.parentNode,e=document.createElement('button');e.classList.add('copy-code'),e.innerHTML='copy';function s(){e.innerHTML='copied!',setTimeout(()=>{e.innerHTML='copy'},2e3)}e.addEventListener('click',o=>{if('clipboard'in navigator){navigator.clipboard.writeText(t.textContent),s();return}const e=document.createRange();e.selectNodeContents(t);const n=window.getSelection();n.removeAllRanges(),n.addRange(e);try{document.execCommand('copy'),s()}catch(e){}n.removeRange(e)}),n.classList.contains("highlight")?n.appendChild(e):n.parentNode.firstChild==n||(t.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?t.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(e):t.parentNode.appendChild(e))})</script></body></html>