<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>高并发架构 | Reid's Blog</title><meta name=keywords content><meta name=description content="Reid's Personal Notes -- https://github.com/Reid00"><meta name=author content="Reid"><link rel=canonical href=https://reid00.github.io/tags/%E9%AB%98%E5%B9%B6%E5%8F%91%E6%9E%B6%E6%9E%84/><link crossorigin=anonymous href=/assets/css/stylesheet.d7fb4cbf980fe688a21621b06a795933c4e6bb2d4070ec940667af1715d84af2.css integrity="sha256-1/tMv5gP5oiiFiGwanlZM8Tmuy1AcOyUBmevFxXYSvI=" rel="preload stylesheet" as=style><link rel=icon href=https://reid00.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://reid00.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://reid00.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://reid00.github.io/apple-touch-icon.png><link rel=mask-icon href=https://reid00.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://reid00.github.io/tags/%E9%AB%98%E5%B9%B6%E5%8F%91%E6%9E%B6%E6%9E%84/index.xml><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-QRR6GRNQGK"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-QRR6GRNQGK",{anonymize_ip:!1})}</script><meta property="og:title" content="高并发架构"><meta property="og:description" content="Reid's Personal Notes -- https://github.com/Reid00"><meta property="og:type" content="website"><meta property="og:url" content="https://reid00.github.io/tags/%E9%AB%98%E5%B9%B6%E5%8F%91%E6%9E%B6%E6%9E%84/"><meta property="og:image" content="https://i.loli.net/2021/09/26/3OMGXylm8HUYJ6p.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://i.loli.net/2021/09/26/3OMGXylm8HUYJ6p.png"><meta name=twitter:title content="高并发架构"><meta name=twitter:description content="Reid's Personal Notes -- https://github.com/Reid00"></head><body class=list id=top><head><meta name=referrer content="no-referrer"></head><main class=main><header class=page-header><div class=breadcrumbs><a href=https://reid00.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://reid00.github.io/tags/>Tags</a></div><h1>高并发架构
<a href=index.xml title=RSS aria-label=RSS><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" height="23"><path d="M4 11a9 9 0 019 9"/><path d="M4 4a16 16 0 0116 16"/><circle cx="5" cy="19" r="1"/></svg></a></h1></header><article class="post-entry tag-entry"><header class=entry-header><h2>高并发架构</h2></header><div class=entry-content><p>介绍 什么是高并发，从字面上理解，就是在某一时刻产生大量的请求，那么多少量称为大量，业界并没有标准的衡量范围。原因非常简单，不同的业务处理复杂度不一样。
而我所理解的高并发，它并不只是一个数字，而更是一种架构思维模式，它让你在面对不同的复杂情况下，从容地选择不同的技术手段，来提升应用系统的处理能力。
但是，并不意味应用系统从诞生的那一刻，就需要具备强大的处理能力，这种做法并不提倡。要知道，脱离实际情况的技术，会显得毫无价值，甚至是一种浪费的表现。
言归正传，那高并发到底是一种怎样的架构思维模式，它对架构设计又有什么影响，以及如何通过它来驱动架构演进，让我们接着往下读，慢慢去体会这其中的精髓。
性能是一种基础 在架构设计的过程中，思考固然重要，但目标更为关键。通过目标的牵引力，可以始终确保推进方向，不会脱离成功的轨道。那高并发的目标是什么，估计你的第一反应就是性能。
没错，性能是高并发的目标之一，它不可或缺，但并不代表所有。而我将它视为是高并发的一种基础能力，它的能力高低将会直接影响到其他能力的取舍。例如：服务可用性，数据一致性等。
性能在软件研发过程中无处不在，不管是在非功能性需求中，还是在性能测试报告中，都能见到它的身影。那么如何来衡量它的高低呢，先来看看常用的性能指标。
每秒处理事务数（TPS） 每秒能够处理的事务数，其中T(Transactions)可以定义不同的含义，它可以是完整的一笔业务，也可以是单个的接口请求。
每秒请求数（RPS） 每秒请求数量，也可以叫做QPS，但它与TPS有所不同，前者注重请求能力，后者注重处理能力。不过，若所有请求都在得到响应后再次发起，那么RPS基本等于TPS。
响应时长（RT） 从发出请求到得到响应的耗时，一般可以采用毫秒单位来表示，而在一些对RT比较敏感的业务场景下，可以使用精度更高的微秒来表示。
并发用户数（VU） 同时请求的用户数，很多人将它与并发数画上等号，但两者稍有不同，前者关注客户端，后者关注服务端，除非每个用户仅发送一笔请求，且请求从客户端到服务端没有延迟，同时服务端有足够的处理线程。
以上都是些常用的性能指标，基本可以覆盖80%以上的性能衡量要求。但千万不要以单个指标的高低来衡量性能。比如：订单查询TPS=100万就认为性能很高，但RT=10秒。
这显然毫无意义。因此，建议同时观察多个指标的方式来衡量性能的高低，大多数情况下主要会关注TPS和RT，而你可以将TPS视为一种水平能力，注重并行处理能力，将RT视为一种垂直能力，注重单笔处理能力，两者缺一不可。
接触过性能测试的同学，可能会见过如下这种性能测试结果图，图中包含了刚才提到过的三个性能指标，其中横坐标为VU，纵坐标分别为TPS和RT。 图中的两条曲线，在不断增加VU的情况下，TPS不断上升，但RT保持稳定，但当VU增加到一定量级的时候，TPS开始趋于稳定，而RT不断上升。
如果你仔细观察，还会发现一个奇妙的地方，当RT=25ms时，它们三者存在着某种关系，即：TPS=VU/RT。但当RT>25ms时，这种关系似乎被打破了，这里暂时先卖个关子，稍后再说。
根据表格中的数据，性能测试报告结论：最大TPS=65000，当RT=25ms(最短)时，最大可承受VU=1500。
感觉有点不对劲，用刚才的公式来验证一下，1500/0.025s=60000，但最大却是TPS=65000。那是因为，当VU=1500时，应用系统的使用资源还有空间。
再来观察一下表格中的数据，VU从1500增加到1750时，TPS继续上升，且到了最大值65000。此时，你是不是会理解为当VU增加到1750时，使用资源被耗尽了。话虽没错，但不严谨。
注：使用资源不一定是指硬件资源，也可能是其他方面，例如：应用系统设置的最大处理线程。
其实在VU增加到1750前，使用资源就已饱和，那如何来测算VU的临界值呢。你可以将最大TPS作为已知条件，即：VU=TPS * RT，65000*0.025s=1625。也就是说，当VU=1625时，使用资源将出现瓶颈。
调整性能测试报告结论：最大TPS=65000，当RT=25ms(最短)时，最大可承受VU=1625。
有人会问，表格中的RT是不是平均值，首先回答为是。不过，高并发场景对RT会特别敏感，所以除了要考虑RT的平均值外，建议还要考虑它的分位值，例如：P99。
举例：假设1000笔请求，其中900笔RT=23ms，50笔RT=36ms，50笔RT=50ms
平均值 P99值 P95 P90 25ms 50ms 36ms 23ms P99的计算方式，是将1000笔请求的RT从小到大进行排序，然后取排在第99%位的数值，基于以上举例数据来进行计算，P99=50ms，其他分位值的计算方式类似。
再次调整性能测试报告结论：最大TPS=65000，当RT(平均)=25ms(最短)时，最大可承受VU=1625，RT(P99)=50ms，RT(P95)=36ms，RT(P90)=23ms。
在非功能性需求中，你可能会看到这样的需求，性能指标要求：RT(平均)&lt;=30。结合刚才的性能测试报告结论，当RT(平均)=25ms(最短)时，最大可承受VU=1625。那就等于在RT上还有5ms的容忍时间。
既然是这样的话，那我们不妨就继续尝试增加VU，不过RT(平均)会出现上升，但只要控制不要上升到30ms即可，这是一种通过牺牲耗时(RT)来换取并发用户数(VU)的行为。但请不要把它理解为每笔请求耗时都会上升5ms，这将是一个严重的误区。
RT(平均)的增加，完全可能是由于应用系统当前没有足够的使用资源来处理请求所造成的，例如：处理线程。如果没有可用线程可以分配给请求时，就会将这请求先放入队列，等前面的请求处理完成并释放线程后，就可以继续处理队列中的请求了。
那也就是说，没有进入队列的请求并不会增加额外的耗时，而只有进入队列的请求会增加。那么进入队列的请求会增加多少耗时呢，在理想情况下(RT恒定)，可能会是正常处理一笔请求耗时的倍数，而倍数的大小又取决于并发请求的数量。
假设最大处理线程=1625，若每个用户仅发送一笔请求，且请求从客户端到服务端没有延迟的条件下，当并发用户数=1625时，能够保证RT=25ms，但当并发用户数>1625时，因为线程只能分配给1625笔请求，那多余的请求就无法保证RT=25ms。
超过1625笔的请求会先放入队列，等前面1625笔请求处理完成后，再从队列中拿出最多1625笔请求进行下一批处理，如果队列中还有剩余请求，那就继续按照这种方式循环处理。
进入队列的请求，每等待一批就需要增加前一批的处理耗时。在理想情况下，每一批都是RT=25ms，如果这笔请求在队列中等待了两批，那就要额外增加50ms的耗时。
因此，并不能简单通过VU=TPS* RT=65000*0.03=1950来计算最大可承受VU。而是需要引入一种叫做科特尔法则(Little’s Law)的排队模型来估算，不过由于这个法则比较复杂，这里暂时不做展开。
通过粗略估算后，VU大约在2032，我们再对这个值用上述表格中再反向验算一下。 最终调整性能测试报告结论：最大TPS=65000，当RT(平均)=25(最短)时，最大可承受VU=1625，RT(P99)=50，RT(P95)=36，RT(P90)=23；当RT(平均)=30(容忍)时，(理想情况)最大可承受VU=2032，RT(P99)=RT(P95)=50，RT(P90)=25。
这就解释了为什么当RT>25ms时，VU=TPS*RT会不成立的原因。不过，这些都是在理想情况下推演出来的，实际情况会比这要复杂得多。
所以，还是尽量采用多轮性能测试来得到性能指标，这样也更具备真实性。毕竟影响性能的因素实在大多且很难完全掌控，任何细微变化都将影响性能指标的变化。
到这里，我们已经了解了可以用哪些指标来衡量性能的高低。不过，这里更想强调的是，性能是高并发的基础能力，是实现高并发的基础条件，并且你需要有侧重性地提升不同维度的性能指标，而非仅关注某一项。
限制是一种设计 上文说到，性能是高并发的目标之一。追求性能没有错，但并非永无止境。想要提升性能，势必投入成本，不过它们并不是一直成正比，而是随着成本不断增加，性能提升幅度逐渐衰减，甚至可能不再提升。所以，有时间我们要懂得适可而止。
思考一下，追求性能是为了解决什么问题，至少有一点，是为了让应用系统能够应对突发请求。换言之，如果能解决这个问题，是不是也算实现了高并发的目标。
而有时候，我们在解决问题时，不要总是习惯做加法，还可以尝试做减法，架构设计同样如此。那么，如何通过做减法的方式，来解决应对突发请求的问题呢。让我们来讲讲限制。
限制，从狭义上可以理解为是一种约束或控制能力。在软件领域中，它可以针对功能性或非功能性，而在高并发的场景中，它更偏向于非功能性。
限制应用系统的处理能力，并不代表要降低应用系统的处理能力，而是通过某些控制手段，让突发请求能够被平滑地处理，同时起到应用系统的保护能力，避免瘫痪，还能将应用系统的资源进行合理分配，避免浪费。
那么，到底有哪些控制手段，既能实现以上这些能力，又能减少对客户体验上的影响，下面就来介绍几种常用的控制手段。
第一招：限流 限流，是在一个时间窗口内，对请求进行速率控制。若请求达到提前设定的阈值时，则对请求进行排队或拒绝。常用的限流算法有两种：漏桶算法和令牌桶算法。
漏桶算法 所有请求先进入漏桶，然后按照一个恒定的速率对漏桶里的请求进行处理，是一种控制处理速率的限流方式，用于平滑突发请求速率。
它的优点是，能够确保资源不会瞬间耗尽，避免请求处理发生阻塞现象，另外，还能够保护被应用系统所调用的外部服务，也免受突发请求的冲击。
它的缺点是，对于突发请求仍然会以一个恒定的速率来进行处理，其灵活性会较弱一点，容易发生突发请求超过漏桶的容量，导致后续请求直接被丢弃。...</p></div><footer class=entry-footer><span title='2023-03-16 19:35:15 +0800 +0800'>2023-03-16</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;Reid</footer><a class=entry-link aria-label="post link to 高并发架构" href=https://reid00.github.io/posts/os_network/%E9%AB%98%E5%B9%B6%E5%8F%91%E6%9E%B6%E6%9E%84/></a></article></main><footer class=footer><span>&copy; 2023 <a href=https://reid00.github.io/>Reid's Blog</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>