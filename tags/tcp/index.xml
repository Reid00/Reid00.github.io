<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>TCP on Reid&#39;s Blog</title>
    <link>https://reid00.github.io/tags/tcp/</link>
    <description>Recent content in TCP on Reid&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Thu, 16 Mar 2023 19:35:12 +0800</lastBuildDate><atom:link href="https://reid00.github.io/tags/tcp/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>拔掉网线后,原本的TCP连接还存在吗？</title>
      <link>https://reid00.github.io/posts/os_network/%E6%8B%94%E6%8E%89%E7%BD%91%E7%BA%BF%E5%90%8E%E5%8E%9F%E6%9C%AC%E7%9A%84tcp%E8%BF%9E%E6%8E%A5%E8%BF%98%E5%AD%98%E5%9C%A8%E5%90%97/</link>
      <pubDate>Thu, 16 Mar 2023 19:35:12 +0800</pubDate>
      
      <guid>https://reid00.github.io/posts/os_network/%E6%8B%94%E6%8E%89%E7%BD%91%E7%BA%BF%E5%90%8E%E5%8E%9F%E6%9C%AC%E7%9A%84tcp%E8%BF%9E%E6%8E%A5%E8%BF%98%E5%AD%98%E5%9C%A8%E5%90%97/</guid>
      <description>背景 今天，聊一个有趣的问题：拔掉网线几秒，再插回去，原本的 TCP 连接还存在吗？
可能有的同学会说，网线都被拔掉了，那说明物理层被断开了，那在上层的传输层理应也会断开，所以原本的 TCP 连接就不会存在了。就好像， 我们拨打有线电话的时候，如果某一方的电话线被拔了，那么本次通话就彻底断了。
真的是这样吗？
上面这个逻辑就有问题。问题在于，错误地认为拔掉网线这个动作会影响传输层，事实上并不会影响。
实际上，TCP 连接在 Linux 内核中是一个名为 struct socket 的结构体，该结构体的内容包含 TCP 连接的状态等信息。当拔掉网线的时候，操作系统并不会变更该结构体的任何内容，所以 TCP 连接的状态也不会发生改变。
我在我的电脑上做了个小实验，我用 ssh 终端连接了我的云服务器，然后我通过断开 wifi 的方式来模拟拔掉网线的场景，此时查看 TCP 连接的状态没有发生变化，还是处于 ESTABLISHED 状态。 通过上面这个实验结果，我们知道了，拔掉网线这个动作并不会影响 TCP 连接的状态。 接下来，要看拔掉网线后，双方做了什么动作。 针对这个问题，要分场景来讨论：
拔掉网线后，有数据传输； 拔掉网线后，没有数据传输。 拔掉网线后，有数据传输 在客户端拔掉网线后，服务端向客户端发送的数据报文会得不到任何的响应，在等待一定时长后，服务端就会触发超时重传机制，重传未得到响应的数据报文。
如果在服务端重传报文的过程中，客户端刚好把网线插回去了，由于拔掉网线并不会改变客户端的 TCP 连接状态，并且还是处于 ESTABLISHED 状态，所以这时客户端是可以正常接收服务端发来的数据报文的，然后客户端就会回 ACK 响应报文。
此时，客户端和服务端的 TCP 连接依然存在，就感觉什么事情都没有发生。
但是，如果在服务端重传报文的过程中，客户端一直没有将网线插回去，服务端超时重传报文的次数达到一定阈值后，内核就会判定出该 TCP 有问题，然后通过 Socket 接口告诉应用程序该 TCP 连接出问题了，于是服务端的 TCP 连接就会断开。
而等客户端插回网线后，如果客户端向服务端发送了数据，由于服务端已经没有与客户端相同四元组的 TCP 连接了，因此服务端内核就会回复 RST 报文，客户端收到后就会释放该 TCP 连接。
此时，客户端和服务端的 TCP 连接都已经断开了。
那 TCP 的数据报文具体重传几次呢？ 在 Linux 系统中，提供了一个叫 tcp_retries2 配置项，默认值是 15，如下：</description>
    </item>
    
    <item>
      <title>TCP IP协议</title>
      <link>https://reid00.github.io/posts/os_network/tcp-ip%E5%8D%8F%E8%AE%AE/</link>
      <pubDate>Thu, 16 Mar 2023 19:35:09 +0800</pubDate>
      
      <guid>https://reid00.github.io/posts/os_network/tcp-ip%E5%8D%8F%E8%AE%AE/</guid>
      <description>TCP/IP 协议族 通常我说 TCP/IP 是指 TCP/IP 协议族。它是基于 TCP 和 IP 这两个最初的协议之上的不同的通信协议的大集合。 例如：http、https、ftp、icmp、arp、rarp、smtp（简单邮件传输协议）
当输入 xxxxHub 后，到网页显示，其间发生了什么？这问题被面试官问了五六十次，熬夜赶出这篇文章
https://mp.weixin.qq.com/s/ESJ8Zt0GBVXHKj3KICoqjg
一个网络请求是怎么传输的？ 我们拿访问浏览器举个栗子，如图所示：
TCP、UDP有什么区别？各有什么优劣？ TCP 面向连接，提供可靠交付。通过 TCP 连接传输的数据，无差错、不丢失、不重复、并且按序到达。相对 UDP 开销大 UDP 面向无连接，不保证可靠交付。无拥塞控制，支持一对一、一对多、多对多，开销小。
关于 TCP 协议 确认 ACK - ACKnowledgement 仅当ACK = 1 时，确认才有效。简单来说，就是确认收到数据。 复位 RST - ReSet 标明 TCP 出现严重差错时，必须释放连接，重新建立连接。 同步 SYN - SYNchronization 在建立连接时，用来同步序号。当 SYN = 1，ACK = 0 时，表名这是一个连接请求报文。SYN = 1，ACK = 1 表示这是一个同意请求报文。 终止 FNI - FINis（表示终、完）用来释放连接。当 FNI = 1 表示此段报文发送方已发送完毕。 关于 UDP 协议 解释三次握手 确认号 ack 期望收到对方下一个报文的序列号</description>
    </item>
    
    <item>
      <title>Http长连接和TCP长连接的区别</title>
      <link>https://reid00.github.io/posts/os_network/http%E9%95%BF%E8%BF%9E%E6%8E%A5%E5%92%8Ctcp%E9%95%BF%E8%BF%9E%E6%8E%A5%E7%9A%84%E5%8C%BA%E5%88%AB/</link>
      <pubDate>Thu, 16 Mar 2023 19:34:53 +0800</pubDate>
      
      <guid>https://reid00.github.io/posts/os_network/http%E9%95%BF%E8%BF%9E%E6%8E%A5%E5%92%8Ctcp%E9%95%BF%E8%BF%9E%E6%8E%A5%E7%9A%84%E5%8C%BA%E5%88%AB/</guid>
      <description>介绍 事实上，这两个完全是两样不同东西，实现的层面也不同：
HTTP 的 Keep-Alive，是由应用层（用户态） 实现的，称为 HTTP 长连接； TCP 的 Keepalive，是由 TCP 层（内核态） 实现的，称为 TCP 保活机制； 接下来，分别说说它们。
HTTP 的 Keep-Alive HTTP 协议采用的是「请求-应答」的模式，也就是客户端发起了请求，服务端才会返回响应，一来一回这样子。
由于 HTTP 是基于 TCP 传输协议实现的，客户端与服务端要进行 HTTP 通信前，需要先建立 TCP 连接，然后客户端发送 HTTP 请求，服务端收到后就返回响应，至此「请求-应答」的模式就完成了，随后就会释放 TCP 连接。
如果每次请求都要经历这样的过程：建立 TCP -&amp;gt; 请求资源 -&amp;gt; 响应资源 -&amp;gt; 释放连接，那么此方式就是 HTTP 短连接，如下图：
这样实在太累人了，一次连接只能请求一次资源。
能不能在第一个 HTTP 请求完后，先不断开 TCP 连接，让后续的 HTTP 请求继续使用此连接？
当然可以，HTTP 的 Keep-Alive 就是实现了这个功能，可以使用同一个 TCP 连接来发送和接收多个 HTTP 请求/应答，避免了连接建立和释放的开销，这个方法称为 HTTP 长连接。
HTTP 长连接的特点是，只要任意一端没有明确提出断开连接，则保持 TCP 连接状态。
怎么才能使用 HTTP 的 Keep-Alive 功能？</description>
    </item>
    
    <item>
      <title>UDP就一定比TCP快吗</title>
      <link>https://reid00.github.io/posts/os_network/udp%E5%B0%B1%E4%B8%80%E5%AE%9A%E6%AF%94tcp%E5%BF%AB%E5%90%97/</link>
      <pubDate>Thu, 16 Mar 2023 19:34:52 +0800</pubDate>
      
      <guid>https://reid00.github.io/posts/os_network/udp%E5%B0%B1%E4%B8%80%E5%AE%9A%E6%AF%94tcp%E5%BF%AB%E5%90%97/</guid>
      <description>话说，UDP比TCP快吗？
相信就算不是八股文老手，也会下意识的脱口而出：&amp;ldquo;是&amp;rdquo;。
这要追问为什么，估计大家也能说出个大概。
但这也让人好奇，用UDP就一定比用TCP快吗？什么情况下用UDP会比用TCP慢？
我们今天就来聊下这个话题。
使用socket进行数据传输 作为一个程序员，假设我们需要在A电脑的进程发一段数据到B电脑的进程，我们一般会在代码里使用socket进行编程。
socket就像是一个电话或者邮箱（邮政的信箱）。当你想要发送消息的时候，拨通电话或者将信息塞到邮箱里，socket内核会自动完成将数据传给对方的这个过程。
基于socket我们可以选择使用TCP或UDP协议进行通信。
对于TCP这样的可靠性协议，每次消息发出后都能明确知道对方收没收到，就像打电话一样，只要&amp;quot;喂喂&amp;quot;两下就能知道对方有没有在听。
而UDP就像是给邮政的信箱寄信一样，你寄出去的信，根本就不知道对方有没有正常收到，丢了也是有可能的。
这让我想起了大概17年前，当时还没有现在这么发达的网购，想买一本《掌机迷》杂志，还得往信封里塞钱，然后一等就是一个月，好几次都怀疑信是不是丢了。我至今印象深刻，因为那是我和我哥攒了好久的钱。。。
回到socket编程的话题上。
创建socket的方式就像下面这样。
1 fd = socket(AF_INET, 具体协议,0); 注意上面的&amp;quot;具体协议&amp;quot;，如果传入的是SOCK_STREAM，是指使用字节流传输数据，说白了就是TCP协议。 TCP: 面向连接的 可靠的 基于字节流 如果传入的是SOCK_DGRAM，是指使用数据报传输数据，也就是UDP协议。 UDP: 无连接 不可靠 基于消息报
返回的fd是指socket句柄，可以理解为socket的身份证号。通过这个fd你可以在内核中找到唯一的socket结构。
如果想要通过这个socket发消息，只需要操作这个fd就行了，比如执行 send(fd, msg, &amp;hellip;)，内核就会通过这个fd句柄找到socket然后进行发数据的操作。
如果一切顺利，此时对方执行接收消息的操作，也就是 recv(fd, msg, &amp;hellip;)，就能拿到你发的消息。 对于异常情况的处理 但如果不顺利呢？
比如消息发到一半，丢包了呢?
那UDP和TCP的态度就不太一样了。
UDP表示，&amp;ldquo;哦，是吗？然后呢？关我x事&amp;rdquo;
TCP态度就截然相反了，&amp;ldquo;啊？那可不行，是不是我发太快了呢？是不是链路太堵被别人影响到了呢？不过你放心，我肯定给你补发&amp;rdquo;
TCP老实人石锤了。我们来看下这个老实人在背后都默默做了哪些事情。
重传机制 对于TCP，它会给发出的消息打上一个编号（sequence），接收方收到后回一个确认(ack)。发送方可以通过ack的数值知道接收方收到了哪些sequence的包。
如果长时间等不到对方的确认，TCP就会重新发一次消息，这就是所谓的重传机制。 流量控制机制 但重传这件事本身对性能影响是比较严重的，所以是下下策。
于是TCP就需要思考有没有办法可以尽量避免重传。
因为数据发送方和接收方处理数据能力可能不同，因此如果可以根据双方的能力去调整发送的数据量就好了，于是就有了发送和接收窗口，基本上从名字就能看出它的作用，比如接收窗口的大小就是指，接收方当前能接收的数据量大小，发送窗口的大小就指发送方当前能发的数据量大小。TCP根据窗口的大小去控制自己发送的数据量，这样就能大大减少丢包的概率。 滑动窗口机制 接收方的接收到数据之后，会不断处理，处理能力也不是一成不变的，有时候处理的快些，那就可以收多点数据，处理的慢点那就希望对方能少发点数据。毕竟发多了就有可能处理不过来导致丢包，丢包会导致重传，这可是下下策。因此我们需要动态的去调节这个接收窗口的大小，于是就有了滑动窗口机制。
看到这里大家可能就有点迷了，流量控制和滑动窗口机制貌似很像，它们之间是啥关系？我总结一下。其实现在TCP是通过滑动窗口机制来实现流量控制机制的。 拥塞控制机制 但这还不够，有时候发生丢包，并不是因为发送方和接收方的处理能力问题导致的。而是跟网络环境有关，大家可以将网络想象为一条公路。马路上可能堵满了别人家的车，只留下一辆车的空间。那就算你家有5辆车，目的地也正好有5个停车位，你也没办法同时全部一起上路。于是TCP希望能感知到外部的网络环境，根据网络环境及时调整自己的发包数量，比如马路只够两辆车跑，那我就只发两辆车。但外部环境这么复杂，TCP是怎么感知到的呢？
TCP会先慢慢试探的发数据，不断加码数据量，越发越多，先发一个，再发2个，4个…。直到出现丢包，这样TCP就知道现在当前网络大概吃得消几个包了，这既是所谓的拥塞控制机制。
不少人会疑惑流量控制和拥塞控制的关系。我这里小小的总结下。流量控制针对的是单个连接数据处理能力的控制，拥塞控制针对的是整个网络环境数据处理能力的控制。
分段机制 但上面提到的都是怎么降低重传的概率，似乎重传这个事情就是无法避免的，那如果确实发生了，有没有办法降低它带来的影响呢？
有。当我们需要发送一个超大的数据包时，如果这个数据包丢了，那就得重传同样大的数据包。但如果我能将其分成一小段一小段，那就算真丢了，那我也就只需要重传那一小段就好了，大大减小了重传的压力，这就是TCP的分段机制。
而这个所谓的一小段的长度，在传输层叫MSS（Maximum Segment Size），数据包长度大于MSS则会分成N个小于等于MSS的包。 而在网络层，如果数据包还大于MTU（Maximum Transmit Unit），那还会继续分包。 一般情况下，MSS=MTU-40Byte，所以TCP分段后，到了IP层大概率就不会再分片了。 乱序重排机制 既然数据包会被分段，链路又这么复杂还会丢包，那数据包乱序也就显得不奇怪了。比如发数据包1,2,3。1号数据包走了其他网络路径，2和3数据包先到，1数据包后到，于是数据包顺序就成了2,3,1。这一点TCP也考虑到了，依靠数据包的sequence，接收方就能知道数据包的先后顺序。</description>
    </item>
    
  </channel>
</rss>
