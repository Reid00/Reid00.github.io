<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>feature engineering on Reid&#39;s Blog</title>
    <link>https://reid00.github.io/tags/feature-engineering/</link>
    <description>Recent content in feature engineering on Reid&#39;s Blog</description>
    <image>
      <url>https://i.loli.net/2021/09/26/3OMGXylm8HUYJ6p.png</url>
      <link>https://i.loli.net/2021/09/26/3OMGXylm8HUYJ6p.png</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Tue, 07 Jun 2022 19:28:59 +0800</lastBuildDate><atom:link href="https://reid00.github.io/tags/feature-engineering/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>数据降维之主成分分析 PCA</title>
      <link>https://reid00.github.io/post/%E6%95%B0%E6%8D%AE%E9%99%8D%E7%BB%B4%E4%B9%8B%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90-pca/</link>
      <pubDate>Tue, 07 Jun 2022 19:28:59 +0800</pubDate>
      
      <guid>https://reid00.github.io/post/%E6%95%B0%E6%8D%AE%E9%99%8D%E7%BB%B4%E4%B9%8B%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90-pca/</guid>
      <description>Summary PCA 是无监督学习中最常见的数据降维方法，但是实际上问题特征很多的情况，PCA通常会预处理来减少特征个数。 将维的意义： 通过降维提高算法的效率 通</description>
    </item>
    
    <item>
      <title>特征工程之数据预处理</title>
      <link>https://reid00.github.io/post/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B%E4%B9%8B%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/</link>
      <pubDate>Tue, 07 Jun 2022 19:09:30 +0800</pubDate>
      
      <guid>https://reid00.github.io/post/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B%E4%B9%8B%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/</guid>
      <description>Summary 数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已。由此可见，特征工程在机器学习中占有相当重要的地位。在实际应用当中，可以说</description>
    </item>
    
  </channel>
</rss>
