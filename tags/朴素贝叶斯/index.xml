<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>朴素贝叶斯 on Reid&#39;s Blog</title>
    <link>https://reid00.github.io/tags/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/</link>
    <description>Recent content in 朴素贝叶斯 on Reid&#39;s Blog</description>
    <image>
      <url>https://i.loli.net/2021/09/26/3OMGXylm8HUYJ6p.png</url>
      <link>https://i.loli.net/2021/09/26/3OMGXylm8HUYJ6p.png</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Tue, 07 Jun 2022 19:40:44 +0800</lastBuildDate><atom:link href="https://reid00.github.io/tags/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>朴素贝叶斯</title>
      <link>https://reid00.github.io/posts/ml/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/</link>
      <pubDate>Tue, 07 Jun 2022 19:40:44 +0800</pubDate>
      
      <guid>https://reid00.github.io/posts/ml/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/</guid>
      <description>贝叶斯准备知识 贝叶斯决策论是概率框架下实施决策的基本方法。要了解贝叶斯决策论，首先得先了解以下几个概念：先验概率、条件概率、后验概率、误判损失、条件风险、贝叶斯判别准则
先验概率： 所谓先验概率，就是根据以往的经验或者现有数据的分析所得到的概率。如，随机扔一枚硬币，则p(正面) = p(反面) = 1/2，这是我们根据已知的知识所知道的信息，即p(正面) = 1/2为先验概率。
条件概率： 所谓条件概率是指事件A在另一事件B发生的条件下发送的概率。用数学符号表示为：P(B\|A)，即B在A发生的条件下发生的概率。举个栗子，你早上误喝了一瓶过期了的牛奶（A），那我们来算一下你今天拉肚子的概率（B），这个就叫做条件概率。即P（拉肚子\|喝了过期牛奶）， 易见，条件概率是有因求果（知道原因推测结果）。
后验概率： 后验概率跟条件概率的表达形式有点相似。数学表达式为p(A\|B), 即A在B发生的条件下发生的概率。以误喝牛奶的例子为例，现在知道了你今天拉肚子了（B），算一下你早上误喝了一瓶过期了的牛奶(A)的概率, 即P（A|B），这就是后验概率，后验概率是有果求因（知道结果推出原因）
误判损失： 数学表达式：L(j|i)， 判别损失表示把一个标记为i类的样本误分类为j类所造成的损失。 比如，当你去参加体检时，明明你各项指标都是正常的，但是医生却把你分为癌症病人，这就造成了误判损失，用数学表示为：L(癌症|正常)。
条件风险： 是指基于后验概率P(i|x)可获得将样本x分类为i所产生的期望损失，公式为：R(i|x) = ∑L(i|j)P(j|x)。(其实就是所有判别损失的加权和，而这个权就是样本判为j类的概率，样本本来应该含有P(j|x)的概率判为j类，但是却判为了i类，这就造成了错判损失，而将所有的错判损失与正确判断的概率的乘积相加，就能得到样本错判为i类的平均损失，即条件风险。)
举个栗子，假设把癌症病人判为正常人的误判损失是100，把正常人判为癌症病人的误判损失是10，把感冒病人判为癌症的误判损失是8，即L（正常|癌症） = 100， L（癌症|正常） = 10，L(癌症|感冒) = 8， 现在，我们经过计算知道有一个来体检的员工的后验概率分别为：p(正常|各项指标) = 0.2， p(感冒|各项指标) = 0.4, p（ 癌症|各项指标)=0.4。假如我们需要计算将这个员工判为癌症的条件风险，则：R（癌症|各项指标） = L（癌症|正常） p(正常|各项指标) + L(癌症|感冒) * p(感冒|各项指标) = 5.2。*
贝叶斯判别准则：
贝叶斯判别准则是找到一个使条件风险达到最小的判别方法。即，将样本判为哪一类，所得到的条件风险R(i|x)（或者说平均判别损失）最小，那就将样本归为那个造成平均判别损失最小的类。
此时：h*(x) = argminR(i|x) 就称为 贝叶斯最优分类器。
总结：贝叶斯决策论是基于先验概率求解后验概率的方法，其核心是寻找一个判别准则使得条件风险达到最小。而在最小化分类错误率的目标下，贝叶斯最优分类器又可以转化为求后验概率达到最大的类别标记，即 h*（x) = argmaxP(i|x)。（此时，L(i|j) = 0, if i = j;L(i|j) = 1, otherwise)</description>
    </item>
    
  </channel>
</rss>
