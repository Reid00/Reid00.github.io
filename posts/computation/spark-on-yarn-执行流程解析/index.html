<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Spark on Yarn 执行流程解析 | Reid's Blog</title><meta name=keywords content="spark,yarn"><meta name=description content="Spark on Yarn 执行流程解析"><meta name=author content="Reid"><link rel=canonical href=https://reid00.github.io/posts/computation/spark-on-yarn-%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B%E8%A7%A3%E6%9E%90/><link crossorigin=anonymous href=/assets/css/stylesheet.d7fb4cbf980fe688a21621b06a795933c4e6bb2d4070ec940667af1715d84af2.css integrity="sha256-1/tMv5gP5oiiFiGwanlZM8Tmuy1AcOyUBmevFxXYSvI=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://reid00.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://reid00.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://reid00.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://reid00.github.io/apple-touch-icon.png><link rel=mask-icon href=https://reid00.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><head><meta name=referrer content="no-referrer"></head><script async src="https://www.googletagmanager.com/gtag/js?id=G-QRR6GRNQGK"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-QRR6GRNQGK",{anonymize_ip:!1})}</script><meta property="og:title" content="Spark on Yarn 执行流程解析"><meta property="og:description" content="Spark on Yarn 执行流程解析"><meta property="og:type" content="article"><meta property="og:url" content="https://reid00.github.io/posts/computation/spark-on-yarn-%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B%E8%A7%A3%E6%9E%90/"><meta property="og:image" content="https://i.loli.net/2021/09/26/3OMGXylm8HUYJ6p.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-03-16T19:34:50+08:00"><meta property="article:modified_time" content="2023-03-16T19:34:50+08:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://i.loli.net/2021/09/26/3OMGXylm8HUYJ6p.png"><meta name=twitter:title content="Spark on Yarn 执行流程解析"><meta name=twitter:description content="Spark on Yarn 执行流程解析"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://reid00.github.io/posts/"},{"@type":"ListItem","position":2,"name":"计算相关的记录，如Spark Flink 等","item":"https://reid00.github.io/posts/computation/"},{"@type":"ListItem","position":3,"name":"Spark on Yarn 执行流程解析","item":"https://reid00.github.io/posts/computation/spark-on-yarn-%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B%E8%A7%A3%E6%9E%90/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Spark on Yarn 执行流程解析","name":"Spark on Yarn 执行流程解析","description":"Spark on Yarn 执行流程解析","keywords":["spark","yarn"],"articleBody":"简介 当一个Spark应用提交到集群上运行时,应用架构包含了两个部分:\nDriver Program（资源申请和调度Job执行） Executors（运行Job中Task任务和缓存数据），两个都是JVM Process进程 Driver程序运行的位置可以通过–deploy-mode 来指定:\nDriver指的是The process running the main() function of the application and creating the SparkContext 运行应用程序的main()函数并创建SparkContext的进程\nclient: 表示Driver运行在提交应用的Client上(默认) cluster: 表示Driver运行在集群中(Standalone：Worker，YARN：NodeManager) cluster和client模式最最本质的区别是：Driver程序运行在哪里。 企业实际生产环境中使用cluster 为主要模式。 1. Client(客户端)模式 DeployMode为Client，表示应用Driver Program运行在提交应用Client主机上。 示意图: 1 2 3 4 5 6 7 8 9 10 11 SPARK_HOME=/export/server/spark ${SPARK_HOME}/bin/spark-submit \\ --master yarn \\ --deploy-mode client \\ --driver-memory 512m \\ --executor-memory 512m \\ --num-executors 1 \\ --total-executor-cores 2 \\ --class org.apache.spark.examples.SparkPi \\ ${SPARK_HOME}/examples/jars/spark-examples_2.11-2.4.5.jar \\ 10 2.Cluster(集群)模式,生产环境用 DeployMode为Cluster，表示应用Driver Program运行在集群从节点某台机器上. 1 2 3 4 5 6 7 8 9 10 11 SPARK_HOME=/export/server/spark ${SPARK_HOME}/bin/spark-submit \\ --master yarn \\ --deploy-mode cluster \\ --driver-memory 512m \\ --executor-memory 512m \\ --num-executors 1 \\ --total-executor-cores 2 \\ --class org.apache.spark.examples.SparkPi \\ ${SPARK_HOME}/examples/jars/spark-examples_2.11-2.4.5.jar \\ 10 总结: Client模式和Cluster模式最最本质的区别是：Driver程序运行在哪里。\nClient模式：测试时使用，开发不用，了解即可 Driver运行在Client上,和集群的通信成本高 Driver输出结果会在客户端显示 Cluster模式：生产环境中使用该模式 Driver程序在YARN集群中，和集群的通信成本低 Driver输出结果不能在客户端显示 该模式下Driver运行ApplicattionMaster这个节点上,由Yarn管理，如果出现问题，yarn会重启ApplicattionMaster(Driver) 3. 两种模式的详细流程图 Client模式图示: 在YARN Client模式下，Driver在任务提交的本地机器上运行。 Driver在任务提交的本地机器上运行，Driver启动后会和ResourceManager通讯申请启动ApplicationMaster 1 2 3 --master yarn \\ --deploy-mode client \\ --driver-memory 512m \\ 随后ResourceManager分配Container，在合适的NodeManager上启动ApplicationMaster，此时的ApplicationMaster的功能相当于一个ExecutorLaucher，只负责向ResourceManager申请Executor内存 1 2 3 --executor-memory 512m \\ --executor-cores 2 \\ --num-executors 1 \\ ResourceManager接到ApplicationMaster的资源申请后会分配Container，然后ApplicationMaster在资源分配指定的NodeManager上启动Executor进程； Executor进程启动后会向Driver反向注册，Executor全部注册完成后Driver开始执行main函数； 之后执行到Action算子时，触发一个Job，并根据宽依赖开始划分Stage，每个Stage生成对应的TaskSet，之后将Task分发到各个Executor上执行。 Cluster 模式示意图 在YARN Cluster模式下，Driver运行在NodeManager Contanier中，此时Driver与AppMaster合为一体。 Driver在任务提交的本地机器上运行，Driver启动后会和ResourceManager通讯申请启动ApplicationMaster 1 2 3 --master yarn \\ --deploy-mode cluster \\ --driver-memory 512m \\ 随后ResourceManager分配Container，在合适的NodeManager上启动ApplicationMaster，此时的ApplicationMaster的功能相当于一个ExecutorLaucher，只负责向ResourceManager申请Executor内存 1 2 3 --executor-memory 512m \\ --executor-cores 2 \\ --num-executors 1 \\ ResourceManager接到ApplicationMaster的资源申请后会分配Container，然后ApplicationMaster在资源分配指定的NodeManager上启动Executor进程； Executor进程启动后会向Driver反向注册，Executor全部注册完成后Driver开始执行main函数； 之后执行到Action算子时，触发一个Job，并根据宽依赖开始划分Stage，每个Stage生成对应的TaskSet，之后将Task分发到各个Executor上执行。 4. 运行中涉及到的名词 Application: Appliction都是指用户编写的Spark应用程序，其中包括一个Driver功能的代码和分布在集群中多个节点上运行的Executor代码 Driver: Spark中的Driver即运行上述Application的main函数并创建SparkContext，创建- SparkContext的目的是为了准备Spark应用程序的运行环境，当Executor部分运行完毕后，Driver同时负责将SparkContext关闭，通常用SparkContext代表Driver AppMaster: 控制yarn app运行和任务资源 Executor: 某个Application运行在worker节点上的一个进程， 该进程负责运行某些Task， 并且负责将数据存到内存或磁盘上，每个Application都有各自独立的一批Executor Worker: 集群中任何可以运行Application代码的节点，在Standalone模式中指的是通过slave文件配置的Worker节点，在Spark on Yarn模式下就是NodeManager节点 Task: 被送到某个Executor上的工作单元，但hadoopMR中的MapTask和ReduceTask概念一样，是运行Application的基本单位，多个Task组成一个Stage，而Task的调度和管理等是由TaskScheduler负责 Job: 包含多个Task组成的并行计算，往往由Spark Action触发生成， 一个Application中往往会产生多个Job Stage: 每个Job会被拆分成多组Task， 作为一个TaskSet， 其名称为Stage，Stage的划分和调度是有DAGScheduler来负责的，Stage有非最终的Stage（Shuffle Map Stage）和最终的Stage（Result Stage）两种，Stage的边界就是发生shuffle的地方 DAGScheduler: 根据Job构建基于Stage的DAG（Directed Acyclic Graph有向无环图)，并提交Stage给TASkScheduler。 其划分Stage的依据是RDD之间的依赖的关系找出开销最小的调度方法 TASKSedulter: 将TaskSet提交给worker运行，每个Executor运行什么Task就是在此处分配的. TaskScheduler维护所有TaskSet，当Executor向Driver发生心跳时，TaskScheduler会根据资源剩余情况分配相应的Task。另外TaskScheduler还维护着所有Task的运行标签，重试失败的Task Spark集群中的角色 Driver: 是一个JVM Process 进程，编写的Spark应用程序就运行在Driver上，由Driver进程执行； Master(ResourceManager): 是一个JVM Process 进程，主要负责资源的调度和分配，并进行集群的监控等职责； Worker(NodeManager)： 是一个JVM Process 进程，一个Worker运行在集群中的一台服务器上，主要负责两个职责，一个是用自己的内存存储RDD的某个或某些partition；另一个是启动其他进程和线程（Executor），对RDD上的partition进行并行的处理和计算。 Executor： 是一个JVM Process 进程，一个Worker(NodeManager)上可以运行多个Executor，Executor通过启动多个线程（task）来执行对RDD的partition进行并行计算，也就是执行我们对RDD定义的例如map、flatMap、reduce等算子操作。\n","wordCount":"246","inLanguage":"en","datePublished":"2023-03-16T19:34:50+08:00","dateModified":"2023-03-16T19:34:50+08:00","author":[{"@type":"Person","name":"Reid"}],"mainEntityOfPage":{"@type":"WebPage","@id":"https://reid00.github.io/posts/computation/spark-on-yarn-%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B%E8%A7%A3%E6%9E%90/"},"publisher":{"@type":"Organization","name":"Reid's Blog","logo":{"@type":"ImageObject","url":"https://reid00.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://reid00.github.io/ accesskey=h title="Reid's Blog (Alt + H)">Reid's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://reid00.github.io/archives title=Archive><span>Archive</span></a></li><li><a href=https://reid00.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://reid00.github.io/categories/ title=Categorys><span>Categorys</span></a></li><li><a href=https://reid00.github.io/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://reid00.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://reid00.github.io/posts/>Posts</a>&nbsp;»&nbsp;<a href=https://reid00.github.io/posts/computation/>计算相关的记录，如Spark Flink 等</a></div><h1 class=post-title>Spark on Yarn 执行流程解析</h1><div class=post-description>Spark on Yarn 执行流程解析</div><div class=post-meta><span title='2023-03-16 19:34:50 +0800 +0800'>2023-03-16</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;Reid</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#%e7%ae%80%e4%bb%8b aria-label=简介>简介</a></li><li><a href=#1-client%e5%ae%a2%e6%88%b7%e7%ab%af%e6%a8%a1%e5%bc%8f aria-label="1. Client(客户端)模式">1. Client(客户端)模式</a></li><li><a href=#2cluster%e9%9b%86%e7%be%a4%e6%a8%a1%e5%bc%8f%e7%94%9f%e4%ba%a7%e7%8e%af%e5%a2%83%e7%94%a8 aria-label=2.Cluster(集群)模式,生产环境用>2.Cluster(集群)模式,生产环境用</a><ul><li><a href=#%e6%80%bb%e7%bb%93 aria-label=总结:>总结:</a></li></ul></li><li><a href=#3-%e4%b8%a4%e7%a7%8d%e6%a8%a1%e5%bc%8f%e7%9a%84%e8%af%a6%e7%bb%86%e6%b5%81%e7%a8%8b%e5%9b%be aria-label="3. 两种模式的详细流程图">3. 两种模式的详细流程图</a><ul><li><a href=#client%e6%a8%a1%e5%bc%8f%e5%9b%be%e7%a4%ba aria-label=Client模式图示:>Client模式图示:</a></li><li><a href=#cluster-%e6%a8%a1%e5%bc%8f%e7%a4%ba%e6%84%8f%e5%9b%be aria-label="Cluster 模式示意图">Cluster 模式示意图</a></li></ul></li><li><a href=#4-%e8%bf%90%e8%a1%8c%e4%b8%ad%e6%b6%89%e5%8f%8a%e5%88%b0%e7%9a%84%e5%90%8d%e8%af%8d aria-label="4. 运行中涉及到的名词">4. 运行中涉及到的名词</a><ul><li><a href=#spark%e9%9b%86%e7%be%a4%e4%b8%ad%e7%9a%84%e8%a7%92%e8%89%b2 aria-label=Spark集群中的角色>Spark集群中的角色</a></li></ul></li></ul></div></details></div><div class=post-content><h1 id=简介>简介<a hidden class=anchor aria-hidden=true href=#简介>#</a></h1><p>当一个Spark应用提交到集群上运行时,应用架构包含了两个部分:</p><ul><li><code>Driver Program</code>（资源申请和调度Job执行）</li><li><code>Executors</code>（运行Job中Task任务和缓存数据），两个都是JVM Process进程</li></ul><p>Driver程序运行的位置可以通过<code>–deploy-mode</code> 来指定:</p><blockquote><p>Driver指的是The process running the main() function of the application and creating the SparkContext
运行应用程序的main()函数并创建SparkContext的进程</p></blockquote><ul><li><code>client</code>: 表示Driver运行在提交应用的Client上(默认)</li><li><code>cluster</code>: 表示Driver运行在集群中(Standalone：Worker，YARN：NodeManager)</li></ul><p>cluster和client模式最最本质的区别是：Driver程序运行在哪里。
企业实际生产环境中使用cluster 为主要模式。
<img loading=lazy src=https://raw.githubusercontent.com/Reid00/image-host/main/20220617/image.5mjo3vzvj440.webp alt=drive></p><h1 id=1-client客户端模式>1. Client(客户端)模式<a hidden class=anchor aria-hidden=true href=#1-client客户端模式>#</a></h1><p>DeployMode为Client，表示应用Driver Program运行在提交应用Client主机上。
示意图:
<img loading=lazy src=https://raw.githubusercontent.com/Reid00/image-host/main/20220617/image.62u7ws7bzr00.webp alt=img></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl><span class=nv>SPARK_HOME</span><span class=o>=</span>/export/server/spark
</span></span><span class=line><span class=cl><span class=si>${</span><span class=nv>SPARK_HOME</span><span class=si>}</span>/bin/spark-submit <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>--master yarn  <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>--deploy-mode client <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>--driver-memory 512m <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>--executor-memory 512m <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>--num-executors <span class=m>1</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>--total-executor-cores <span class=m>2</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>--class org.apache.spark.examples.SparkPi <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span><span class=si>${</span><span class=nv>SPARK_HOME</span><span class=si>}</span>/examples/jars/spark-examples_2.11-2.4.5.jar <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span><span class=m>10</span>
</span></span></code></pre></td></tr></table></div></div><h1 id=2cluster集群模式生产环境用>2.Cluster(集群)模式,生产环境用<a hidden class=anchor aria-hidden=true href=#2cluster集群模式生产环境用>#</a></h1><p>DeployMode为Cluster，表示应用Driver Program运行在集群从节点某台机器上.
<img loading=lazy src=https://raw.githubusercontent.com/Reid00/image-host/main/20220617/image.bcjkbdfzq0o.webp alt=cluster></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl><span class=nv>SPARK_HOME</span><span class=o>=</span>/export/server/spark
</span></span><span class=line><span class=cl><span class=si>${</span><span class=nv>SPARK_HOME</span><span class=si>}</span>/bin/spark-submit <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>--master yarn <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>--deploy-mode cluster <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>--driver-memory 512m <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>--executor-memory 512m <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>--num-executors <span class=m>1</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>--total-executor-cores <span class=m>2</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>--class org.apache.spark.examples.SparkPi <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span><span class=si>${</span><span class=nv>SPARK_HOME</span><span class=si>}</span>/examples/jars/spark-examples_2.11-2.4.5.jar <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span><span class=m>10</span>
</span></span></code></pre></td></tr></table></div></div><h2 id=总结>总结:<a hidden class=anchor aria-hidden=true href=#总结>#</a></h2><p>Client模式和Cluster模式最最本质的区别是：Driver程序运行在哪里。</p><ul><li>Client模式：测试时使用，开发不用，了解即可<ol><li>Driver运行在Client上,和集群的通信成本高</li><li>Driver输出结果会在客户端显示</li></ol></li><li>Cluster模式：生产环境中使用该模式<ol><li>Driver程序在YARN集群中，和集群的通信成本低</li><li>Driver输出结果不能在客户端显示</li><li>该模式下Driver运行ApplicattionMaster这个节点上,由Yarn管理，如果出现问题，yarn会重启ApplicattionMaster(Driver)</li></ol></li></ul><h1 id=3-两种模式的详细流程图>3. 两种模式的详细流程图<a hidden class=anchor aria-hidden=true href=#3-两种模式的详细流程图>#</a></h1><h2 id=client模式图示>Client模式图示:<a hidden class=anchor aria-hidden=true href=#client模式图示>#</a></h2><p>在YARN Client模式下，Driver在任务提交的本地机器上运行。
<img loading=lazy src=https://raw.githubusercontent.com/Reid00/image-host/main/20220617/image.5rkxwp8nyx00.webp alt=client></p><ol><li>Driver在任务提交的本地机器上运行，Driver启动后会和ResourceManager通讯申请启动ApplicationMaster</li></ol><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>--master yarn <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>--deploy-mode client <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>--driver-memory 512m <span class=se>\
</span></span></span></code></pre></td></tr></table></div></div><ol start=2><li>随后ResourceManager分配Container，在合适的NodeManager上启动ApplicationMaster，此时的ApplicationMaster的功能相当于一个ExecutorLaucher，只负责向ResourceManager申请Executor内存</li></ol><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>--executor-memory 512m <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>--executor-cores <span class=m>2</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>--num-executors <span class=m>1</span> <span class=se>\
</span></span></span></code></pre></td></tr></table></div></div><ol start=3><li>ResourceManager接到ApplicationMaster的资源申请后会分配Container，然后ApplicationMaster在资源分配指定的NodeManager上启动Executor进程；</li><li>Executor进程启动后会向Driver反向注册，Executor全部注册完成后Driver开始执行main函数；</li><li>之后执行到Action算子时，触发一个Job，并根据宽依赖开始划分Stage，每个Stage生成对应的TaskSet，之后将Task分发到各个Executor上执行。</li></ol><h2 id=cluster-模式示意图>Cluster 模式示意图<a hidden class=anchor aria-hidden=true href=#cluster-模式示意图>#</a></h2><p>在YARN Cluster模式下，Driver运行在NodeManager Contanier中，此时Driver与AppMaster合为一体。
<img loading=lazy src=https://raw.githubusercontent.com/Reid00/image-host/main/20220617/image.2yxrfgwo0cg0.webp alt=cluster></p><ol><li>Driver在任务提交的本地机器上运行，Driver启动后会和ResourceManager通讯申请启动ApplicationMaster</li></ol><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>--master yarn <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>--deploy-mode cluster <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>--driver-memory 512m <span class=se>\
</span></span></span></code></pre></td></tr></table></div></div><ol start=2><li>随后ResourceManager分配Container，在合适的NodeManager上启动ApplicationMaster，此时的ApplicationMaster的功能相当于一个ExecutorLaucher，只负责向ResourceManager申请Executor内存</li></ol><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>--executor-memory 512m <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>--executor-cores <span class=m>2</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>--num-executors <span class=m>1</span> <span class=se>\
</span></span></span></code></pre></td></tr></table></div></div><ol start=3><li>ResourceManager接到ApplicationMaster的资源申请后会分配Container，然后ApplicationMaster在资源分配指定的NodeManager上启动Executor进程；</li><li>Executor进程启动后会向Driver反向注册，Executor全部注册完成后Driver开始执行main函数；</li><li>之后执行到Action算子时，触发一个Job，并根据宽依赖开始划分Stage，每个Stage生成对应的TaskSet，之后将Task分发到各个Executor上执行。</li></ol><h1 id=4-运行中涉及到的名词>4. 运行中涉及到的名词<a hidden class=anchor aria-hidden=true href=#4-运行中涉及到的名词>#</a></h1><ol><li>Application: Appliction都是指用户编写的Spark应用程序，其中包括一个Driver功能的代码和分布在集群中多个节点上运行的Executor代码</li><li>Driver: Spark中的Driver即运行上述Application的main函数并创建SparkContext，创建- SparkContext的目的是为了准备Spark应用程序的运行环境，当Executor部分运行完毕后，Driver同时负责将SparkContext关闭，通常用SparkContext代表Driver</li><li>AppMaster: 控制yarn app运行和任务资源</li><li>Executor: 某个Application运行在worker节点上的一个进程， 该进程负责运行某些Task， 并且负责将数据存到内存或磁盘上，每个Application都有各自独立的一批Executor</li><li>Worker: 集群中任何可以运行Application代码的节点，在Standalone模式中指的是通过slave文件配置的Worker节点，在Spark on Yarn模式下就是NodeManager节点</li><li>Task: 被送到某个Executor上的工作单元，但hadoopMR中的MapTask和ReduceTask概念一样，是运行Application的基本单位，多个Task组成一个Stage，而Task的调度和管理等是由TaskScheduler负责</li><li>Job: 包含多个Task组成的并行计算，往往由Spark Action触发生成， 一个Application中往往会产生多个Job</li><li>Stage: 每个Job会被拆分成多组Task， 作为一个TaskSet， 其名称为Stage，Stage的划分和调度是有DAGScheduler来负责的，Stage有非最终的Stage（Shuffle Map Stage）和最终的Stage（Result Stage）两种，Stage的边界就是发生shuffle的地方</li><li>DAGScheduler: 根据Job构建基于Stage的DAG（Directed Acyclic Graph有向无环图)，并提交Stage给TASkScheduler。 其划分Stage的依据是RDD之间的依赖的关系找出开销最小的调度方法</li><li>TASKSedulter: 将TaskSet提交给worker运行，每个Executor运行什么Task就是在此处分配的. TaskScheduler维护所有TaskSet，当Executor向Driver发生心跳时，TaskScheduler会根据资源剩余情况分配相应的Task。另外TaskScheduler还维护着所有Task的运行标签，重试失败的Task</li></ol><h2 id=spark集群中的角色>Spark集群中的角色<a hidden class=anchor aria-hidden=true href=#spark集群中的角色>#</a></h2><p><strong>Driver:</strong> 是一个JVM Process 进程，编写的Spark应用程序就运行在Driver上，由Driver进程执行；
<strong>Master(ResourceManager):</strong> 是一个JVM Process 进程，主要负责资源的调度和分配，并进行集群的监控等职责；
<strong>Worker(NodeManager)：</strong> 是一个JVM Process 进程，一个Worker运行在集群中的一台服务器上，主要负责两个职责，一个是用自己的内存存储RDD的某个或某些partition；另一个是启动其他进程和线程（Executor），对RDD上的partition进行并行的处理和计算。
<strong>Executor：</strong> 是一个JVM Process 进程，一个Worker(NodeManager)上可以运行多个Executor，Executor通过启动多个线程（task）来执行对RDD的partition进行并行计算，也就是执行我们对RDD定义的例如map、flatMap、reduce等算子操作。</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://reid00.github.io/tags/spark/>Spark</a></li><li><a href=https://reid00.github.io/tags/yarn/>yarn</a></li></ul><nav class=paginav><a class=prev href=https://reid00.github.io/posts/computation/spark-%E9%9D%A2%E8%AF%95%E6%B3%A8%E6%84%8F%E7%82%B9/><span class=title>« Prev</span><br><span>Spark 面试注意点</span></a>
<a class=next href=https://reid00.github.io/posts/computation/spark-%E5%B9%BF%E6%92%AD%E5%8F%98%E9%87%8F/><span class=title>Next »</span><br><span>Spark 广播变量</span></a></nav></footer><script src=https://utteranc.es/client.js repo=Reid00/hugo-blog-talks issue-term=pathname label=Comment theme=github-light crossorigin=anonymous async></script></article></main><footer class=footer><span>&copy; 2023 <a href=https://reid00.github.io/>Reid's Blog</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>