<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Posts | Reid's Blog</title><meta name=keywords content><meta name=description content="Posts - Reid's Blog"><meta name=author content="Reid"><link rel=canonical href=https://reid00.github.io/posts/><link crossorigin=anonymous href=/assets/css/stylesheet.d7fb4cbf980fe688a21621b06a795933c4e6bb2d4070ec940667af1715d84af2.css integrity="sha256-1/tMv5gP5oiiFiGwanlZM8Tmuy1AcOyUBmevFxXYSvI=" rel="preload stylesheet" as=style><link rel=icon href=https://reid00.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://reid00.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://reid00.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://reid00.github.io/apple-touch-icon.png><link rel=mask-icon href=https://reid00.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://reid00.github.io/posts/index.xml><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-QRR6GRNQGK"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-QRR6GRNQGK",{anonymize_ip:!1})}</script><meta property="og:title" content="Posts"><meta property="og:description" content="Reid's Personal Notes -- https://github.com/Reid00"><meta property="og:type" content="website"><meta property="og:url" content="https://reid00.github.io/posts/"><meta property="og:image" content="https://i.loli.net/2021/09/26/3OMGXylm8HUYJ6p.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://i.loli.net/2021/09/26/3OMGXylm8HUYJ6p.png"><meta name=twitter:title content="Posts"><meta name=twitter:description content="Reid's Personal Notes -- https://github.com/Reid00"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://reid00.github.io/posts/"}]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://reid00.github.io/ accesskey=h title="Reid's Blog (Alt + H)">Reid's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://reid00.github.io/archives title=Archive><span>Archive</span></a></li><li><a href=https://reid00.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://reid00.github.io/categories/ title=Categorys><span>Categorys</span></a></li><li><a href=https://reid00.github.io/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=https://reid00.github.io/>Home</a></div><h1>Posts
<a href=index.xml title=RSS aria-label=RSS><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" height="23"><path d="M4 11a9 9 0 019 9"/><path d="M4 4a16 16 0 0116 16"/><circle cx="5" cy="19" r="1"/></svg></a></h1></header><article class=post-entry><header class=entry-header><h2>常见距离的介绍</h2></header><div class=entry-content><p>机器学习常见距离介绍 1. 欧式距离 2. 曼哈顿距离 我们可以定义曼哈顿距离的正式意义为L1-距离或城市区块距离，也就是在欧几里得空间的固定直角坐标系上两点所形成的线段对轴产生的投影的距离总和。例如在平面上，坐标（x1, y1）的点P1与坐标（x2, y2）的点P2的曼哈顿距离为：，要注意的是，曼哈顿距离依赖座标系统的转度，而非系统在座标轴上的平移或映射。 通俗来讲，想象你在曼哈顿要从一个十字路口开车到另外一个十字路口，驾驶距离是两点间的直线距离吗？显然不是，除非你能穿越大楼。而实际驾驶距离就是这个“曼哈顿距离”，此即曼哈顿距离名称的来源， 同时，曼哈顿距离也称为城市街区距离(City Block distance)。
3. 切比雪夫距离 若二个向量或二个点p 、and q，其座标分别为p1,p2 4. 闵可夫斯基距离(Minkowski Distance) 闵氏距离不是一种距离，而是一组距离的定义.
(1) 闵氏距离的定义 两个n维变量a(x11,x12,…,x1n)与 b(x21,x22,…,x2n)间的闵可夫斯基距离定义为： 其中p是一个变参数。 当p=1时，就是曼哈顿距离 当p=2时，就是欧氏距离 当p→∞时，就是切比雪夫距离 根据变参数的不同，闵氏距离可以表示一类的距离。
5. 标准化欧氏距离 (Standardized Euclidean distance ) 标准化欧氏距离是针对简单欧氏距离的缺点而作的一种改进方案。标准欧氏距离的思路：既然数据各维分量的分布不一样，那先将各个分量都“标准化”到均值、方差相等。至于均值和方差标准化到多少，先复习点统计学知识。
假设样本集X的数学期望或均值(mean)为m，标准差(standard deviation，方差开根)为s，那么X的“标准化变量”X*表示为：(X-m）/s，而且标准化变量的数学期望为0，方差为1。
即，样本集的标准化过程(standardization)用公式描述就是： 标准化后的值 = ( 标准化前的值 － 分量的均值 ) /分量的标准差　经过简单的推导就可以得到两个n维向量a(x11,x12,…,x1n)与 b(x21,x22,…,x2n)间的标准化欧氏距离的公式：　如果将方差的倒数看成是一个权重，这个公式可以看成是一种加权欧氏距离(Weighted Euclidean distance)。
6. 马氏距离(Mahalanobis Distance) 有M个样本向量X1~Xm，协方差矩阵记为S，均值记为向量μ，则其中样本向量X到u的马氏距离表示为： (协方差矩阵中每个元素是各个矢量元素之间的协方差Cov(X,Y)，Cov(X,Y) = E{ [X-E(X)] [Y-E(Y)]}，其中E为数学期望）
而其中向量Xi与Xj之间的马氏距离定义为：
若协方差矩阵是单位矩阵（各个样本向量之间独立同分布）,则公式就成了： 也就是欧氏距离了。　若协方差矩阵是对角矩阵，公式变成了标准化欧氏距离。
马氏距离的优缺点：量纲无关，排除变量之间的相关性的干扰。 「微博上的seafood高清版点评道：原来马氏距离是根据协方差矩阵演变，一直被老师误导了，怪不得看Killian在05年NIPS发表的LMNN论文时候老是看到协方差矩阵和半正定，原来是这回事」 7.巴氏距离（Bhattacharyya Distance） 在统计中，Bhattacharyya距离测量两个离散或连续概率分布的相似性。它与衡量两个统计样品或种群之间的重叠量的Bhattacharyya系数密切相关。Bhattacharyya距离和Bhattacharyya系数以20世纪30年代曾在印度统计研究所工作的一个统计学家A....</p></div><footer class=entry-footer><span title='2022-06-08 09:40:38 +0800 +0800'>2022-06-08</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;Reid</footer><a class=entry-link aria-label="post link to 常见距离的介绍" href=https://reid00.github.io/posts/ml/%E5%B8%B8%E8%A7%81%E8%B7%9D%E7%A6%BB%E7%9A%84%E4%BB%8B%E7%BB%8D/></a></article><article class=post-entry><header class=entry-header><h2>决策树到随机森林</h2></header><div class=entry-content><p>简述决策树原理？ 决策树是一种自上而下，对样本数据进行树形分类的过程，由节点和有向边组成。节点分为内部节点和叶节点，其中每个内部节点表示一个特征或属性，叶节点表示类别。从顶部节点开始，所有样本聚在一起，经过根节点的划分，样本被分到不同的子节点中，再根据子节点的特征进一步划分，直至所有样本都被归到某个类别。
为什么要对决策树进行减枝？如何进行减枝？ 剪枝是决策树解决过拟合问题的方法。在决策树学习过程中，为了尽可能正确分类训练样本，结点划分过程将不断重复，有时会造成决策树分支过多，于是可能将训练样本学得太好，以至于把训练集自身的一些特点当作所有数据共有的一般特点而导致测试集预测效果不好，出现了过拟合现象。因此，可以通过剪枝来去掉一些分支来降低过拟合的风险。
决策树剪枝的基本策略有“预剪枝”和“后剪枝”。预剪枝是指在决策树生成过程中，对每个结点在划分前先进行估计，若当前结点的划分不能带来决策树泛化性能提升，则停止划分并将当前结点标记为叶结点；后剪枝则是先从训练集生成一棵完整的决策树，然后自底向上地对非叶结点进行考察，若将该结点对应的子树替换为叶结点能带来决策树泛化性能提升，则将该子树替换为叶结点。
预剪枝使得决策树的很多分支都没有"展开”，这不仅降低了过拟合的风险，还显著减少了决策树的训练时间开销和测试时间开销。但另一方面，有些分支的当前划分虽不能提升泛化性能、甚至可能导致泛化性能暂时下降?但在其基础上进行的后续划分却有可能导致性能显著提高；预剪枝基于"贪心"本质禁止这些分支展开，给预剪枝决策树带来了欠拟含的风险。
后剪枝决策树通常比预剪枝决策树保留了更多的分支，一般情形下后剪枝决策树的欠拟合风险很小，泛化性能往往优于预剪枝决策树 。但后剪枝过程是在生成完全决策树之后进行的 并且要白底向上对树中的所有非叶结点进行逐 考察，因此其训练时间开销比未剪枝决策树和预剪枝决策树都要大得多。
简述决策树的生成策略？ 决策树主要有ID3、C4.5、CART，算法的适用略有不同，但它们有个总原则，即在选择特征、向下分裂、树生成中，它们都是为了让信息更“纯”。
举一个简单例子，通过三个特征：是否有喉结、身高、体重，判断人群中的男女，是否有喉结把人群分为两部分，一边全是男性、一边全是女性，达到理想结果，纯度最高。 通过身高或体重，人群会有男有女。 上述三种算法，信息增益、增益率、基尼系数对“纯”的不同解读。如下详细阐述：
​ 综上，ID3采用信息增益作为划分依据，会倾向于取值较多的特征，因为信息增益反映的是给定条件以后不确定性减少的程度，特征取值越多就意味着不确定性更高。C4.5对ID3进行优化，通过引入信息增益率，对特征取值较多的属性进行惩罚。
随机森林 Bagging（套袋法） bagging的算法过程如下：
从原始样本集中使用Bootstraping方法随机抽取n个训练样本，共进行k轮抽取，得到k个训练集。（k个训练集之间相互独立，元素可以有重复） 对于k个训练集，我们训练k个模型（这k个模型可以根据具体问题而定，比如决策树，knn等） 对于分类问题：由投票表决产生分类结果；对于回归问题：由k个模型预测结果的均值作为最后预测结果。（所有模型的重要性相同） Boosting（提升法） boosting的算法过程如下：
对于训练集中的每个样本建立权值wi，表示对每个样本的关注度。当某个样本被误分类的概率很高时，需要加大对该样本的权值。 进行迭代的过程中，每一步迭代都是一个弱分类器。我们需要用某种策略将其组合，作为最终模型。（例如AdaBoost给每个弱分类器一个权值，将其线性组合最为最终分类器。误差越小的弱分类器，权值越大） 提升就是指每一步我都产生一个弱预测模型，然后加权累加到总模型中，然后每一步弱预测模型生成的的依据都是损失函数的负梯度方向，这样若干步以后就可以达到逼近损失函数局部最小值的目标。 Bagging，Boosting的主要区别 样本选择上：Bagging采用的是Bootstrap随机有放回抽样；而Boosting每一轮的训练集是不变的，改变的只是每一个样本的权重。
每轮训练过后如何调整样本权重 ？
如何确定最后各学习器的权重 这两个问题可由加法模型和指数损失函数推导出来。
样本权重：Bagging使用的是均匀取样，每个样本权重相等；Boosting根据错误率调整样本权重，错误率越大的样本权重越大。
预测函数：Bagging所有的预测函数的权重相等；Boosting中误差越小的预测函数其权重越大。
并行计算：Bagging各个预测函数可以并行生成；Boosting各个预测函数必须按顺序迭代生成。
下面是将决策树与这些算法框架进行结合所得到的新的算法： 1）Bagging + 决策树 = 随机森林 2）AdaBoost + 决策树 = 提升树 （自适应提升（AdaBoost）） 3）Gradient Boosting + 决策树 = GBDT 梯度下降提升树（GDBT）
首先既然是树，那么它的基函数肯定就是决策树啦，而损失函数则是根据我们具体的问题去分析，但方法都一样，最终都走上了梯度下降的老路，比如说进行到第m步的时候，首先计算残差
有了残差之后，我们再用（xi,rim）去拟合第m个基函数，假设这棵树把输入空间划分成j个空间R1m，R2m……，Rjm，假设它在每个空间上的输出为bjm，这样的话，第m棵树可以表示如下：
下一步，对树的每个区域分别用线性搜索的方式寻找最佳步长，这个步长可以和上面的区域预测值bjm进行合并，最后就得到了第m步的目标函数
当然了，对于GDBT比较容易出现过拟合的情况，所以有必要增加一点正则项，比如叶节点的数目或叶节点预测值的平方和，进而限制模型复杂度的过度提升，这里在下面的实践中的参数设置我们可以继续讨论。
构造随机森林的 4 个步骤： 假如有N个样本，则有放回的随机选择N个样本(每次随机选择一个样本，然后返回继续选择)。这选择好了的N个样本用来训练一个决策树，作为决策树根节点处的样本。
当每个样本有M个属性时，在决策树的每个节点需要分裂时，随机从这M个属性中选取出m个属性，满足条件m « M。然后从这m个属性中采用某种策略（比如说信息增益）来选择1个属性作为该节点的分裂属性。
策树形成过程中每个节点都要按照步骤2来分裂（很容易理解，如果下一次该节点选出来的那一个属性是刚刚其父节点分裂时用过的属性，则该节点已经达到了叶子节点，无须继续分裂了）。一直到不能够再分裂为止。注意整个决策树形成过程中没有进行剪枝。
按照步骤1~3建立大量的决策树，这样就构成了随机森林了。
随机森林的优缺点 优点 它可以出来很高维度（特征很多）的数据，并且不用降维，无需做特征选择 它可以判断特征的重要程度 可以判断出不同特征之间的相互影响 不容易过拟合 训练速度比较快，容易做成并行方法 实现起来比较简单 对于不平衡的数据集来说，它可以平衡误差。 如果有很大一部分的特征遗失，仍可以维持准确度。 缺点 随机森林已经被证明在某些噪音较大的分类或回归问题上会过拟合。 对于有不同取值的属性的数据，取值划分较多的属性会对随机森林产生更大的影响，所以随机森林在这种数据上产出的属性权值是不可信的</p></div><footer class=entry-footer><span title='2022-06-08 09:37:05 +0800 +0800'>2022-06-08</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;Reid</footer><a class=entry-link aria-label="post link to 决策树到随机森林" href=https://reid00.github.io/posts/ml/%E5%86%B3%E7%AD%96%E6%A0%91%E5%88%B0%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97/></a></article><article class=post-entry><header class=entry-header><h2>KMeans聚类分析</h2></header><div class=entry-content><p>聚类与分类的区别 分类：类别是已知的，通过对已知分类的数据进行训练和学习，找到这些不同类的特征，再对未分类的数据进行分类。属于监督学习。
聚类：事先不知道数据会分为几类，通过聚类分析将数据聚合成几个群体。聚类不需要对数据进行训练和学习。属于无监督学习。
关于监督学习和无监督学习，这里给一个简单的介绍：是否有监督，就看输入数据是否有标签，输入数据有标签，则为有监督学习，否则为无监督学习。
k-means 聚类 聚类算法有很多种，K-Means 是聚类算法中的最常用的一种，算法最大的特点是简单，好理解，运算速度快，但是只能应用于连续型的数据，并且一定要在聚类前需要手工指定要分成几类。
K-Means 聚类算法的大致意思就是“物以类聚，人以群分”：
首先输入 k 的值，即我们指定希望通过聚类得到 k 个分组； 从数据集中随机选取 k 个数据点作为初始大佬（质心）； 对集合中每一个小弟，计算与每一个大佬的距离，离哪个大佬距离近，就跟定哪个大佬。 这时每一个大佬手下都聚集了一票小弟，这时候召开选举大会，每一群选出新的大佬（即通过算法选出新的质心）。 如果新大佬和老大佬之间的距离小于某一个设置的阈值（表示重新计算的质心的位置变化不大，趋于稳定，或者说收敛），可以认为我们进行的聚类已经达到期望的结果，算法终止。 如果新大佬和老大佬距离变化很大，需要迭代3~5步骤。 用Python 代码实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 # dataSet样本点,k 簇的个数 # disMeas距离量度，默认为欧几里得距离 # createCent,初始点的选取 def kMeans(dataSet, k, distMeas=distEclud, createCent=randCent): m = shape(dataSet)[0] #样本数 clusterAssment = mat(zeros((m,2))) #m*2的矩阵 centroids = createCent(dataSet, k) #初始化k个中心 clusterChanged = True while clusterChanged: #当聚类不再变化 clusterChanged = False for i in range(m): minDist = inf; minIndex = -1 for j in range(k): #找到最近的质心 distJI = distMeas(centroids[j,:],dataSet[i,:]) if distJI &lt; minDist: minDist = distJI; minIndex = j if clusterAssment[i,0] !...</p></div><footer class=entry-footer><span title='2022-06-08 09:35:33 +0800 +0800'>2022-06-08</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;Reid</footer><a class=entry-link aria-label="post link to KMeans聚类分析" href=https://reid00.github.io/posts/ml/kmeans%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90/></a></article><article class=post-entry><header class=entry-header><h2>L1L2正则</h2></header><div class=entry-content><p>概念 L0：计算非零个数，用于产生稀疏性，但是在实际研究中很少用，因为L0范数很难优化求解，是一个NP-hard问题，因此更多情况下我们是使用L1范数 L1：计算绝对值之和，用以产生稀疏性，因为它是L0范式的一个最优凸近似，容易优化求解 L2：计算平方和再开根号，L2范数更多是防止过拟合，并且让优化求解变得稳定很快速（这是因为加入了L2范式之后，满足了强凸）。
L1范数(Lasso Regularization)：向量中各个元素绝对值的和。
L2范数(Ridge Regression)：向量中各元素平方和再求平方根。
作用 L1正则化可以产生稀疏权值矩阵，即产生一个稀疏模型，可以用于特征选择
L2正则化可以防止模型过拟合（overfitting）；一定程度上，L1也可以防止过拟合
L1正则化是在代价函数后面加上 L2正则化是在代价函数后面增加了 两者都起到一定的过拟合作用，两者都对应一定的先验知识，L1对应拉普拉斯分布，L2对应高斯分布，L1偏向于参数稀疏性，L2偏向于参数分布较为稠。</p></div><footer class=entry-footer><span title='2022-06-08 09:32:08 +0800 +0800'>2022-06-08</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;Reid</footer><a class=entry-link aria-label="post link to L1L2正则" href=https://reid00.github.io/posts/ml/l1l2%E6%AD%A3%E5%88%99/></a></article><article class=post-entry><header class=entry-header><h2>逻辑回归的常见面试题总结</h2></header><div class=entry-content><p>1.简介 逻辑回归是面试当中非常喜欢问到的一个机器学习算法，因为表面上看逻辑回归形式上很简单，很好掌握，但是一问起来就容易懵逼。所以在面试的时候给大家的第一个建议不要说自己精通逻辑回归，非常容易被问倒，从而减分。下面总结了一些平常我在作为面试官面试别人和被别人面试的时候，经常遇到的一些问题。
Regression问题的常规步骤为：
寻找h函数（即假设估计的函数）； 构造J函数（损失函数）； 想办法使得J函数最小并求得回归参数（θ）； 数据拟合问题 2.正式介绍 如何凸显你是一个对逻辑回归已经非常了解的人呢。那就是用一句话概括它！逻辑回归假设数据服从伯努利分布,通过极大化似然函数的方法，运用梯度下降来求解参数，来达到将数据二分类的目的。
这里面其实包含了5个点 1：逻辑回归的假设，2：逻辑回归的损失函数，3：逻辑回归的求解方法，4：逻辑回归的目的，5:逻辑回归如何分类。这些问题是考核你对逻辑回归的基本了解。
逻辑回归的基本假设 任何的模型都是有自己的假设，在这个假设下模型才是适用的。逻辑回归的第一个基本假设是**假设数据服从伯努利分布。**伯努利分布有一个简单的例子是抛硬币，抛中为正面的概率是pp,抛中为负面的概率是1−p1−p.在逻辑回归这个模型里面是假设 hθ(x)hθ(x) 为样本为正的概率，1−hθ(x)1−hθ(x)为样本为负的概率。那么整个模型可以描述为
hθ(x;θ)=phθ(x;θ)=p
逻辑回归的第二个假设是假设样本为正的概率是
p=11+e−θTxp=11+e−θTx
所以逻辑回归的最终形式
hθ(x;θ)=11+e−θTx
逻辑回归的求解方法 由于该极大似然函数无法直接求解，我们一般通过对该函数进行梯度下降来不断逼急最优解。在这个地方其实会有个加分的项，考察你对其他优化方法的了解。因为就梯度下降本身来看的话就有随机梯度下降，批梯度下降，small batch 梯度下降三种方式，面试官可能会问这三种方式的优劣以及如何选择最合适的梯度下降方式。
简单来说 批梯度下降会获得全局最优解，缺点是在更新每个参数的时候需要遍历所有的数据，计算量会很大，并且会有很多的冗余计算，导致的结果是当数据量大的时候，每个参数的更新都会很慢。
随机梯度下降是以高方差频繁更新，优点是使得sgd（随机梯度下降）会跳到新的和潜在更好的局部最优解，缺点是使得收敛到局部最优解的过程更加的复杂。
如果使用梯度下降法(批量梯度下降法)，那么每次迭代过程中都要对 个样本进行求梯度，所以开销非常大，随机梯度下降的思想就是随机采样一个样本 来更新参数，那么计算开销就从 下降到 。
随机梯度下降虽然提高了计算效率，降低了计算开销，但是由于每次迭代只随机选择一个样本，因此随机性比较大，所以下降过程中非常曲折
可以看到多了随机两个字，随机也就是说我们用样本中的一个例子来近似我所有的样本，来调整θ，因而随机梯度下降是会带来一定的问题，因为计算得到的并不是准确的一个梯度，**对于最优化问题，凸问题，**虽然不是每次迭代得到的损失函数都向着全局最优方向， 但是大的整体的方向是向全局最优解的，最终的结果往往是在全局最优解附近。
小批量梯度下降结合了sgd和batch gd的优点，每次更新的时候使用n个样本。减少了参数更新的次数，可以达到更加稳定收敛结果，一般在深度学习当中我们采用这种方法。小批量梯度下降的开销为 其中 是批量大小。
其实这里还有一个隐藏的更加深的加分项，看你了不了解诸如Adam，动量法等优化方法。因为上述方法其实还有两个致命的问题。 第一个是如何对模型选择合适的学习率。自始至终保持同样的学习率其实不太合适。因为一开始参数刚刚开始学习的时候，此时的参数和最优解隔的比较远，需要保持一个较大的学习率尽快逼近最优解。但是学习到后面的时候，参数和最优解已经隔的比较近了，你还保持最初的学习率，容易越过最优点，在最优点附近来回振荡，通俗一点说，就很容易学过头了，跑偏了。 第二个是如何对参数选择合适的学习率。在实践中，对每个参数都保持的同样的学习率也是很不合理的。有些参数更新频繁，那么学习率可以适当小一点。有些参数更新缓慢，那么学习率就应该大一点。这里我们不展开，有空我会专门出一个专题介绍。 逻辑回归的目的 该函数的目的便是将数据二分类，提高准确率。 逻辑回归如何分类 逻辑回归作为一个回归(也就是y值是连续的)，如何应用到分类上去呢。y值确实是一个连续的变量。逻辑回归的做法是划定一个阈值，y值大于这个阈值的是一类，y值小于这个阈值的是另外一类。阈值具体如何调整根据实际情况选择。一般会选择0.5做为阈值来划分。 逻辑回归的损失函数为什么要使用极大似然函数作为损失函数？ 损失函数一般有四种，平方损失函数，对数损失函数，HingeLoss0-1损失函数，绝对值损失函数。将极大似然函数取对数以后等同于对数损失函数。在逻辑回归这个模型下，对数损失函数的训练求解参数的速度是比较快的。至于原因大家可以求出这个式子的梯度更新
这个式子的更新速度只和相关。和sigmod函数本身的梯度是无关的。这样更新的速度是可以自始至终都比较的稳定。
为什么不选平方损失函数的呢？其一是因为如果你使用平方损失函数，你会发现梯度更新的速度和sigmod函数本身的梯度是很相关的。sigmod函数在它在定义域内的梯度都不大于0.25。这样训练会非常的慢。
逻辑回归在训练的过程当中，如果有很多的特征高度相关或者说有一个特征重复了100遍，会造成怎样的影响？ 先说结论，如果在损失函数最终收敛的情况下，其实就算有很多特征高度相关也不会影响分类器的效果。
但是对特征本身来说的话，假设只有一个特征，在不考虑采样的情况下，你现在将它重复100遍。训练以后完以后，数据还是这么多，但是这个特征本身重复了100遍，实质上将原来的特征分成了100份，每一个特征都是原来特征权重值的百分之一
如果在随机采样的情况下，其实训练收敛完以后，还是可以认为这100个特征和原来那一个特征扮演的效果一样，只是可能中间很多特征的值正负相消了。
为什么我们还是会在训练的过程当中将高度相关的特征去掉？ 去掉高度相关的特征会让模型的可解释性更好 可以大大提高训练的速度。如果模型当中有很多特征高度相关的话，就算损失函数本身收敛了，但实际上参数是没有收敛的，这样会拉低训练的速度。其次是特征多了，本身就会增大训练的时间。 4.逻辑回归的优缺点总结 优点
形式简单，模型的可解释性非常好。从特征的权重可以看到不同的特征对最后结果的影响，某个特征的权重值比较高，那么这个特征最后对结果的影响会比较大。
模型效果不错。在工程上是可以接受的（作为baseline)，如果特征工程做的好，效果不会太差，并且特征工程可以大家并行开发，大大加快开发的速度。
训练速度较快。分类的时候，计算量仅仅只和特征的数目相关。并且逻辑回归的分布式优化sgd发展比较成熟，训练的速度可以通过堆机器进一步提高，这样我们可以在短时间内迭代好几个版本的模型。
资源占用小,尤其是内存。因为只需要存储各个维度的特征值，。
方便输出结果调整。逻辑回归可以很方便的得到最后的分类结果，因为输出的是每个样本的概率分数，我们可以很容易的对这些概率分数进行cutoff，也就是划分阈值(大于某个阈值的是一类，小于某个阈值的是一类)。
但是逻辑回归本身也有许多的缺点:
准确率并不是很高。因为形式非常的简单(非常类似线性模型)，很难去拟合数据的真实分布。
很难处理数据不平衡的问题。举个例子：如果我们对于一个正负样本非常不平衡的问题比如正负样本比 10000:1.我们把所有样本都预测为正也能使损失函数的值比较小。但是作为一个分类器，它对正负样本的区分能力不会很好。
处理非线性数据较麻烦。逻辑回归在不引入其他方法的情况下，只能处理线性可分的数据，或者进一步说，处理二分类的问题 。...</p></div><footer class=entry-footer><span title='2022-06-08 09:27:08 +0800 +0800'>2022-06-08</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;Reid</footer><a class=entry-link aria-label="post link to 逻辑回归的常见面试题总结" href=https://reid00.github.io/posts/ml/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E7%9A%84%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98%E6%80%BB%E7%BB%93/></a></article><article class=post-entry><header class=entry-header><h2>SVM</h2></header><div class=entry-content><p>1. SVM SVM的应用 SVM在很多诸如文本分类，图像分类，生物序列分析和生物数据挖掘，手写字符识别等领域有很多的应用，但或许你并没强烈的意识到，SVM可以成功应用的领域远远超出现在已经在开发应用了的领域。
通常人们会从一些常用的核函数中选择（根据问题和数据的不同，选择不同的参数，实际上就是得到了不同的核函数），例如：多项式核、高斯核、线性核。
SVM是一种二类分类模型。它的基本模型是在特征空间中寻找间隔最大化的分离超平面的线性分类器。（间隔最大是它有别于感知机）
（1）当训练样本线性可分时，通过硬间隔最大化，学习一个线性分类器，即线性可分支持向量机；
（2）当训练数据近似线性可分时，引入松弛变量，通过软间隔最大化，学习一个线性分类器，即线性支持向量机；
（3）当训练数据线性不可分时，通过使用核技巧及软间隔最大化，学习非线性支持向量机。
注：以上各SVM的数学推导应该熟悉：硬间隔最大化（几何间隔）—学习的对偶问题—软间隔最大化（引入松弛变量）—非线性支持向量机（核技巧）。
读者可能还是没明白核函数到底是个什么东西？我再简要概括下，即以下三点：
实际中，我们会经常遇到线性不可分的样例，此时，我们的常用做法是把样例特征映射到高维空间中去(映射到高维空间后，相关特征便被分开了，也就达到了分类的目的)； 但进一步，如果凡是遇到线性不可分的样例，一律映射到高维空间，那么这个维度大小是会高到可怕的。那咋办呢？ 此时，核函数就隆重登场了，核函数的价值在于它虽然也是将特征进行从低维到高维的转换，但核函数绝就绝在它事先在低维上进行计算，而将实质上的分类效果表现在了高维上，避免了直接在高维空间中的复杂计算 2. SVM的一些问题 SVM为什么采用间隔最大化？ 当训练数据线性可分时，存在无穷个分离超平面可以将两类数据正确分开。
感知机利用误分类最小策略，求得分离超平面，不过此时的解有无穷多个。
线性可分支持向量机利用间隔最大化求得最优分离超平面，这时，解是唯一的。另一方面，此时的分隔超平面所产生的分类结果是最鲁棒的，对未知实例的泛化能力最强。
然后应该借此阐述，几何间隔，函数间隔，及从函数间隔—>求解最小化1/2 ||w||^2 时的w和b。即线性可分支持向量机学习算法—最大间隔法的由来。
SVM如何处理多分类问题？** 一般有两种做法：一种是直接法，直接在目标函数上修改，将多个分类面的参数求解合并到一个最优化问题里面。看似简单但是计算量却非常的大。
另外一种做法是间接法：对训练器进行组合。其中比较典型的有一对一，和一对多。
一对多，就是对每个类都训练出一个分类器，由svm是二分类，所以将此而分类器的两类设定为目标类为一类，其余类为另外一类。这样针对k个类可以训练出k个分类器，当有一个新的样本来的时候，用这k个分类器来测试，那个分类器的概率高，那么这个样本就属于哪一类。这种方法效果不太好，bias比较高。
svm一对一法（one-vs-one），针对任意两个类训练出一个分类器，如果有k类，一共训练出C(2,k) 个分类器，这样当有一个新的样本要来的时候，用这C(2,k) 个分类器来测试，每当被判定属于某一类的时候，该类就加一，最后票数最多的类别被认定为该样本的类。
是否存在一组参数使SVM训练误差为0？ Y
训练误差为0的SVM分类器一定存在吗？ 一定存在
加入松弛变量的SVM的训练误差可以为0吗？ 如果数据中出现了离群点outliers，那么就可以使用松弛变量来解决。
使用SMO算法训练的线性分类器并不一定能得到训练误差为0的模型。这是由 于我们的优化目标改变了，并不再是使训练误差最小。
带核的SVM为什么能分类非线性问题? 核函数的本质是两个函数的內积，通过核函数将其隐射到高维空间，在高维空间非线性问题转化为线性问题, SVM得到超平面是高维空间的线性分类平面。其分类结果也视为低维空间的非线性分类结果, 因而带核的SVM就能分类非线性问题。
如何选择核函数？ 如果特征的数量大到和样本数量差不多，则选用LR或者线性核的SVM； 如果特征的数量小，样本的数量正常，则选用SVM+高斯核函数； 如果特征的数量小，而样本的数量很大，则需要手工添加一些特征从而变成第一种情况。 3. LR和SVM的联系与区别 相同点 都是线性分类器。本质上都是求一个最佳分类超平面。
都是监督学习算法
都是判别模型。判别模型不关心数据是怎么生成的，它只关心信号之间的差别，然后用差别来简单对给定的一个信号进行分类。常见的判别模型有：KNN、SVM、LR，常见的生成模型有：朴素贝叶斯，隐马尔可夫模型。
不同点 LR是参数模型，svm是非参数模型，linear和rbf则是针对数据线性可分和不可分的区别
从目标函数来看，区别在于逻辑回归采用的是logistical loss，SVM采用的是hinge loss，这两个损失函数的目的都是增加对分类影响较大的数据点的权重，减少与分类关系较小的数据点的权重。
SVM的处理方法是只考虑support vectors，也就是和分类最相关的少数点，去学习分类器。而逻辑回归通过非线性映射，大大减小了离分类平面较远的点的权重，相对提升了与分类最相关的数据点的权重。
逻辑回归相对来说模型更简单，好理解，特别是大规模线性分类时比较方便。而SVM的理解和优化相对来说复杂一些，SVM转化为对偶问题后,分类只需要计算与少数几个支持向量的距离,这个在进行复杂核函数计算时优势很明显,能够大大简化模型和计算。
logic 能做的 svm能做，但可能在准确率上有问题，svm能做的logic有的做不了。
4. 线性分类器与非线性分类器的区别以及优劣 线性和非线性是针对模型参数和输入特征来讲的；比如输入x，模型y=ax+ax^2 那么就是非线性模型，如果输入是x和X^2则模型是线性的。
线性分类器可解释性好，计算复杂度较低，不足之处是模型的拟合效果相对弱些。
LR,贝叶斯分类，单层感知机、线性回归
非线性分类器效果拟合能力较强，不足之处是数据量不足容易过拟合、计算复杂度高、可解释性不好。...</p></div><footer class=entry-footer><span title='2022-06-07 20:04:15 +0800 +0800'>2022-06-07</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;Reid</footer><a class=entry-link aria-label="post link to SVM" href=https://reid00.github.io/posts/ml/svm/></a></article><article class=post-entry><header class=entry-header><h2>决策树</h2></header><div class=entry-content><p>决策树 决策树（decision tree）是一个树结构（可以是二叉树或非二叉树）。其每个非叶节点表示一个特征属性上的测试，每个分支代表这个特征属性在某个值域上的输出，而每个叶节点存放一个类别。使用决策树进行决策的过程就是从根节点开始，测试待分类项中相应的特征属性，并按照其值选择输出分支，直到到达叶子节点，将叶子节点存放的类别作为决策结果[1]。 下面先来看一个小例子，看看决策树到底是什么概念（这个例子来源于[2]）。
决策树的训练数据往往就是这样的表格形式，表中的前三列（ID不算）是数据样本的属性，最后一列是决策树需要做的分类结果。通过该数据，构建的决策树如下：
有了这棵树，我们就可以对新来的用户数据进行是否可以偿还的预测了。
决策树最重要的是决策树的构造。所谓决策树的构造就是进行属性选择度量确定各个特征属性之间的拓扑结构。构造决策树的关键步骤是分裂属性。所谓分裂属性就是在某个节点处按照某一特征属性的不同划分构造不同的分支，其目标是让各个分裂子集尽可能地“纯”。尽可能“纯”就是尽量让一个分裂子集中待分类项属于同一类别。分裂属性分为三种不同的情况[1]： 1、属性是离散值且不要求生成二叉决策树。此时用属性的每一个划分作为一个分支。 2、属性是离散值且要求生成二叉决策树。此时使用属性划分的一个子集进行测试，按照“属于此子集”和“不属于此子集”分成两个分支。 3、属性是连续值。此时确定一个值作为分裂点split_point，按照>split_point和&lt;=split_point生成两个分支。
决策树的属性分裂选择是”贪心“算法，也就是没有回溯的。
ID3.5 好了，接下来说一下教科书上提到最多的决策树ID3.5算法（是最基本的模型，简单实用，但是在某些场合下也有缺陷）。
信息论中有熵（entropy）的概念，表示状态的混乱程度，熵越大越混乱。熵的变化可以看做是信息增益，决策树ID3算法的核心思想是以信息增益度量属性选择，选择分裂后信息增益最大的属性进行分裂。
设D为用（输出）类别对训练元组进行的划分，则D的熵表示为： info(D)=−∑i=1mpilog2(pi)info(D)=−∑i=1mpilog2⁡(pi)
其中pipi表示第i个类别在整个训练元组中出现的概率，一般来说会用这个类别的样本数量占总量的占比来作为概率的估计；熵的实际意义表示是D中元组的类标号所需要的平均信息量。熵的含义可以看我前面写的PRML ch1.6 信息论的介绍。 如果将训练元组D按属性A进行划分，则A对D划分的期望信息为： infoA(D)=∑j=1v|Dj||D|info(Dj) infoA(D)=∑j=1v|Dj||D|info(Dj) 于是，信息增益就是两者的差值： gain(A)=info(D)−infoA(D) gain(A)=info(D)−infoA(D) ID3决策树算法就用到上面的信息增益，在每次分裂的时候贪心选择信息增益最大的属性，作为本次分裂属性。每次分裂就会使得树长高一层。这样逐步生产下去，就一定可以构建一颗决策树。（基本原理就是这样，但是实际中，为了防止过拟合，以及可能遇到叶子节点类别不纯的情况，需要有一些特殊的trick，这些留到最后讲）
OK，借鉴一下[1]中的一个小例子，来看一下信息增益的计算过程。
这个例子是这样的：输入样本的属性有三个——日志密度（L），好友密度（F），以及是否使用真实头像（H）；样本的标记是账号是否真实yes or no。
然后可以一次计算每一个属性的信息增益，比如日致密度的信息增益是0.276。
同理可得H和F的信息增益为0.033和0.553。因为F具有最大的信息增益，所以第一次分裂选择F为分裂属性，分裂后的结果如下图表示：
上面为了简便，将特征属性离散化了，其实日志密度和好友密度都是连续的属性。对于特征属性为连续值，可以如此使用ID3算法：先将D中元素按照特征属性排序，则每两个相邻元素的中间点可以看做潜在分裂点，从第一个潜在分裂点开始，分裂D并计算两个集合的期望信息，具有最小期望信息的点称为这个属性的最佳分裂点，其信息期望作为此属性的信息期望。
C4.5 ID3有一些缺陷，就是选择的时候容易选择一些比较容易分纯净的属性，尤其在具有像ID值这样的属性，因为每个ID都对应一个类别，所以分的很纯净，ID3比较倾向找到这样的属性做分裂。
C4.5算法定义了分裂信息，表示为： split_infoA(D)=−∑j=1v|Dj||D|log2(|Dj||D|) split_infoA(D)=−∑j=1v|Dj||D|log2⁡(|Dj||D|) 很容易理解，这个也是一个熵的定义，pi=|Dj||D|pi=|Dj||D|，可以看做是属性分裂的熵，分的越多就越混乱，熵越大。定义信息增益率： gain_ratio(A)=gain(A)split_info(A) gain_ratio(A)=gain(A)split_info(A)
C4.5就是选择最大增益率的属性来分裂，其他类似ID3.5。
CART CART（Classification And Regression Tree）算法既可以用于创建分类树，也可以用于创建回归树。CART算法的重要特点包含以下三个方面：
二分(Binary Split)：在每次判断过程中，都是对样本数据进行二分。CART算法是一种二分递归分割技术，把当前样本划分为两个子样本，使得生成的每个非叶子结点都有两个分支，因此CART算法生成的决策树是结构简洁的二叉树。由于CART算法构成的是一个二叉树，它在每一步的决策时只能是“是”或者“否”，即使一个feature有多个取值，也是把数据分为两部分 单变量分割(Split Based on One Variable)：每次最优划分都是针对单个变量。 剪枝策略：CART算法的关键点，也是整个Tree-Based算法的关键步骤。剪枝过程特别重要，所以在最优决策树生成过程中占有重要地位。有研究表明，剪枝过程的重要性要比树生成过程更为重要，对于不同的划分标准生成的最大树(Maximum Tree)，在剪枝之后都能够保留最重要的属性划分，差别不大。反而是剪枝方法对于最优树的生成更为关键。 CART分类决策树 GINI指数 CART的分支标准建立在GINI指数这个概念上，GINI指数主要是度量数据划分的不纯度，是介于0~1之间的数。GINI值越小，表明样本集合的纯净度越高；GINI值越大表明样本集合的类别越杂乱
CART分类时，使用基尼指数（Gini）来选择最好的数据分割的特征，gini描述的是纯度，与信息熵的含义相似。CART中每一次迭代都会降低GINI系数。最好的划分就是使得GINI_Gain最小的划分。
停止条件 决策树的构建过程是一个递归的过程，所以需要确定停止条件，否则过程将不会结束。一种最直观的方式是当每个子节点只有一种类型的记录时停止，但是这样往往会使得树的节点过多，导致过拟合问题（Overfitting）。另一种可行的方法是当前节点中的记录数低于一个最小的阀值，那么就停止分割，将max(P(i))对应的分类作为当前叶节点的分类。
过度拟合 采用上面算法生成的决策树在事件中往往会导致过度拟合。也就是该决策树对训练数据可以得到很低的错误率，但是运用到测试数据上却得到非常高的错误率。过渡拟合的原因有以下几点： •噪音数据：训练数据中存在噪音数据，决策树的某些节点有噪音数据作为分割标准，导致决策树无法代表真实数据。 •缺少代表性数据：训练数据没有包含所有具有代表性的数据，导致某一类数据无法很好的匹配，这一点可以通过观察混淆矩阵（Confusion Matrix）分析得出。 •多重比较（Mulitple Comparision）：举个列子，股票分析师预测股票涨或跌。假设分析师都是靠随机猜测，也就是他们正确的概率是0.5。每一个人预测10次，那么预测正确的次数在8次或8次以上的概率为 ，C810∗(0.5)10+C910∗(0.5)10+C1010∗(0.5)10C108∗(0.5)10+C109∗(0.5)10+C1010∗(0.5)10只有5%左右，比较低。但是如果50个分析师，每个人预测10次，选择至少一个人得到8次或以上的人作为代表，那么概率为 1−(1−0....</p></div><footer class=entry-footer><span title='2022-06-07 20:03:36 +0800 +0800'>2022-06-07</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;Reid</footer><a class=entry-link aria-label="post link to 决策树" href=https://reid00.github.io/posts/ml/%E5%86%B3%E7%AD%96%E6%A0%91/></a></article><article class=post-entry><header class=entry-header><h2>逻辑回归</h2></header><div class=entry-content><p>一、线性模型预测一个样本的损失量 损失量：模型对样本的预测结果和该样本对应的实际结果的差距；
1）为什么会想到用 y = -log(x) 函数? （该函数称为 惩罚函数：预测结果与实际值的偏差越大，惩罚越大） y = 1（p ≥ 0.5）时，cost = -log(p)，p 越小，样本发生概率越小（最小为 0），则损失函数越大，分类预测值和实际值的偏差越大；相反，p 越大，样本发生概率越大（最大为 0.5），则损失函数越小，则预测值和实际值的偏差越小； y = 0（p ≤ 0.5）时，cost = -log(1-p)，p 越小，样本发生概率越小（最小为 0.5），则损失函数越大，分类预测值和实际值的偏差越大；相反，p 越大，样本发生概率越大（最大为 1），则损失函数越小，则预测值和实际值的偏差越小； 2）求一个样本的损失量 由于逻辑回归解决的是分类问题，而且是二分类，因此定义损失函数时也要有两类
惩罚函数变形：
惩罚函数作用：计算预测结果针对实际值的损失量；
已知样本发生的概率 p（也可以相应求出预测值），以及该样本的实际分类结果，得出此次预测结果针对真值的损失量是多少； 二、求数据集的损失函数 模型变形，得到数据集的损失函数：数据集中的所有样本的损失值的和； 最终的损失函数模型 该模型不能优化成简单的数学表达式（或者说是正规方程解：线性回归算法找那个的fit_normal() 方法），只能使用梯度下降法求解； 该函数为凸函数，没有局部最优解，只存在全局最优解； 三、逻辑回归损失函数的梯度 损失函数： 1）σ(t) 函数的导数 2）log(σ(t)) 函数的导数 变形：
3）log(1 - σ(t)) 函数的导数 4）对损失函数 J(θ) 的其中某一项（第 i 行，第 j 列）求导 两式相加： 5）损失函数 J(θ) 的梯度 与线性回归梯度对比
注：两者的预测值 ý 不同； 梯度向量化处理 四、代码实现逻辑回归算法 逻辑回归算法是在线性回归算法的基础上演变的；...</p></div><footer class=entry-footer><span title='2022-06-07 20:02:01 +0800 +0800'>2022-06-07</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;Reid</footer><a class=entry-link aria-label="post link to 逻辑回归" href=https://reid00.github.io/posts/ml/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/></a></article><article class=post-entry><header class=entry-header><h2>梯度下降原理介绍</h2></header><div class=entry-content><p>Summary 本文将从一个下山的场景开始，先提出梯度下降算法的基本思想，进而从数学上解释梯度下降算法的原理，最后实现一个简单的梯度下降算法的实例！
梯度下降的场景假设 梯度下降法的基本思想可以类比为一个下山的过程。假设这样一个场景：一个人被困在山上，需要从山上下来(i.e. 找到山的最低点，也就是山谷)。但此时山上的浓雾很大，导致可视度很低。因此，下山的路径就无法确定，他必须利用自己周围的信息去找到下山的路径。这个时候，他就可以利用梯度下降算法来帮助自己下山。具体来说就是，以他当前的所处的位置为基准，寻找这个位置最陡峭的地方，然后朝着山的高度下降的地方走，同理，如果我们的目标是上山，也就是爬到山顶，那么此时应该是朝着最陡峭的方向往上走。然后每走一段距离，都反复采用同一个方法，最后就能成功的抵达山谷。
我们同时可以假设这座山最陡峭的地方是无法通过肉眼立马观察出来的，而是需要一个复杂的工具来测量，同时，这个人此时正好拥有测量出最陡峭方向的能力。所以，此人每走一段距离，都需要一段时间来测量所在位置最陡峭的方向，这是比较耗时的。那么为了在太阳下山之前到达山底，就要尽可能的减少测量方向的次数。这是一个两难的选择，如果测量的频繁，可以保证下山的方向是绝对正确的，但又非常耗时，如果测量的过少，又有偏离轨道的风险。所以需要找到一个合适的测量方向的频率，来确保下山的方向不错误，同时又不至于耗时太多！
梯度下降 首先，我们有一个可微分的函数。这个函数就代表着一座山。我们的目标就是找到这个函数的最小值，也就是山底。根据之前的场景假设，最快的下山的方式就是找到当前位置最陡峭的方向，然后沿着此方向向下走，对应到函数中，就是找到给定点的梯度 ，然后朝着梯度相反的方向，就能让函数值下降的最快！因为梯度的方向就是函数之变化最快的方向(在后面会详细解释) 所以，我们重复利用这个方法，反复求取梯度，最后就能到达局部的最小值，这就类似于我们下山的过程。而求取梯度就确定了最陡峭的方向，也就是场景中测量方向的手段。那么为什么梯度的方向就是最陡峭的方向呢？接下来，我们从微分开始讲起
微分 看待微分的意义，可以有不同的角度，最常用的两种是：
函数图像中，某点的切线的斜率
函数的变化率 几个微分的例子：
上面的例子都是单变量的微分，当一个函数有多个变量的时候，就有了多变量的微分，即分别对每个变量进行求微分
梯度 梯度实际上就是多变量微分的一般化。 下面这个例子：
我们可以看到，梯度就是分别对每个变量进行微分，然后用逗号分割开，梯度是用&lt;>包括起来，说明梯度其实一个向量。
梯度是微积分中一个很重要的概念，之前提到过梯度的意义
在单变量的函数中，梯度其实就是函数的微分，代表着函数在某个给定点的切线的斜率 在多变量函数中，梯度是一个向量，向量有方向，梯度的方向就指出了函数在给定点的上升最快的方向 这也就说明了为什么我们需要千方百计的求取梯度！我们需要到达山底，就需要在每一步观测到此时最陡峭的地方，梯度就恰巧告诉了我们这个方向。梯度的方向是函数在给定点上升最快的方向，那么梯度的反方向就是函数在给定点下降最快的方向，这正是我们所需要的。所以我们只要沿着梯度的方向一直走，就能走到局部的最低点！
梯度下降算法的数学解释 上面我们花了大量的篇幅介绍梯度下降算法的基本思想和场景假设，以及梯度的概念和思想。下面我们就开始从数学上解释梯度下降算法的计算过程和思想！ 此公式的意义是：J是关于Θ的一个函数，我们当前所处的位置为Θ0点，要从这个点走到J的最小值点，也就是山底。首先我们先确定前进的方向，也就是梯度的反向，然后走一段距离的步长，也就是α，走完这个段步长，就到达了Θ1这个点！
下面就这个公式的几个常见的疑问：
α是什么含义？ α在梯度下降算法中被称作为学习率或者步长，意味着我们可以通过α来控制每一步走的距离，以保证不要步子跨的太大扯着蛋，哈哈，其实就是不要走太快，错过了最低点。同时也要保证不要走的太慢，导致太阳下山了，还没有走到山下。所以α的选择在梯度下降法中往往是很重要的！α不能太大也不能太小，太小的话，可能导致迟迟走不到最低点，太大的话，会导致错过最低点！ 为什么要梯度要乘以一个负号？ 梯度前加一个负号，就意味着朝着梯度相反的方向前进！我们在前文提到，梯度的方向实际就是函数在此点上升最快的方向！而我们需要朝着下降最快的方向走，自然就是负的梯度的方向，所以此处需要加上负号
梯度下降算法的实例 我们已经基本了解了梯度下降算法的计算过程，那么我们就来看几个梯度下降算法的小实例，首先从单变量的函数开始
单变量函数的梯度下降 我们假设有一个单变量的函数
函数的微分 初始化，起点为 学习率为 根据梯度下降的计算公式
我们开始进行梯度下降的迭代计算过程：
image.png
如图，经过四次的运算，也就是走了四步，基本就抵达了函数的最低点，也就是山底
多变量函数的梯度下降 我们假设有一个目标函数
现在要通过梯度下降法计算这个函数的最小值。我们通过观察就能发现最小值其实就是 (0，0)点。但是接下来，我们会从梯度下降算法开始一步步计算到这个最小值！ 我们假设初始的起点为：
初始的学习率为：
函数的梯度为：
进行多次迭代：
我们发现，已经基本靠近函数的最小值点
梯度下降算法的实现 下面我们将用python实现一个简单的梯度下降算法。场景是一个简单的线性回归的例子：假设现在我们有一系列的点，如下图所示
我们将用梯度下降法来拟合出这条直线！
首先，我们需要定义一个代价函数，在此我们选用均方误差代价函数
此公式中
m是数据集中点的个数
½是一个常量，这样是为了在求梯度的时候，二次方乘下来就和这里的½抵消了，自然就没有多余的常数系数，方便后续的计算，同时对结果不会有影响
y 是数据集中每个点的真实y坐标的值
h 是我们的预测函数，根据每一个输入x，根据Θ 计算得到预测的y值，即
我们可以根据代价函数看到，代价函数中的变量有两个，所以是一个多变量的梯度下降问题，求解出代价函数的梯度，也就是分别对两个变量进行微分
明确了代价函数和梯度，以及预测的函数形式。我们就可以开始编写代码了。但在这之前，需要说明一点，就是为了方便代码的编写，我们会将所有的公式都转换为矩阵的形式，python中计算矩阵是非常方便的，同时代码也会变得非常的简洁。
为了转换为矩阵的计算，我们观察到预测函数的形式
我们有两个变量，为了对这个公式进行矩阵化，我们可以给每一个点x增加一维，这一维的值固定为1，这一维将会乘到Θ0上。这样就方便我们统一矩阵化的计算
然后我们将代价函数和梯度转化为矩阵向量相乘的形式
coding time 首先，我们需要定义数据集和学习率...</p></div><footer class=entry-footer><span title='2022-06-07 19:53:26 +0800 +0800'>2022-06-07</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;Reid</footer><a class=entry-link aria-label="post link to 梯度下降原理介绍" href=https://reid00.github.io/posts/ml/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E5%8E%9F%E7%90%86%E4%BB%8B%E7%BB%8D/></a></article><article class=post-entry><header class=entry-header><h2>线性回归</h2></header><div class=entry-content><p>称函数为效用函数 线性回归模型看起来非常简单，简单到让人怀疑其是否有研究价值以及使用价值。但实际上，线性回归模型可以说是最重要的数学模型之一，很多模型都是建立在它的基础之上，可以被称为是“模型之母”。
1.1 什么是简单线性回归 所谓简单，是指只有一个样本特征，即只有一个自变量；所谓线性，是指方程是线性的；所谓回归，是指用方程来模拟变量之间是如何关联的。
简单线性回归，其思想简单，实现容易（与其背后强大的数学性质相关。同时也是许多强大的非线性模型（多项式回归、逻辑回归、SVM）的基础。并且其结果具有很好的可解释性。
1.2 一种基本推导思 我们所谓的建模过程，其实就是找到一个模型，最大程度的拟合我们的数据。 在简单线回归问题中，模型就是我们的直线方程：y = ax + b 。
要想最大的拟合数据，本质上就是找到没有拟合的部分，也就是损失的部分尽量小，就是损失函数（loss function）（也有算法是衡量拟合的程度，称函数为效用函数（utility function））：
因此，推导思路为：
通过分析问题，确定问题的损失函数或者效用函数； 然后通过最优化损失函数或者效用函数，获得机器学习的模型 近乎所有参数学习算法都是这样的套路，区别是模型不同，建立的目标函数不同，优化的方式也不同。
回到简单线性回归问题，目标：
已知训练数据样本、 ，找到和的值，使 尽可能小
这是一个典型的最小二乘法问题（最小化误差的平方）
通过最小二乘法可以求出a、b的表达式：
最小二乘法 2.1 由损失函数引出一堆“风险” 2.1.1 损失函数 在机器学习中，所有的算法模型其实都依赖于最小化或最大化某一个函数，我们称之为“目标函数”。
最小化的这组函数被称为“损失函数”。什么是损失函数呢？
损失函数描述了单个样本预测值和真实值之间误差的程度。用来度量模型一次预测的好坏。
损失函数是衡量预测模型预测期望结果表现的指标。损失函数越小，模型的鲁棒性越好。。
常用损失函数有：
0-1损失函数：用来表述分类问题，当预测分类错误时，损失函数值为1，正确为 平方损失函数：用来描述回归问题，用来表示连续性变量，为预测值与真实值差值的平方。（误差值越大、惩罚力度越强，也就是对差值敏感）
绝对损失函数：用在回归模型，用距离的绝对值来衡量 对数损失函数：是预测值Y和条件概率之间的衡量。事实上，该损失函数用到了极大似然估计的思想。P(Y|X)通俗的解释就是：在当前模型的基础上，对于样本X，其预测值为Y，也就是预测正确的概率。由于概率之间的同时满足需要使用乘法，为了将其转化为加法，我们将其取对数。最后由于是损失函数，所以预测正确的概率越高，其损失值应该是越小，因此再加个负号取个反。 以上损失函数是针对于单个样本的，但是一个训练数据集中存在N个样本，N个样本给出N个损失，如何进行选择呢？
这就引出了风险函数。
2.1.2 期望风险 期望风险是损失函数的期望，用来表达理论上模型f(X)关于联合分布P(X,Y)的平均意义下的损失。又叫期望损失/风险函数。
2.1.3 经验风险 模型f(X)关于训练数据集的平均损失，称为经验风险或经验损失。
其公式含义为：模型关于训练集的平均损失（每个样本的损失加起来，然后平均一下）
经验风险最小的模型为最优模型。在训练集上最小经验风险最小，也就意味着预测值和真实值尽可能接近，模型的效果越好。公式含义为取训练样本集中对数损失函数平均值的最小。
2.1.4 经验风险最小化和结构风险最小化 期望风险是模型关于联合分布的期望损失，经验风险是模型关于训练样本数据集的平均损失。根据大数定律，当样本容量N趋于无穷时，经验风险趋于期望风险。
因此很自然地想到用经验风险去估计期望风险。但是由于训练样本个数有限，可能会出现过度拟合的问题，即决策函数对于训练集几乎全部拟合，但是对于测试集拟合效果过差。因此需要对其进行矫正：
结构风险最小化：当样本容量不大的时候，经验风险最小化容易产生“过拟合”的问题，为了“减缓”过拟合问题，提出了结构风险最小理论。结构风险最小化为经验风险与复杂度同时较小。 通过公式可以看出，结构风险：在经验风险上加上一个正则化项(regularizer)，或者叫做罚项(penalty) 。正则化项是J(f)是函数的复杂度再乘一个权重系数（用以权衡经验风险和复杂度）
2.1.5 小结 1、损失函数：单个样本预测值和真实值之间误差的程度。
2、期望风险：是损失函数的期望，理论上模型f(X)关于联合分布P(X,Y)的平均意义下的损失。
3、经验风险：模型关于训练集的平均损失（每个样本的损失加起来，然后平均一下）。
4、结构风险：在经验风险上加上一个正则化项，防止过拟合的策略。
2.2 最小二乘法 2.2.1 什么是最小二乘法 言归正传，进入最小二乘法的部分。...</p></div><footer class=entry-footer><span title='2022-06-07 19:48:37 +0800 +0800'>2022-06-07</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;Reid</footer><a class=entry-link aria-label="post link to 线性回归" href=https://reid00.github.io/posts/ml/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/></a></article><footer class=page-footer><nav class=pagination><a class=prev href=https://reid00.github.io/posts/page/6/>« Prev</a>
<a class=next href=https://reid00.github.io/posts/page/8/>Next »</a></nav></footer></main><footer class=footer><span>&copy; 2023 <a href=https://reid00.github.io/>Reid's Blog</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>