<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>UDP就一定比TCP快吗 | Reid's Blog</title><meta name=keywords content="TCP,UDP"><meta name=description content="话说，UDP比TCP快吗？
相信就算不是八股文老手，也会下意识的脱口而出：&ldquo;是&rdquo;。
这要追问为什么，估计大家也能说出个大概。
但这也让人好奇，用UDP就一定比用TCP快吗？什么情况下用UDP会比用TCP慢？
我们今天就来聊下这个话题。
使用socket进行数据传输 作为一个程序员，假设我们需要在A电脑的进程发一段数据到B电脑的进程，我们一般会在代码里使用socket进行编程。
socket就像是一个电话或者邮箱（邮政的信箱）。当你想要发送消息的时候，拨通电话或者将信息塞到邮箱里，socket内核会自动完成将数据传给对方的这个过程。
基于socket我们可以选择使用TCP或UDP协议进行通信。
对于TCP这样的可靠性协议，每次消息发出后都能明确知道对方收没收到，就像打电话一样，只要&#34;喂喂&#34;两下就能知道对方有没有在听。
而UDP就像是给邮政的信箱寄信一样，你寄出去的信，根本就不知道对方有没有正常收到，丢了也是有可能的。
这让我想起了大概17年前，当时还没有现在这么发达的网购，想买一本《掌机迷》杂志，还得往信封里塞钱，然后一等就是一个月，好几次都怀疑信是不是丢了。我至今印象深刻，因为那是我和我哥攒了好久的钱。。。
回到socket编程的话题上。
创建socket的方式就像下面这样。
1 fd = socket(AF_INET, 具体协议,0); 注意上面的&#34;具体协议&#34;，如果传入的是SOCK_STREAM，是指使用字节流传输数据，说白了就是TCP协议。 TCP: 面向连接的 可靠的 基于字节流 如果传入的是SOCK_DGRAM，是指使用数据报传输数据，也就是UDP协议。 UDP: 无连接 不可靠 基于消息报
返回的fd是指socket句柄，可以理解为socket的身份证号。通过这个fd你可以在内核中找到唯一的socket结构。
如果想要通过这个socket发消息，只需要操作这个fd就行了，比如执行 send(fd, msg, &mldr;)，内核就会通过这个fd句柄找到socket然后进行发数据的操作。
如果一切顺利，此时对方执行接收消息的操作，也就是 recv(fd, msg, &mldr;)，就能拿到你发的消息。 对于异常情况的处理 但如果不顺利呢？
比如消息发到一半，丢包了呢?
那UDP和TCP的态度就不太一样了。
UDP表示，&ldquo;哦，是吗？然后呢？关我x事&rdquo;
TCP态度就截然相反了，&ldquo;啊？那可不行，是不是我发太快了呢？是不是链路太堵被别人影响到了呢？不过你放心，我肯定给你补发&rdquo;
TCP老实人石锤了。我们来看下这个老实人在背后都默默做了哪些事情。
重传机制 对于TCP，它会给发出的消息打上一个编号（sequence），接收方收到后回一个确认(ack)。发送方可以通过ack的数值知道接收方收到了哪些sequence的包。
如果长时间等不到对方的确认，TCP就会重新发一次消息，这就是所谓的重传机制。 流量控制机制 但重传这件事本身对性能影响是比较严重的，所以是下下策。
于是TCP就需要思考有没有办法可以尽量避免重传。
因为数据发送方和接收方处理数据能力可能不同，因此如果可以根据双方的能力去调整发送的数据量就好了，于是就有了发送和接收窗口，基本上从名字就能看出它的作用，比如接收窗口的大小就是指，接收方当前能接收的数据量大小，发送窗口的大小就指发送方当前能发的数据量大小。TCP根据窗口的大小去控制自己发送的数据量，这样就能大大减少丢包的概率。 滑动窗口机制 接收方的接收到数据之后，会不断处理，处理能力也不是一成不变的，有时候处理的快些，那就可以收多点数据，处理的慢点那就希望对方能少发点数据。毕竟发多了就有可能处理不过来导致丢包，丢包会导致重传，这可是下下策。因此我们需要动态的去调节这个接收窗口的大小，于是就有了滑动窗口机制。
看到这里大家可能就有点迷了，流量控制和滑动窗口机制貌似很像，它们之间是啥关系？我总结一下。其实现在TCP是通过滑动窗口机制来实现流量控制机制的。 拥塞控制机制 但这还不够，有时候发生丢包，并不是因为发送方和接收方的处理能力问题导致的。而是跟网络环境有关，大家可以将网络想象为一条公路。马路上可能堵满了别人家的车，只留下一辆车的空间。那就算你家有5辆车，目的地也正好有5个停车位，你也没办法同时全部一起上路。于是TCP希望能感知到外部的网络环境，根据网络环境及时调整自己的发包数量，比如马路只够两辆车跑，那我就只发两辆车。但外部环境这么复杂，TCP是怎么感知到的呢？
TCP会先慢慢试探的发数据，不断加码数据量，越发越多，先发一个，再发2个，4个…。直到出现丢包，这样TCP就知道现在当前网络大概吃得消几个包了，这既是所谓的拥塞控制机制。
不少人会疑惑流量控制和拥塞控制的关系。我这里小小的总结下。流量控制针对的是单个连接数据处理能力的控制，拥塞控制针对的是整个网络环境数据处理能力的控制。
分段机制 但上面提到的都是怎么降低重传的概率，似乎重传这个事情就是无法避免的，那如果确实发生了，有没有办法降低它带来的影响呢？
有。当我们需要发送一个超大的数据包时，如果这个数据包丢了，那就得重传同样大的数据包。但如果我能将其分成一小段一小段，那就算真丢了，那我也就只需要重传那一小段就好了，大大减小了重传的压力，这就是TCP的分段机制。
而这个所谓的一小段的长度，在传输层叫MSS（Maximum Segment Size），数据包长度大于MSS则会分成N个小于等于MSS的包。 而在网络层，如果数据包还大于MTU（Maximum Transmit Unit），那还会继续分包。 一般情况下，MSS=MTU-40Byte，所以TCP分段后，到了IP层大概率就不会再分片了。 乱序重排机制 既然数据包会被分段，链路又这么复杂还会丢包，那数据包乱序也就显得不奇怪了。比如发数据包1,2,3。1号数据包走了其他网络路径，2和3数据包先到，1数据包后到，于是数据包顺序就成了2,3,1。这一点TCP也考虑到了，依靠数据包的sequence，接收方就能知道数据包的先后顺序。"><meta name=author content="Reid"><link rel=canonical href=https://reid00.github.io/posts/udp%E5%B0%B1%E4%B8%80%E5%AE%9A%E6%AF%94tcp%E5%BF%AB%E5%90%97/><link crossorigin=anonymous href=/assets/css/stylesheet.d7fb4cbf980fe688a21621b06a795933c4e6bb2d4070ec940667af1715d84af2.css integrity="sha256-1/tMv5gP5oiiFiGwanlZM8Tmuy1AcOyUBmevFxXYSvI=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://reid00.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://reid00.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://reid00.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://reid00.github.io/apple-touch-icon.png><link rel=mask-icon href=https://reid00.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-QRR6GRNQGK"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-QRR6GRNQGK",{anonymize_ip:!1})}</script><meta property="og:title" content="UDP就一定比TCP快吗"><meta property="og:description" content="话说，UDP比TCP快吗？
相信就算不是八股文老手，也会下意识的脱口而出：&ldquo;是&rdquo;。
这要追问为什么，估计大家也能说出个大概。
但这也让人好奇，用UDP就一定比用TCP快吗？什么情况下用UDP会比用TCP慢？
我们今天就来聊下这个话题。
使用socket进行数据传输 作为一个程序员，假设我们需要在A电脑的进程发一段数据到B电脑的进程，我们一般会在代码里使用socket进行编程。
socket就像是一个电话或者邮箱（邮政的信箱）。当你想要发送消息的时候，拨通电话或者将信息塞到邮箱里，socket内核会自动完成将数据传给对方的这个过程。
基于socket我们可以选择使用TCP或UDP协议进行通信。
对于TCP这样的可靠性协议，每次消息发出后都能明确知道对方收没收到，就像打电话一样，只要&#34;喂喂&#34;两下就能知道对方有没有在听。
而UDP就像是给邮政的信箱寄信一样，你寄出去的信，根本就不知道对方有没有正常收到，丢了也是有可能的。
这让我想起了大概17年前，当时还没有现在这么发达的网购，想买一本《掌机迷》杂志，还得往信封里塞钱，然后一等就是一个月，好几次都怀疑信是不是丢了。我至今印象深刻，因为那是我和我哥攒了好久的钱。。。
回到socket编程的话题上。
创建socket的方式就像下面这样。
1 fd = socket(AF_INET, 具体协议,0); 注意上面的&#34;具体协议&#34;，如果传入的是SOCK_STREAM，是指使用字节流传输数据，说白了就是TCP协议。 TCP: 面向连接的 可靠的 基于字节流 如果传入的是SOCK_DGRAM，是指使用数据报传输数据，也就是UDP协议。 UDP: 无连接 不可靠 基于消息报
返回的fd是指socket句柄，可以理解为socket的身份证号。通过这个fd你可以在内核中找到唯一的socket结构。
如果想要通过这个socket发消息，只需要操作这个fd就行了，比如执行 send(fd, msg, &mldr;)，内核就会通过这个fd句柄找到socket然后进行发数据的操作。
如果一切顺利，此时对方执行接收消息的操作，也就是 recv(fd, msg, &mldr;)，就能拿到你发的消息。 对于异常情况的处理 但如果不顺利呢？
比如消息发到一半，丢包了呢?
那UDP和TCP的态度就不太一样了。
UDP表示，&ldquo;哦，是吗？然后呢？关我x事&rdquo;
TCP态度就截然相反了，&ldquo;啊？那可不行，是不是我发太快了呢？是不是链路太堵被别人影响到了呢？不过你放心，我肯定给你补发&rdquo;
TCP老实人石锤了。我们来看下这个老实人在背后都默默做了哪些事情。
重传机制 对于TCP，它会给发出的消息打上一个编号（sequence），接收方收到后回一个确认(ack)。发送方可以通过ack的数值知道接收方收到了哪些sequence的包。
如果长时间等不到对方的确认，TCP就会重新发一次消息，这就是所谓的重传机制。 流量控制机制 但重传这件事本身对性能影响是比较严重的，所以是下下策。
于是TCP就需要思考有没有办法可以尽量避免重传。
因为数据发送方和接收方处理数据能力可能不同，因此如果可以根据双方的能力去调整发送的数据量就好了，于是就有了发送和接收窗口，基本上从名字就能看出它的作用，比如接收窗口的大小就是指，接收方当前能接收的数据量大小，发送窗口的大小就指发送方当前能发的数据量大小。TCP根据窗口的大小去控制自己发送的数据量，这样就能大大减少丢包的概率。 滑动窗口机制 接收方的接收到数据之后，会不断处理，处理能力也不是一成不变的，有时候处理的快些，那就可以收多点数据，处理的慢点那就希望对方能少发点数据。毕竟发多了就有可能处理不过来导致丢包，丢包会导致重传，这可是下下策。因此我们需要动态的去调节这个接收窗口的大小，于是就有了滑动窗口机制。
看到这里大家可能就有点迷了，流量控制和滑动窗口机制貌似很像，它们之间是啥关系？我总结一下。其实现在TCP是通过滑动窗口机制来实现流量控制机制的。 拥塞控制机制 但这还不够，有时候发生丢包，并不是因为发送方和接收方的处理能力问题导致的。而是跟网络环境有关，大家可以将网络想象为一条公路。马路上可能堵满了别人家的车，只留下一辆车的空间。那就算你家有5辆车，目的地也正好有5个停车位，你也没办法同时全部一起上路。于是TCP希望能感知到外部的网络环境，根据网络环境及时调整自己的发包数量，比如马路只够两辆车跑，那我就只发两辆车。但外部环境这么复杂，TCP是怎么感知到的呢？
TCP会先慢慢试探的发数据，不断加码数据量，越发越多，先发一个，再发2个，4个…。直到出现丢包，这样TCP就知道现在当前网络大概吃得消几个包了，这既是所谓的拥塞控制机制。
不少人会疑惑流量控制和拥塞控制的关系。我这里小小的总结下。流量控制针对的是单个连接数据处理能力的控制，拥塞控制针对的是整个网络环境数据处理能力的控制。
分段机制 但上面提到的都是怎么降低重传的概率，似乎重传这个事情就是无法避免的，那如果确实发生了，有没有办法降低它带来的影响呢？
有。当我们需要发送一个超大的数据包时，如果这个数据包丢了，那就得重传同样大的数据包。但如果我能将其分成一小段一小段，那就算真丢了，那我也就只需要重传那一小段就好了，大大减小了重传的压力，这就是TCP的分段机制。
而这个所谓的一小段的长度，在传输层叫MSS（Maximum Segment Size），数据包长度大于MSS则会分成N个小于等于MSS的包。 而在网络层，如果数据包还大于MTU（Maximum Transmit Unit），那还会继续分包。 一般情况下，MSS=MTU-40Byte，所以TCP分段后，到了IP层大概率就不会再分片了。 乱序重排机制 既然数据包会被分段，链路又这么复杂还会丢包，那数据包乱序也就显得不奇怪了。比如发数据包1,2,3。1号数据包走了其他网络路径，2和3数据包先到，1数据包后到，于是数据包顺序就成了2,3,1。这一点TCP也考虑到了，依靠数据包的sequence，接收方就能知道数据包的先后顺序。"><meta property="og:type" content="article"><meta property="og:url" content="https://reid00.github.io/posts/udp%E5%B0%B1%E4%B8%80%E5%AE%9A%E6%AF%94tcp%E5%BF%AB%E5%90%97/"><meta property="og:image" content="https://i.loli.net/2021/09/26/3OMGXylm8HUYJ6p.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-10-26T11:11:30+08:00"><meta property="article:modified_time" content="2022-10-26T11:11:30+08:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://i.loli.net/2021/09/26/3OMGXylm8HUYJ6p.png"><meta name=twitter:title content="UDP就一定比TCP快吗"><meta name=twitter:description content="话说，UDP比TCP快吗？
相信就算不是八股文老手，也会下意识的脱口而出：&ldquo;是&rdquo;。
这要追问为什么，估计大家也能说出个大概。
但这也让人好奇，用UDP就一定比用TCP快吗？什么情况下用UDP会比用TCP慢？
我们今天就来聊下这个话题。
使用socket进行数据传输 作为一个程序员，假设我们需要在A电脑的进程发一段数据到B电脑的进程，我们一般会在代码里使用socket进行编程。
socket就像是一个电话或者邮箱（邮政的信箱）。当你想要发送消息的时候，拨通电话或者将信息塞到邮箱里，socket内核会自动完成将数据传给对方的这个过程。
基于socket我们可以选择使用TCP或UDP协议进行通信。
对于TCP这样的可靠性协议，每次消息发出后都能明确知道对方收没收到，就像打电话一样，只要&#34;喂喂&#34;两下就能知道对方有没有在听。
而UDP就像是给邮政的信箱寄信一样，你寄出去的信，根本就不知道对方有没有正常收到，丢了也是有可能的。
这让我想起了大概17年前，当时还没有现在这么发达的网购，想买一本《掌机迷》杂志，还得往信封里塞钱，然后一等就是一个月，好几次都怀疑信是不是丢了。我至今印象深刻，因为那是我和我哥攒了好久的钱。。。
回到socket编程的话题上。
创建socket的方式就像下面这样。
1 fd = socket(AF_INET, 具体协议,0); 注意上面的&#34;具体协议&#34;，如果传入的是SOCK_STREAM，是指使用字节流传输数据，说白了就是TCP协议。 TCP: 面向连接的 可靠的 基于字节流 如果传入的是SOCK_DGRAM，是指使用数据报传输数据，也就是UDP协议。 UDP: 无连接 不可靠 基于消息报
返回的fd是指socket句柄，可以理解为socket的身份证号。通过这个fd你可以在内核中找到唯一的socket结构。
如果想要通过这个socket发消息，只需要操作这个fd就行了，比如执行 send(fd, msg, &mldr;)，内核就会通过这个fd句柄找到socket然后进行发数据的操作。
如果一切顺利，此时对方执行接收消息的操作，也就是 recv(fd, msg, &mldr;)，就能拿到你发的消息。 对于异常情况的处理 但如果不顺利呢？
比如消息发到一半，丢包了呢?
那UDP和TCP的态度就不太一样了。
UDP表示，&ldquo;哦，是吗？然后呢？关我x事&rdquo;
TCP态度就截然相反了，&ldquo;啊？那可不行，是不是我发太快了呢？是不是链路太堵被别人影响到了呢？不过你放心，我肯定给你补发&rdquo;
TCP老实人石锤了。我们来看下这个老实人在背后都默默做了哪些事情。
重传机制 对于TCP，它会给发出的消息打上一个编号（sequence），接收方收到后回一个确认(ack)。发送方可以通过ack的数值知道接收方收到了哪些sequence的包。
如果长时间等不到对方的确认，TCP就会重新发一次消息，这就是所谓的重传机制。 流量控制机制 但重传这件事本身对性能影响是比较严重的，所以是下下策。
于是TCP就需要思考有没有办法可以尽量避免重传。
因为数据发送方和接收方处理数据能力可能不同，因此如果可以根据双方的能力去调整发送的数据量就好了，于是就有了发送和接收窗口，基本上从名字就能看出它的作用，比如接收窗口的大小就是指，接收方当前能接收的数据量大小，发送窗口的大小就指发送方当前能发的数据量大小。TCP根据窗口的大小去控制自己发送的数据量，这样就能大大减少丢包的概率。 滑动窗口机制 接收方的接收到数据之后，会不断处理，处理能力也不是一成不变的，有时候处理的快些，那就可以收多点数据，处理的慢点那就希望对方能少发点数据。毕竟发多了就有可能处理不过来导致丢包，丢包会导致重传，这可是下下策。因此我们需要动态的去调节这个接收窗口的大小，于是就有了滑动窗口机制。
看到这里大家可能就有点迷了，流量控制和滑动窗口机制貌似很像，它们之间是啥关系？我总结一下。其实现在TCP是通过滑动窗口机制来实现流量控制机制的。 拥塞控制机制 但这还不够，有时候发生丢包，并不是因为发送方和接收方的处理能力问题导致的。而是跟网络环境有关，大家可以将网络想象为一条公路。马路上可能堵满了别人家的车，只留下一辆车的空间。那就算你家有5辆车，目的地也正好有5个停车位，你也没办法同时全部一起上路。于是TCP希望能感知到外部的网络环境，根据网络环境及时调整自己的发包数量，比如马路只够两辆车跑，那我就只发两辆车。但外部环境这么复杂，TCP是怎么感知到的呢？
TCP会先慢慢试探的发数据，不断加码数据量，越发越多，先发一个，再发2个，4个…。直到出现丢包，这样TCP就知道现在当前网络大概吃得消几个包了，这既是所谓的拥塞控制机制。
不少人会疑惑流量控制和拥塞控制的关系。我这里小小的总结下。流量控制针对的是单个连接数据处理能力的控制，拥塞控制针对的是整个网络环境数据处理能力的控制。
分段机制 但上面提到的都是怎么降低重传的概率，似乎重传这个事情就是无法避免的，那如果确实发生了，有没有办法降低它带来的影响呢？
有。当我们需要发送一个超大的数据包时，如果这个数据包丢了，那就得重传同样大的数据包。但如果我能将其分成一小段一小段，那就算真丢了，那我也就只需要重传那一小段就好了，大大减小了重传的压力，这就是TCP的分段机制。
而这个所谓的一小段的长度，在传输层叫MSS（Maximum Segment Size），数据包长度大于MSS则会分成N个小于等于MSS的包。 而在网络层，如果数据包还大于MTU（Maximum Transmit Unit），那还会继续分包。 一般情况下，MSS=MTU-40Byte，所以TCP分段后，到了IP层大概率就不会再分片了。 乱序重排机制 既然数据包会被分段，链路又这么复杂还会丢包，那数据包乱序也就显得不奇怪了。比如发数据包1,2,3。1号数据包走了其他网络路径，2和3数据包先到，1数据包后到，于是数据包顺序就成了2,3,1。这一点TCP也考虑到了，依靠数据包的sequence，接收方就能知道数据包的先后顺序。"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://reid00.github.io/posts/"},{"@type":"ListItem","position":2,"name":"UDP就一定比TCP快吗","item":"https://reid00.github.io/posts/udp%E5%B0%B1%E4%B8%80%E5%AE%9A%E6%AF%94tcp%E5%BF%AB%E5%90%97/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"UDP就一定比TCP快吗","name":"UDP就一定比TCP快吗","description":"话说，UDP比TCP快吗？\n相信就算不是八股文老手，也会下意识的脱口而出：\u0026ldquo;是\u0026rdquo;。\n这要追问为什么，估计大家也能说出个大概。\n但这也让人好奇，用UDP就一定比用TCP快吗？什么情况下用UDP会比用TCP慢？\n我们今天就来聊下这个话题。\n使用socket进行数据传输 作为一个程序员，假设我们需要在A电脑的进程发一段数据到B电脑的进程，我们一般会在代码里使用socket进行编程。\nsocket就像是一个电话或者邮箱（邮政的信箱）。当你想要发送消息的时候，拨通电话或者将信息塞到邮箱里，socket内核会自动完成将数据传给对方的这个过程。\n基于socket我们可以选择使用TCP或UDP协议进行通信。\n对于TCP这样的可靠性协议，每次消息发出后都能明确知道对方收没收到，就像打电话一样，只要\u0026quot;喂喂\u0026quot;两下就能知道对方有没有在听。\n而UDP就像是给邮政的信箱寄信一样，你寄出去的信，根本就不知道对方有没有正常收到，丢了也是有可能的。\n这让我想起了大概17年前，当时还没有现在这么发达的网购，想买一本《掌机迷》杂志，还得往信封里塞钱，然后一等就是一个月，好几次都怀疑信是不是丢了。我至今印象深刻，因为那是我和我哥攒了好久的钱。。。\n回到socket编程的话题上。\n创建socket的方式就像下面这样。\n1 fd = socket(AF_INET, 具体协议,0); 注意上面的\u0026quot;具体协议\u0026quot;，如果传入的是SOCK_STREAM，是指使用字节流传输数据，说白了就是TCP协议。 TCP: 面向连接的 可靠的 基于字节流 如果传入的是SOCK_DGRAM，是指使用数据报传输数据，也就是UDP协议。 UDP: 无连接 不可靠 基于消息报\n返回的fd是指socket句柄，可以理解为socket的身份证号。通过这个fd你可以在内核中找到唯一的socket结构。\n如果想要通过这个socket发消息，只需要操作这个fd就行了，比如执行 send(fd, msg, \u0026hellip;)，内核就会通过这个fd句柄找到socket然后进行发数据的操作。\n如果一切顺利，此时对方执行接收消息的操作，也就是 recv(fd, msg, \u0026hellip;)，就能拿到你发的消息。 对于异常情况的处理 但如果不顺利呢？\n比如消息发到一半，丢包了呢?\n那UDP和TCP的态度就不太一样了。\nUDP表示，\u0026ldquo;哦，是吗？然后呢？关我x事\u0026rdquo;\nTCP态度就截然相反了，\u0026ldquo;啊？那可不行，是不是我发太快了呢？是不是链路太堵被别人影响到了呢？不过你放心，我肯定给你补发\u0026rdquo;\nTCP老实人石锤了。我们来看下这个老实人在背后都默默做了哪些事情。\n重传机制 对于TCP，它会给发出的消息打上一个编号（sequence），接收方收到后回一个确认(ack)。发送方可以通过ack的数值知道接收方收到了哪些sequence的包。\n如果长时间等不到对方的确认，TCP就会重新发一次消息，这就是所谓的重传机制。 流量控制机制 但重传这件事本身对性能影响是比较严重的，所以是下下策。\n于是TCP就需要思考有没有办法可以尽量避免重传。\n因为数据发送方和接收方处理数据能力可能不同，因此如果可以根据双方的能力去调整发送的数据量就好了，于是就有了发送和接收窗口，基本上从名字就能看出它的作用，比如接收窗口的大小就是指，接收方当前能接收的数据量大小，发送窗口的大小就指发送方当前能发的数据量大小。TCP根据窗口的大小去控制自己发送的数据量，这样就能大大减少丢包的概率。 滑动窗口机制 接收方的接收到数据之后，会不断处理，处理能力也不是一成不变的，有时候处理的快些，那就可以收多点数据，处理的慢点那就希望对方能少发点数据。毕竟发多了就有可能处理不过来导致丢包，丢包会导致重传，这可是下下策。因此我们需要动态的去调节这个接收窗口的大小，于是就有了滑动窗口机制。\n看到这里大家可能就有点迷了，流量控制和滑动窗口机制貌似很像，它们之间是啥关系？我总结一下。其实现在TCP是通过滑动窗口机制来实现流量控制机制的。 拥塞控制机制 但这还不够，有时候发生丢包，并不是因为发送方和接收方的处理能力问题导致的。而是跟网络环境有关，大家可以将网络想象为一条公路。马路上可能堵满了别人家的车，只留下一辆车的空间。那就算你家有5辆车，目的地也正好有5个停车位，你也没办法同时全部一起上路。于是TCP希望能感知到外部的网络环境，根据网络环境及时调整自己的发包数量，比如马路只够两辆车跑，那我就只发两辆车。但外部环境这么复杂，TCP是怎么感知到的呢？\nTCP会先慢慢试探的发数据，不断加码数据量，越发越多，先发一个，再发2个，4个…。直到出现丢包，这样TCP就知道现在当前网络大概吃得消几个包了，这既是所谓的拥塞控制机制。\n不少人会疑惑流量控制和拥塞控制的关系。我这里小小的总结下。流量控制针对的是单个连接数据处理能力的控制，拥塞控制针对的是整个网络环境数据处理能力的控制。\n分段机制 但上面提到的都是怎么降低重传的概率，似乎重传这个事情就是无法避免的，那如果确实发生了，有没有办法降低它带来的影响呢？\n有。当我们需要发送一个超大的数据包时，如果这个数据包丢了，那就得重传同样大的数据包。但如果我能将其分成一小段一小段，那就算真丢了，那我也就只需要重传那一小段就好了，大大减小了重传的压力，这就是TCP的分段机制。\n而这个所谓的一小段的长度，在传输层叫MSS（Maximum Segment Size），数据包长度大于MSS则会分成N个小于等于MSS的包。 而在网络层，如果数据包还大于MTU（Maximum Transmit Unit），那还会继续分包。 一般情况下，MSS=MTU-40Byte，所以TCP分段后，到了IP层大概率就不会再分片了。 乱序重排机制 既然数据包会被分段，链路又这么复杂还会丢包，那数据包乱序也就显得不奇怪了。比如发数据包1,2,3。1号数据包走了其他网络路径，2和3数据包先到，1数据包后到，于是数据包顺序就成了2,3,1。这一点TCP也考虑到了，依靠数据包的sequence，接收方就能知道数据包的先后顺序。","keywords":["TCP","UDP"],"articleBody":"话说，UDP比TCP快吗？\n相信就算不是八股文老手，也会下意识的脱口而出：“是”。\n这要追问为什么，估计大家也能说出个大概。\n但这也让人好奇，用UDP就一定比用TCP快吗？什么情况下用UDP会比用TCP慢？\n我们今天就来聊下这个话题。\n使用socket进行数据传输 作为一个程序员，假设我们需要在A电脑的进程发一段数据到B电脑的进程，我们一般会在代码里使用socket进行编程。\nsocket就像是一个电话或者邮箱（邮政的信箱）。当你想要发送消息的时候，拨通电话或者将信息塞到邮箱里，socket内核会自动完成将数据传给对方的这个过程。\n基于socket我们可以选择使用TCP或UDP协议进行通信。\n对于TCP这样的可靠性协议，每次消息发出后都能明确知道对方收没收到，就像打电话一样，只要\"喂喂\"两下就能知道对方有没有在听。\n而UDP就像是给邮政的信箱寄信一样，你寄出去的信，根本就不知道对方有没有正常收到，丢了也是有可能的。\n这让我想起了大概17年前，当时还没有现在这么发达的网购，想买一本《掌机迷》杂志，还得往信封里塞钱，然后一等就是一个月，好几次都怀疑信是不是丢了。我至今印象深刻，因为那是我和我哥攒了好久的钱。。。\n回到socket编程的话题上。\n创建socket的方式就像下面这样。\n1 fd = socket(AF_INET, 具体协议,0); 注意上面的\"具体协议\"，如果传入的是SOCK_STREAM，是指使用字节流传输数据，说白了就是TCP协议。 TCP: 面向连接的 可靠的 基于字节流 如果传入的是SOCK_DGRAM，是指使用数据报传输数据，也就是UDP协议。 UDP: 无连接 不可靠 基于消息报\n返回的fd是指socket句柄，可以理解为socket的身份证号。通过这个fd你可以在内核中找到唯一的socket结构。\n如果想要通过这个socket发消息，只需要操作这个fd就行了，比如执行 send(fd, msg, …)，内核就会通过这个fd句柄找到socket然后进行发数据的操作。\n如果一切顺利，此时对方执行接收消息的操作，也就是 recv(fd, msg, …)，就能拿到你发的消息。 对于异常情况的处理 但如果不顺利呢？\n比如消息发到一半，丢包了呢?\n那UDP和TCP的态度就不太一样了。\nUDP表示，“哦，是吗？然后呢？关我x事”\nTCP态度就截然相反了，“啊？那可不行，是不是我发太快了呢？是不是链路太堵被别人影响到了呢？不过你放心，我肯定给你补发”\nTCP老实人石锤了。我们来看下这个老实人在背后都默默做了哪些事情。\n重传机制 对于TCP，它会给发出的消息打上一个编号（sequence），接收方收到后回一个确认(ack)。发送方可以通过ack的数值知道接收方收到了哪些sequence的包。\n如果长时间等不到对方的确认，TCP就会重新发一次消息，这就是所谓的重传机制。 流量控制机制 但重传这件事本身对性能影响是比较严重的，所以是下下策。\n于是TCP就需要思考有没有办法可以尽量避免重传。\n因为数据发送方和接收方处理数据能力可能不同，因此如果可以根据双方的能力去调整发送的数据量就好了，于是就有了发送和接收窗口，基本上从名字就能看出它的作用，比如接收窗口的大小就是指，接收方当前能接收的数据量大小，发送窗口的大小就指发送方当前能发的数据量大小。TCP根据窗口的大小去控制自己发送的数据量，这样就能大大减少丢包的概率。 滑动窗口机制 接收方的接收到数据之后，会不断处理，处理能力也不是一成不变的，有时候处理的快些，那就可以收多点数据，处理的慢点那就希望对方能少发点数据。毕竟发多了就有可能处理不过来导致丢包，丢包会导致重传，这可是下下策。因此我们需要动态的去调节这个接收窗口的大小，于是就有了滑动窗口机制。\n看到这里大家可能就有点迷了，流量控制和滑动窗口机制貌似很像，它们之间是啥关系？我总结一下。其实现在TCP是通过滑动窗口机制来实现流量控制机制的。 拥塞控制机制 但这还不够，有时候发生丢包，并不是因为发送方和接收方的处理能力问题导致的。而是跟网络环境有关，大家可以将网络想象为一条公路。马路上可能堵满了别人家的车，只留下一辆车的空间。那就算你家有5辆车，目的地也正好有5个停车位，你也没办法同时全部一起上路。于是TCP希望能感知到外部的网络环境，根据网络环境及时调整自己的发包数量，比如马路只够两辆车跑，那我就只发两辆车。但外部环境这么复杂，TCP是怎么感知到的呢？\nTCP会先慢慢试探的发数据，不断加码数据量，越发越多，先发一个，再发2个，4个…。直到出现丢包，这样TCP就知道现在当前网络大概吃得消几个包了，这既是所谓的拥塞控制机制。\n不少人会疑惑流量控制和拥塞控制的关系。我这里小小的总结下。流量控制针对的是单个连接数据处理能力的控制，拥塞控制针对的是整个网络环境数据处理能力的控制。\n分段机制 但上面提到的都是怎么降低重传的概率，似乎重传这个事情就是无法避免的，那如果确实发生了，有没有办法降低它带来的影响呢？\n有。当我们需要发送一个超大的数据包时，如果这个数据包丢了，那就得重传同样大的数据包。但如果我能将其分成一小段一小段，那就算真丢了，那我也就只需要重传那一小段就好了，大大减小了重传的压力，这就是TCP的分段机制。\n而这个所谓的一小段的长度，在传输层叫MSS（Maximum Segment Size），数据包长度大于MSS则会分成N个小于等于MSS的包。 而在网络层，如果数据包还大于MTU（Maximum Transmit Unit），那还会继续分包。 一般情况下，MSS=MTU-40Byte，所以TCP分段后，到了IP层大概率就不会再分片了。 乱序重排机制 既然数据包会被分段，链路又这么复杂还会丢包，那数据包乱序也就显得不奇怪了。比如发数据包1,2,3。1号数据包走了其他网络路径，2和3数据包先到，1数据包后到，于是数据包顺序就成了2,3,1。这一点TCP也考虑到了，依靠数据包的sequence，接收方就能知道数据包的先后顺序。\n后发的数据包先到是吧，那就先放到专门的乱序队列中，等数据都到齐后，重新整理好乱序队列的数据包顺序后再给到用户，这就是乱序重排机制。 连接机制 前面提到，UDP是无连接的，而TCP是面向连接的。\n这里提到的连接到底是啥？\nTCP通过上面提到的各种机制实现了数据的可靠性。这些机制背后是通过一个个数据结构来实现的逻辑。而为了实现这套逻辑，操作系统内核需要在两端代码里维护一套复杂的状态机（三次握手，四次挥手，RST，closing等异常处理机制），这套状态机其实就是所谓的\"连接\"。这其实就是TCP的连接机制，而UDP用不上这套状态机，因此它是\"无连接\"的。\n网络环境链路很长，还复杂，数据丢包是很常见的。\n我们平常用TCP做各种数据传输，完全对这些事情无感知。\n哪有什么岁月静好，是TCP替你负重前行。\n这就是TCP三大特性\"面向连接、可靠的、基于字节流\"中\"可靠\"的含义。\n不信你改用UDP试试，丢包那就是真丢了，丢到你怀疑人生。\n用UDP就一定比用TCP快吗？ 这时候UDP就不服了：“正因为没有这些复杂的TCP可靠性机制，所以我很快啊”\n嗯，这也是大部分人认为UDP比TCP快的原因。 实际上大部分情况下也确实是这样的。这话没毛病。\n那问题就来了。有没有用了UDP但却比TCP慢的情况呢？\n其实也有。 在回答这个问题前，我需要先说下UDP的用途。\n实际上，大部分人也不会尝试直接拿裸udp放到生产环境中去做项目。\n那UDP的价值在哪？\n在我看来，UDP的存在，本质是内核提供的一个最小网络传输功能。\n很多时候，大家虽然号称自己用了UDP，但实际上都很忌惮它的丢包问题，所以大部分情况下都会在UDP的基础上做各种不同程度的应用层可靠性保证。比如王者农药用的KCP，以及最近很火的QUIC（HTTP3.0），其实都在UDP的基础上做了重传逻辑，实现了一套类似TCP那样的可靠性机制。\n教科书上最爱提UDP适合用于音视频传输，因为这些场景允许丢包。但其实也不是什么包都能丢的，比如重要的关键帧啥的，该重传还得重传。除此之外，还有一些乱序处理机制。举个例子吧。\n打音视频电话的时候，你可能遇到过丢失中间某部分信息的情况，但应该从来没遇到过乱序的情况吧。\n比如对方打网络电话给你，说了：“我好想给小白来个点赞在看！”\n这时候网络信号不好，你可能会听到\"我….点赞在看\"。\n但却从来没遇到过\"在看小白好想赞\"这样的乱序场景吧？\n所以说，虽然选择了使用UDP，但一般还是会在应用层上做一些重传机制的。\n于是问题就来了，如果现在我需要传一个特别大的数据包。\n在TCP里，它内部会根据MSS的大小分段，这时候进入到IP层之后，每个包大小都不会超过MTU，因此IP层一般不会再进行分片。这时候发生丢包了，只需要重传每个MSS分段就够了。\n但对于UDP，其本身并不会分段，如果数据过大，到了IP层，就会进行分片。此时发生丢包的话，再次重传，就会重传整个大数据包。\n对于上面这种情况，使用UDP就比TCP要慢。\n当然，解决起来也不复杂。这里的关键点在于是否实现了数据分段机制，使用UDP的应用层如果也实现了分段机制的话，那就不会出现上述的问题了。\n总结 TCP为了实现可靠性，引入了重传机制、流量控制、滑动窗口、拥塞控制、分段以及乱序重排机制。而UDP则没有实现，因此一般来说TCP比UDP慢。\nTCP是面向连接的协议，而UDP是无连接的协议。这里的\"连接\"其实是，操作系统内核在两端代码里维护的一套复杂状态机。\n大部分项目，会在基于UDP的基础上，模仿TCP，实现不同程度的可靠性机制。比如王者农药用的KCP其实就在基于UDP在应用层里实现了一套重传机制。\n对于UDP+重传的场景，如果要传超大数据包，并且没有实现分段机制的话，那数据就会在IP层分片，一旦丢包，那就需要重传整个超大数据包。而TCP则不需要考虑这个，内部会自动分段，丢包重传分段就行了。这种场景下，其实TCP更快。\n","wordCount":"108","inLanguage":"en","datePublished":"2022-10-26T11:11:30+08:00","dateModified":"2022-10-26T11:11:30+08:00","author":[{"@type":"Person","name":"Reid"}],"mainEntityOfPage":{"@type":"WebPage","@id":"https://reid00.github.io/posts/udp%E5%B0%B1%E4%B8%80%E5%AE%9A%E6%AF%94tcp%E5%BF%AB%E5%90%97/"},"publisher":{"@type":"Organization","name":"Reid's Blog","logo":{"@type":"ImageObject","url":"https://reid00.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://reid00.github.io/ accesskey=h title="Reid's Blog (Alt + H)">Reid's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://reid00.github.io/archives title=Archive><span>Archive</span></a></li><li><a href=https://reid00.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://reid00.github.io/categories/ title=Categorys><span>Categorys</span></a></li><li><a href=https://reid00.github.io/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://reid00.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://reid00.github.io/posts/>Posts</a></div><h1 class=post-title>UDP就一定比TCP快吗</h1><div class=post-meta><span title='2022-10-26 11:11:30 +0800 +0800'>2022-10-26</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;Reid</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#%e4%bd%bf%e7%94%a8socket%e8%bf%9b%e8%a1%8c%e6%95%b0%e6%8d%ae%e4%bc%a0%e8%be%93 aria-label=使用socket进行数据传输>使用socket进行数据传输</a></li><li><a href=#%e5%af%b9%e4%ba%8e%e5%bc%82%e5%b8%b8%e6%83%85%e5%86%b5%e7%9a%84%e5%a4%84%e7%90%86 aria-label=对于异常情况的处理>对于异常情况的处理</a><ul><li><a href=#%e9%87%8d%e4%bc%a0%e6%9c%ba%e5%88%b6 aria-label=重传机制>重传机制</a></li><li><a href=#%e6%b5%81%e9%87%8f%e6%8e%a7%e5%88%b6%e6%9c%ba%e5%88%b6 aria-label=流量控制机制>流量控制机制</a></li><li><a href=#%e6%bb%91%e5%8a%a8%e7%aa%97%e5%8f%a3%e6%9c%ba%e5%88%b6 aria-label=滑动窗口机制>滑动窗口机制</a></li><li><a href=#%e6%8b%a5%e5%a1%9e%e6%8e%a7%e5%88%b6%e6%9c%ba%e5%88%b6 aria-label=拥塞控制机制>拥塞控制机制</a></li><li><a href=#%e5%88%86%e6%ae%b5%e6%9c%ba%e5%88%b6 aria-label=分段机制>分段机制</a></li><li><a href=#%e4%b9%b1%e5%ba%8f%e9%87%8d%e6%8e%92%e6%9c%ba%e5%88%b6 aria-label=乱序重排机制>乱序重排机制</a></li><li><a href=#%e8%bf%9e%e6%8e%a5%e6%9c%ba%e5%88%b6 aria-label=连接机制>连接机制</a></li></ul></li><li><a href=#%e6%80%bb%e7%bb%93 aria-label=总结>总结</a></li></ul></div></details></div><div class=post-content><p>话说，UDP比TCP快吗？</p><p>相信就算不是八股文老手，也会下意识的脱口而出：&ldquo;是&rdquo;。</p><p>这要追问为什么，估计大家也能说出个大概。</p><p>但这也让人好奇，用UDP就一定比用TCP快吗？什么情况下用UDP会比用TCP慢？</p><p>我们今天就来聊下这个话题。</p><h2 id=使用socket进行数据传输>使用socket进行数据传输<a hidden class=anchor aria-hidden=true href=#使用socket进行数据传输>#</a></h2><p>作为一个程序员，假设我们需要在A电脑的进程发一段数据到B电脑的进程，我们一般会在代码里使用socket进行编程。</p><p>socket就像是一个电话或者邮箱（邮政的信箱）。当你想要发送消息的时候，拨通电话或者将信息塞到邮箱里，socket内核会自动完成将数据传给对方的这个过程。</p><p>基于socket我们可以选择使用TCP或UDP协议进行通信。</p><p>对于TCP这样的可靠性协议，每次消息发出后都能明确知道对方收没收到，就像打电话一样，只要"喂喂"两下就能知道对方有没有在听。</p><p>而UDP就像是给邮政的信箱寄信一样，你寄出去的信，根本就不知道对方有没有正常收到，丢了也是有可能的。</p><p>这让我想起了大概17年前，当时还没有现在这么发达的网购，想买一本《掌机迷》杂志，还得往信封里塞钱，然后一等就是一个月，好几次都怀疑信是不是丢了。我至今印象深刻，因为那是我和我哥攒了好久的钱。。。</p><p>回到socket编程的话题上。</p><p>创建socket的方式就像下面这样。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=n>fd</span> <span class=o>=</span> <span class=nf>socket</span><span class=p>(</span><span class=n>AF_INET</span><span class=p>,</span> <span class=err>具体协议</span><span class=p>,</span><span class=mi>0</span><span class=p>);</span>
</span></span></code></pre></td></tr></table></div></div><p>注意上面的"具体协议"，如果传入的是SOCK_STREAM，是指使用字节流传输数据，说白了就是TCP协议。
TCP: <code>面向连接的</code> <code>可靠的</code> <code>基于字节流</code>
如果传入的是SOCK_DGRAM，是指使用数据报传输数据，也就是UDP协议。
UDP: <code>无连接</code> <code>不可靠</code> <code>基于消息报</code></p><p>返回的fd是指socket句柄，可以理解为socket的<code>身份证号</code>。通过这个fd你可以在内核中找到唯一的socket结构。</p><p>如果想要通过这个socket发消息，只需要操作这个fd就行了，比如执行 send(fd, msg, &mldr;)，内核就会通过这个fd句柄找到socket然后进行发数据的操作。</p><p>如果一切顺利，此时对方执行接收消息的操作，也就是 recv(fd, msg, &mldr;)，就能拿到你发的消息。
<img loading=lazy src="https://mmbiz.qpic.cn/mmbiz_gif/AnAgeMhDIianyhYJN5jcGIWlicWE0BlibPtC4ZAP7M7C8MfCy5DxV04r2W0pGpQWfQFek0DcH9Q48ugX1icib8ib4Piag/640?wx_fmt=gif&amp;wxfrom=5&amp;wx_lazy=1" alt=conn></p><h2 id=对于异常情况的处理>对于异常情况的处理<a hidden class=anchor aria-hidden=true href=#对于异常情况的处理>#</a></h2><p>但如果不顺利呢？</p><p>比如消息发到一半，丢包了呢?</p><p>那UDP和TCP的态度就不太一样了。</p><p>UDP表示，&ldquo;哦，是吗？然后呢？关我x事&rdquo;</p><p>TCP态度就截然相反了，&ldquo;啊？那可不行，是不是我发太快了呢？是不是链路太堵被别人影响到了呢？不过你放心，我肯定给你补发&rdquo;</p><p>TCP老实人石锤了。我们来看下这个老实人在背后都默默做了哪些事情。</p><h3 id=重传机制>重传机制<a hidden class=anchor aria-hidden=true href=#重传机制>#</a></h3><p>对于TCP，它会给发出的消息打上一个编号（sequence），接收方收到后回一个确认(ack)。发送方可以通过ack的数值知道接收方收到了哪些sequence的包。</p><p>如果长时间等不到对方的确认，TCP就会重新发一次消息，这就是所谓的重传机制。
<img loading=lazy src=https://cdn.staticaly.com/gh/Reid00/image-host@main/20221026/image.1ye33hio78sg.webp alt=重传></p><h3 id=流量控制机制>流量控制机制<a hidden class=anchor aria-hidden=true href=#流量控制机制>#</a></h3><p>但重传这件事本身对性能影响是比较严重的，所以是下下策。</p><p>于是TCP就需要思考有没有办法可以<code>尽量避免重传</code>。</p><p>因为数据发送方和接收方处理数据能力可能不同，因此如果可以根据双方的能力去调整发送的数据量就好了，于是就有了<code>发送和接收窗口</code>，基本上从名字就能看出它的作用，比如<code>接收窗口的大小就是指，接收方当前能接收的数据量大小，发送窗口的大小就指发送方当前能发的数据量大小</code>。TCP根据窗口的大小去控制自己发送的数据量，这样就能大大减少丢包的概率。
<img loading=lazy src=https://cdn.staticaly.com/gh/Reid00/image-host@main/20221026/image.1w5fzfgjt2hs.webp alt=win></p><h3 id=滑动窗口机制>滑动窗口机制<a hidden class=anchor aria-hidden=true href=#滑动窗口机制>#</a></h3><p>接收方的接收到数据之后，会不断处理，<code>处理能力也不是一成不变的</code>，有时候处理的快些，那就可以收多点数据，处理的慢点那就希望对方能少发点数据。毕竟发多了就有可能处理不过来导致丢包，丢包会导致重传，这可是下下策。因此我们需要动态的去调节这个接收窗口的大小，于是就有了<code>滑动窗口机制</code>。</p><p>看到这里大家可能就有点迷了，流量控制和滑动窗口机制貌似很像，它们之间是啥关系？我总结一下。<code>其实现在TCP是通过滑动窗口机制来实现流量控制机制的。</code>
<img loading=lazy src=https://cdn.staticaly.com/gh/Reid00/image-host@main/20221026/image.1pbz1bkdeqm8.webp alt=img></p><h3 id=拥塞控制机制>拥塞控制机制<a hidden class=anchor aria-hidden=true href=#拥塞控制机制>#</a></h3><p>但这还不够，有时候发生丢包，<code>并不是因为发送方和接收方的处理能力问题导致的</code>。而是跟<code>网络环境</code>有关，大家可以将网络想象为一条公路。马路上可能堵满了别人家的车，只留下一辆车的空间。那就算你家有5辆车，目的地也正好有5个停车位，你也没办法同时全部一起上路。于是TCP希望能感知到外部的网络环境，根据网络环境及时调整自己的发包数量，比如马路只够两辆车跑，那我就只发两辆车。但外部环境这么复杂，TCP是怎么感知到的呢？</p><p>TCP会<code>先慢慢试探的发数据</code>，不断加码数据量，越发越多，先发一个，再发2个，4个…。<code>直到出现丢包</code>，这样TCP就知道现在当前网络大概吃得消几个包了，这既是所谓的拥塞控制机制。</p><p>不少人会疑惑流量控制和拥塞控制的关系。我这里小小的总结下。<code>流量控制针对的是单个连接数据处理能力的控制，拥塞控制针对的是整个网络环境数据处理能力的控制。</code></p><h3 id=分段机制>分段机制<a hidden class=anchor aria-hidden=true href=#分段机制>#</a></h3><p>但上面提到的都是怎么降低重传的概率，似乎重传这个事情就是无法避免的，<code>那如果确实发生了，有没有办法降低它带来的影响呢？</code></p><p>有。当我们需要发送一个<code>超大</code>的数据包时，如果这个数据包丢了，那就得<code>重传同样大的数据包</code>。但如果我能将其<code>分成一小段一小段</code>，那就算真丢了，那我也就只需要重传那一小段就好了，大大减小了重传的压力，这就是TCP的分段机制。</p><p>而这个所谓的一小段的长度，在传输层叫<code>MSS（Maximum Segment Size）</code>，数据包长度大于MSS则会分成N个小于等于MSS的包。
<img loading=lazy src="https://mmbiz.qpic.cn/mmbiz_gif/AnAgeMhDIianyhYJN5jcGIWlicWE0BlibPtZr5Llwk6yHJybDHSe3oXC6N9HuUibhRhqCypQiamOuibMyyZkbUfb0GbA/640?wx_fmt=gif&amp;wxfrom=5&amp;wx_lazy=1" alt=MSS分包></p><p>而在网络层，如果数据包还大于MTU（Maximum Transmit Unit），那还会继续分包。
<img loading=lazy src="https://mmbiz.qpic.cn/mmbiz_gif/AnAgeMhDIianyhYJN5jcGIWlicWE0BlibPtmBbcwib8JKrk6ButEVJtibiapvuJDMcpuGtqc7eXPa0d7fibeB9HicBYUFA/640?wx_fmt=gif&amp;wxfrom=5&amp;wx_lazy=1" alt=MTU分包></p><p>一般情况下，MSS=MTU-40Byte，所以TCP分段后，到了IP层大概率就不会再分片了。
<img loading=lazy src=https://cdn.staticaly.com/gh/Reid00/image-host@main/20221026/image.2i66eav5eny0.webp alt=MSS和MTU的区别></p><h3 id=乱序重排机制>乱序重排机制<a hidden class=anchor aria-hidden=true href=#乱序重排机制>#</a></h3><p>既然数据包会被分段，链路又这么复杂还会丢包，那数据包乱序也就显得不奇怪了。比如发数据包1,2,3。1号数据包走了其他网络路径，2和3数据包先到，1数据包后到，于是数据包顺序就成了2,3,1。这一点TCP也考虑到了，<code>依靠数据包的sequence</code>，接收方就能知道数据包的先后顺序。</p><p>后发的数据包先到是吧，那就先放到专门的乱序队列中，等数据都到齐后，重新整理好乱序队列的数据包顺序后再给到用户，这就是乱序重排机制。
<img loading=lazy src=https://cdn.staticaly.com/gh/Reid00/image-host@main/20221026/image.tc1jjilupls.webp alt=乱序队列等待数据包的到来></p><h3 id=连接机制>连接机制<a hidden class=anchor aria-hidden=true href=#连接机制>#</a></h3><p>前面提到，UDP是无连接的，而TCP是面向连接的。</p><p>这里提到的<code>连接</code>到底是啥？</p><p>TCP通过上面提到的各种机制实现了数据的可靠性。这些机制背后是通过一个个数据结构来实现的逻辑。而为了实现这套逻辑，操作系统内核需要在两端代码里维护<code>一套复杂的状态机</code>（三次握手，四次挥手，RST，closing等异常处理机制），<code>这套状态机其实就是所谓的"连接"</code>。这其实就是TCP的连接机制，而UDP用不上这套状态机，因此它是"无连接"的。</p><p>网络环境链路很长，还复杂，数据丢包是很常见的。</p><p>我们平常用TCP做各种数据传输，完全对这些事情无感知。</p><p>哪有什么岁月静好，<code>是TCP替你负重前行</code>。</p><p>这就是TCP三大特性"面向连接、可靠的、基于字节流"中"可靠"的含义。</p><p>不信你改用UDP试试，丢包那就是真丢了，丢到你怀疑人生。</p><p>用UDP就一定比用TCP快吗？
这时候UDP就不服了：&ldquo;正因为没有这些复杂的TCP可靠性机制，所以我很快啊&rdquo;</p><p>嗯，这也是大部分人认为UDP比TCP快的原因。
实际上大部分情况下也确实是这样的。这话没毛病。</p><p>那问题就来了。有没有用了UDP但却比TCP慢的情况呢？</p><p>其实也有。
在回答这个问题前，我需要先说下UDP的用途。</p><p>实际上，大部分人也不会尝试直接拿裸udp放到生产环境中去做项目。</p><p>那UDP的价值在哪？</p><p>在我看来，UDP的存在，本质是内核提供的一个<code>最小网络传输功能</code>。</p><p>很多时候，大家虽然号称自己用了UDP，但实际上都很忌惮它的丢包问题，所以大部分情况下都会在UDP的基础上做各种不同程度的应用层可靠性保证。比如王者农药用的<code>KCP</code>，以及最近很火的<code>QUIC（HTTP3.0）</code>，其实都在UDP的基础上做了<code>重传逻辑</code>，<code>实现了一套类似TCP那样的可靠性机制</code>。</p><p>教科书上最爱提UDP适合用于音视频传输，因为这些场景允许丢包。但其实也不是什么包都能丢的，比如重要的关键帧啥的，该重传还得重传。除此之外，还有一些乱序处理机制。举个例子吧。</p><p>打音视频电话的时候，你可能遇到过丢失中间某部分信息的情况，但应该从来没遇到过乱序的情况吧。</p><p>比如对方打网络电话给你，说了：&ldquo;我好想给小白来个点赞在看！&rdquo;</p><p>这时候网络信号不好，你可能会听到"我….点赞在看"。</p><p>但却从来没遇到过"在看小白好想赞"这样的乱序场景吧？</p><p>所以说，虽然选择了使用UDP，但一般还是会在应用层上做一些重传机制的。</p><p>于是问题就来了，如果现在我需要传一个特别大的数据包。</p><p>在TCP里，它内部会根据MSS的大小分段，这时候进入到IP层之后，每个包大小都不会超过MTU，因此IP层一般不会再进行分片。这时候发生丢包了，只需要重传每个MSS分段就够了。</p><p>但对于UDP，其本身并不会分段，如果数据过大，到了IP层，就会进行分片。此时发生丢包的话，再次重传，就会重传整个大数据包。</p><p>对于上面这种情况，使用UDP就比TCP要慢。</p><p>当然，解决起来也不复杂。<code>这里的关键点在于是否实现了数据分段机制，使用UDP的应用层如果也实现了分段机制的话，那就不会出现上述的问题了</code>。</p><h2 id=总结>总结<a hidden class=anchor aria-hidden=true href=#总结>#</a></h2><p>TCP为了实现可靠性，引入了重传机制、流量控制、滑动窗口、拥塞控制、分段以及乱序重排机制。而UDP则没有实现，因此一般来说TCP比UDP慢。</p><p>TCP是面向连接的协议，而UDP是无连接的协议。这里的"连接"其实是，操作系统内核在两端代码里维护的一套复杂状态机。</p><p>大部分项目，会在基于UDP的基础上，模仿TCP，实现不同程度的可靠性机制。比如王者农药用的KCP其实就在基于UDP在应用层里实现了一套重传机制。</p><p>对于UDP+重传的场景，如果要传超大数据包，并且没有实现分段机制的话，那数据就会在IP层分片，一旦丢包，那就需要重传整个超大数据包。而TCP则不需要考虑这个，内部会自动分段，丢包重传分段就行了。这种场景下，其实TCP更快。</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://reid00.github.io/tags/tcp/>TCP</a></li><li><a href=https://reid00.github.io/tags/udp/>UDP</a></li></ul><nav class=paginav><a class=prev href=https://reid00.github.io/posts/raft-%E4%BB%8B%E7%BB%8D/><span class=title>« Prev</span><br><span>Raft 介绍</span></a>
<a class=next href=https://reid00.github.io/posts/spark-%E9%9D%A2%E8%AF%95%E6%B3%A8%E6%84%8F%E7%82%B9/><span class=title>Next »</span><br><span>Spark 面试注意点</span></a></nav></footer><script src=https://utteranc.es/client.js repo=Reid00/hugo-blog-talks issue-term=pathname label=Comment theme=github-light crossorigin=anonymous async></script></article></main><footer class=footer><span>&copy; 2023 <a href=https://reid00.github.io/>Reid's Blog</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>