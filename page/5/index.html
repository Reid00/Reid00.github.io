<!doctype html><html lang=en dir=auto><head><meta name=generator content="Hugo 0.111.3"><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Reid's Blog</title><meta name=description content="Reid's Personal Notes -- https://github.com/Reid00"><meta name=author content="Reid"><link rel=canonical href=https://reid00.github.io/><link crossorigin=anonymous href=/assets/css/stylesheet.d7fb4cbf980fe688a21621b06a795933c4e6bb2d4070ec940667af1715d84af2.css integrity="sha256-1/tMv5gP5oiiFiGwanlZM8Tmuy1AcOyUBmevFxXYSvI=" rel="preload stylesheet" as=style><link rel=icon href=https://reid00.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://reid00.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://reid00.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://reid00.github.io/apple-touch-icon.png><link rel=mask-icon href=https://reid00.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://reid00.github.io/index.xml><link rel=alternate type=application/json href=https://reid00.github.io/index.json><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-QRR6GRNQGK"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-QRR6GRNQGK",{anonymize_ip:!1})}</script><meta property="og:title" content="Reid's Blog"><meta property="og:description" content="Reid's Personal Notes -- https://github.com/Reid00"><meta property="og:type" content="website"><meta property="og:url" content="https://reid00.github.io/"><meta property="og:image" content="https://i.loli.net/2021/09/26/3OMGXylm8HUYJ6p.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://i.loli.net/2021/09/26/3OMGXylm8HUYJ6p.png"><meta name=twitter:title content="Reid's Blog"><meta name=twitter:description content="Reid's Personal Notes -- https://github.com/Reid00"><script type=application/ld+json>{"@context":"https://schema.org","@type":"Organization","name":"Reid's Blog","url":"https://reid00.github.io/","description":"Reid\u0026#39;s Personal Notes -- https://github.com/Reid00","thumbnailUrl":"https://reid00.github.io/favicon.ico","sameAs":["https://github.com/Reid00","https://twitter.com","index.xml"]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://reid00.github.io/ accesskey=h title="Reid's Blog (Alt + H)">Reid's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://reid00.github.io/archives title=Archive><span>Archive</span></a></li><li><a href=https://reid00.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://reid00.github.io/categories/ title=Categorys><span>Categorys</span></a></li><li><a href=https://reid00.github.io/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-entry><header class=entry-header><h2>CTR发展</h2></header><div class=entry-content><p>简介 在推荐、搜索、广告等领域，CTR（click-through rate）预估是一项非常核心的技术，这里引用阿里妈妈资深算法专家朱小强大佬的一句话：“它（CTR预估）是镶嵌在互联网技术上的明珠”。
本篇文章主要是对CTR预估中的常见模型进行梳理与总结，并分成模块进行概述。每个模型都会从「模型结构」、「优势」、「不足」三个方面进行探讨，在最后对所有模型之间的关系进行比较与总结。本篇文章讨论的模型如下图所示（原创图），这个图中展示了本篇文章所要讲述的算法以及之间的关系，在文章的最后总结会对这张图进行详细地说明。
一. 分布式线性模型 Logistic Regression Logistic Regression是每一位算法工程师再也熟悉不过的基本算法之一了，毫不夸张地说，LR作为最经典的统计学习算法几乎统治了早期工业机器学习时代。这是因为其具备简单、时间复杂度低、可大规模并行化等优良特性。在早期的CTR预估中，算法工程师们通过手动设计交叉特征以及特征离散化等方式，赋予LR这样的线性模型对数据集的非线性学习能力，高维离散特征+手动交叉特征构成了CTR预估的基础特征。LR在工程上易于大规模并行化训练恰恰适应了这个时代的要求。
模型结构：
优势：
模型简单，具备一定可解释性 计算时间复杂度低 工程上可大规模并行化 不足：
依赖于人工大量的特征工程，例如需要根据业务背知识通过特征工程融入模型 特征交叉难以穷尽 对于训练集中没有出现的交叉特征无法进行参数学习 二. 自动化特征工程 GBDT + LR（2014）—— 特征自动化时代的初探索 Facebook在2014年提出了GBDT+LR的组合模型来进行CTR预估，其本质上是通过Boosting Tree模型本身的特征组合能力来替代原先算法工程师们手动组合特征的过程。GBDT等这类Boosting Tree模型本身具备了特征筛选能力（每次分裂选取增益最大的分裂特征与分裂点）以及高阶特征组合能力（树模型天然优势）对应树的一条路径（用叶子节点来表示），因此通过GBDT来自动生成特征向量就成了一个非常自然的思路。注意这里虽然是两个模型的组合，但实际并非是端到端的模型，而是两阶段的、解耦的，即先通过GBDT训练得到特征向量后，再作为下游LR的输入，LR的在训练过程中并不会对GBDT进行更新。
模型结构：
通过GBDT训练模型，得到组合的特征向量。例如训练了两棵树，每棵树有5个叶子结点，对于某个特定样本来说，落在了第一棵树的第3个结点，此时我们可以得到向量 ；落在第二棵树的第4个结点，此时的到向量 ；那么最终通过concat所有树的向量，得到这个样本的最终向量 。将这个向量作为下游LR模型的inputs，进行训练。
优势：
特征工程自动化，通过Boosting Tree模型的天然优势自动探索特征组合 不足：
两阶段的、非端到端的模型 CTR预估场景涉及到大量高维稀疏特征，树模型并不适合处理（因此实际上会将dense特征或者低维的离散特征给GBDT，剩余高维稀疏特征在LR阶段进行训练） GBDT模型本身比较复杂，无法做到online learning，模型对数据的感知相对较滞后（必须提高离线模型的更新频率） 由于LR善于处理离散特征，GBDT善于处理连续特征。所以也可以交由GBDT处理连续特征，输出结果拼接上离散特征一起输入LR。
三. FM模型以及变体 （1）FM：Factorization Machines, 2010 —— 隐向量学习提升模型表达 FM是在2010年提出的一种可以学习二阶特征交叉的模型，通过在原先线性模型的基础上，枚举了所有特征的二阶交叉信息后融入模型，提高了模型的表达能力。但不同的是，模型在二阶交叉信息的权重学习上，采用了隐向量内积（也可看做embedding）的方式进行学习。
FM和基于树的模型（e.g. GBDT）都能够自动学习特征交叉组合。基于树的模型适合连续中低度稀疏数据，容易学到高阶组合。但是树模型却不适合学习高度稀疏数据的特征组合，一方面高度稀疏数据的特征维度一般很高，这时基于树的模型学习效率很低，甚至不可行；另一方面树模型也不能学习到训练数据中很少或没有出现的特征组合。相反，FM模型因为通过隐向量的内积来提取特征组合，对于训练数据中很少或没有出现的特征组合也能够学习到。例如，特征 和特征 在训练数据中从来没有成对出现过，但特征 经常和特征 成对出现，特征 也经常和特征 成对出现，因而在FM模型中特征 和特征 也会有一定的相关性。毕竟所有包含特征 的训练样本都会导致模型更新特征 的隐向量 ，同理，所有包含特征 的样本也会导致模型更新隐向量 ，这样 就不太可能为0。
模型结构：
FM的公式包含了一阶线性部分与二阶特征交叉部分：
在LR中，一般是通过手动构造交叉特征后，喂给模型进行训练，例如我们构造性别与广告类别的交叉特征： (gender=’女’ & ad_category=’美妆’)，此时我们会针对这个交叉特征学习一个参数 。但是在LR中，参数梯度更新公式与该特征取值 关系密切： ，当 取值为0时，参数 就无法得到更新，而 要非零就要求交叉特征的两项都要非零，但实际在数据高度稀疏，一旦两个特征只要有一个取0，参数 不能得到有效更新；除此之外，对于训练集中没有出现的交叉特征，也没办法学习这类权重，泛化性能不够好。...</p></div><footer class=entry-footer><span title='2022-06-08 14:00:30 +0800 +0800'>2022-06-08</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;Reid</footer><a class=entry-link aria-label="post link to CTR发展" href=https://reid00.github.io/posts/ml/ctr%E5%8F%91%E5%B1%95/></a></article><article class=post-entry><header class=entry-header><h2>Token Cookie Session区别</h2></header><div class=entry-content><p>在做接口测试时，经常会碰到请求参数为token的类型，但是可能大部分测试人员对token，cookie，session的区别还是一知半解。
Cookie cookie 是一个非常具体的东西，指的就是浏览器里面能永久存储的一种数据，仅仅是浏览器实现的一种数据存储功能。
cookie由服务器生成，发送给浏览器，浏览器把cookie以kv形式保存到某个目录下的文本文件内，下一次请求同一网站时会把该cookie发送给服务器。由于cookie是存在客户端上的，所以浏览器加入了一些限制确保cookie不会被恶意使用，同时不会占据太多磁盘空间，所以每个域的cookie数量是有限的。
Session session 从字面上讲，就是会话。这个就类似于你和一个人交谈，你怎么知道当前和你交谈的是张三而不是李四呢？对方肯定有某种特征（长相等）表明他就是张三。
session 也是类似的道理，服务器要知道当前发请求给自己的是谁。为了做这种区分，服务器就要给每个客户端分配不同的“身份标识”，然后客户端每次向服务器发请求的时候，都带上这个“身份标识”，服务器就知道这个请求来自于谁了。至于客户端怎么保存这个“身份标识”，可以有很多种方式，对于浏览器客户端，大家都默认采用 cookie 的方式。
服务器使用session把用户的信息临时保存在了服务器上，用户离开网站后session会被销毁。这种用户信息存储方式相对cookie来说更安全，可是session有一个缺陷：如果web服务器做了负载均衡，那么下一个操作请求到了另一台服务器的时候session会丢失。
Token Token的引入：Token是在客户端频繁向服务端请求数据，服务端频繁的去数据库查询用户名和密码并进行对比，判断用户名和密码正确与否，并作出相应提示，在这样的背景下，Token便应运而生。
Token的定义：Token是服务端生成的一串字符串，以作客户端进行请求的一个令牌，当第一次登录后，服务器生成一个Token便将此Token返回给客户端，以后客户端只需带上这个Token前来请求数据即可，无需再次带上用户名和密码。最简单的token组成:uid(用户唯一的身份标识)、time(当前时间的时间戳)、sign(签名，由token的前几位+盐以哈希算法压缩成一定长的十六进制字符串，可以防止恶意第三方拼接token请求服务器)。
使用Token的目的：Token的目的是为了减轻服务器的压力，减少频繁的查询数据库，使服务器更加健壮。
传统身份验证 HTTP 是一种没有状态的协议，也就是它并不知道是谁是访问应用。这里我们把用户看成是客户端，客户端使用用户名还有密码通过了身份验证，不过下回这个客户端再发送请求时候，还得再验证一下。
解决的方法就是，当用户请求登录的时候，如果没有问题，我们在服务端生成一条记录，这个记录里可以说明一下登录的用户是谁，然后把这条记录的 ID 号发送给客户端，客户端收到以后把这个 ID 号存储在 Cookie 里，下次这个用户再向服务端发送请求的时候，可以带着这个 Cookie ，这样服务端会验证一个这个 Cookie 里的信息，看看能不能在服务端这里找到对应的记录，如果可以，说明用户已经通过了身份验证，就把用户请求的数据返回给客户端。
上面说的就是 Session，我们需要在服务端存储为登录的用户生成的 Session ，这些 Session 可能会存储在内存，磁盘，或者数据库里。我们可能需要在服务端定期的去清理过期的 Session 。
基于 Token 的身份验证 使用基于 Token 的身份验证方法，在服务端不需要存储用户的登录记录。大概的流程是这样的：
客户端使用用户名跟密码请求登录 服务端收到请求，去验证用户名与密码 验证成功后，服务端会签发一个 Token，再把这个 Token 发送给客户端 客户端收到 Token 以后可以把它存储起来，比如放在 Cookie 里或者 Local Storage 里 客户端每次向服务端请求资源的时候需要带着服务端签发的 Token 服务端收到请求，然后去验证客户端请求里面带着的 Token，如果验证成功，就向客户端返回请求的数据 APP登录的时候发送加密的用户名和密码到服务器，服务器验证用户名和密码，如果成功，以某种方式比如随机生成32位的字符串作为token，存储到服务器中，并返回token到APP，以后APP请求时，凡是需要验证的地方都要带上该token，然后服务器端验证token，成功返回所需要的结果，失败返回错误信息，让他重新登录。其中服务器上token设置一个有效期，每次APP请求的时候都验证token和有效期。
那么我的问题来了：1.服务器上的token存储到数据库中，每次查询会不会很费时。如果不存储到数据库，应该存储到哪里呢。2.客户端得到的token肯定要加密存储的，发送token的时候再解密。存储到数据库还是配置文件呢？
token是个易失数据，丢了无非让用户重新登录一下，新浪微博动不动就让我重新登录，反正这事儿我是无所谓啦。 所以如果你觉得普通的数据库表撑不住了，可以放到 MSSQL/MySQL 的内存表里（不过据说mysql的内存表性能提升有限），可以放到 Memcache里（讲真，这个是挺常见的策略），可以放到redis里（我做过这样的实现），甚至可以放到 OpenResty 的变量字典里（只要你有信心不爆内存）。...</p></div><footer class=entry-footer><span title='2022-06-08 13:57:41 +0800 +0800'>2022-06-08</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;Reid</footer><a class=entry-link aria-label="post link to Token Cookie Session区别" href=https://reid00.github.io/posts/token-cookie-session%E5%8C%BA%E5%88%AB/></a></article><article class=post-entry><header class=entry-header><h2>搜索引擎背后的经典数据结构和算法</h2></header><div class=entry-content><p>前言 我们每天都在用 Google, 百度这些搜索引擎，那大家有没想过搜索引擎是如何实现的呢，看似简单的搜索其实技术细节非常复杂，说搜索引擎是 IT 皇冠上的明珠也不为过，今天我们来就来简单过一下搜索引擎的原理，看看它是如何工作的，当然搜索引擎博大精深，一篇文章不可能完全介绍完，我们只会介绍它最重要的几个步骤，不过万变不离其宗，搜索引擎都离开这些重要步骤，剩下的无非是在其上添砖加瓦，所以掌握这些「关键路径」，能很好地达到观一斑而窥全貎的目的。
本文将会从以下几个部分来介绍搜索引擎，会深度剖析搜索引擎的工作原理及其中用到的一些经典数据结构和算法，相信大家看了肯定有收获。
搜索引擎系统架构图
搜索引擎工作原理详细剖析
搜索引擎系统架构图 搜索引擎整体架构图如下图所示，大致可以分为搜集，预处理，索引，查询这四步，每一步的技术细节都很多，我们将在下文中详细分析每一步的工作原理。 搜索引擎工作原理详细剖析 一、搜索 爬虫一开始是不知道该从哪里开始爬起的，所以我们可以给它一组优质种子网页的链接，比如新浪主页，腾讯主页等，这些主页比较知名，在 Alexa 排名上也非常靠前，拿到这些优质种子网页后，就对这些网页通过广度优先遍历不断遍历这些网页，爬取网页内容，提取出其中的链接，不断将其将入到待爬取队列，然后爬虫不断地从 url 的待爬取队列里提取出 url 进行爬取，重复以上过程…
当然了，只用一个爬虫是不够的，可以启动多个爬虫并行爬取，这样速度会快很多。
1、待爬取的 url 实现 待爬取 url 我们可以把它放到 Redis 里，保证了高性能，需要注意的是，Redis要开启持久化功能，这样支持断点续爬，如果 Redis 挂掉了，重启之后由于有持续久功能，可以从上一个待爬的 url 开始重新爬。
2、如何判重 如何避免网页的重复爬取呢，我们需要对 url 进行去重操作，去重怎么实现？可能有人说用散列表，将每个待抓取 url 存在散列表里，每次要加入待爬取 url 时都通过这个散列表来判断一下是否爬取过了，这样做确实没有问题，但我们需要注意到的是这样需要会出巨大的空间代价，有多大，我们简单算一下，假设有 10 亿 url （不要觉得 10 亿很大，像 Google, 百度这样的搜索引擎，它们要爬取的网页量级比 10 亿大得多），放在散列表里，需要多大存储空间呢？
我们假设每个网页 url 平均长度 64 字节，则 10 亿个 url 大约需要 60 G 内存，如果用散列表实现的话，由于散列表为了避免过多的冲突，需要较小的装载因子（假设哈希表要装载 10 个元素，实际可能要分配 20 个元素的空间，以避免哈希冲突），同时不管是用链式存储还是用红黑树来处理冲突，都要存储指针，各种这些加起来所需内存可能会超过 100 G，再加上冲突时需要在链表中比较字符串，性能上也是一个损耗，当然 100 G 对大型搜索引擎来说不是什么大问题，但其实还有一种方案可以实现远小于 100 G 的内存：布隆过滤器。...</p></div><footer class=entry-footer><span title='2022-06-08 11:54:09 +0800 +0800'>2022-06-08</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;Reid</footer><a class=entry-link aria-label="post link to 搜索引擎背后的经典数据结构和算法" href=https://reid00.github.io/posts/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E8%83%8C%E5%90%8E%E7%9A%84%E7%BB%8F%E5%85%B8%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/></a></article><article class=post-entry><header class=entry-header><h2>MySql事务</h2></header><div class=entry-content><p>『浅入深出』MySQL 中事务的实现 https://draveness.me/mysql-transaction/
MySQL 中如何实现事务隔离 https://www.cnblogs.com/fengzheng/p/12557762.html
详解一条 SQL 的执行过程
https://juejin.cn/post/6931606328129355790
首先说读未提交，它是性能最好，也可以说它是最野蛮的方式，因为它压根儿就不加锁，所以根本谈不上什么隔离效果，可以理解为没有隔离。
再来说串行化。读的时候加共享锁，也就是其他事务可以并发读，但是不能写。写的时候加排它锁，其他事务不能并发写也不能并发读。
最后说读提交和可重复读。这两种隔离级别是比较复杂的，既要允许一定的并发，又想要兼顾的解决问题。
实现可重复读 为了解决不可重复读，或者为了实现可重复读，MySQL 采用了 MVVC (多版本并发控制) 的方式。
我们在数据库表中看到的一行记录可能实际上有多个版本，每个版本的记录除了有数据本身外，还要有一个表示版本的字段，记为 row trx_id，而这个字段就是使其产生的事务的 id，事务 ID 记为 transaction id，它在事务开始的时候向事务系统申请，按时间先后顺序递增。
按照上面这张图理解，一行记录现在有 3 个版本，每一个版本都记录这使其产生的事务 ID，比如事务A的transaction id 是100，那么版本1的row trx_id 就是 100，同理版本2和版本3。
在上面介绍读提交和可重复读的时候都提到了一个词，叫做快照，学名叫做一致性视图，这也是可重复读和不可重复读的关键，可重复读是在事务开始的时候生成一个当前事务全局性的快照，而读提交则是每次执行语句的时候都重新生成一次快照。
对于一个快照来说，它能够读到那些版本数据，要遵循以下规则：
当前事务内的更新，可以读到； 版本未提交，不能读到； 版本已提交，但是却在快照创建后提交的，不能读到； 版本已提交，且是在快照创建前提交的，可以读到； 利用上面的规则，再返回去套用到读提交和可重复读的那两张图上就很清晰了。还是要强调，两者主要的区别就是在快照的创建上，可重复读仅在事务开始是创建一次，而读提交每次执行语句的时候都要重新创建一次。
并发写问题 存在这的情况，两个事务，对同一条数据做修改。最后结果应该是哪个事务的结果呢，肯定要是时间靠后的那个对不对。并且更新之前要先读数据，这里所说的读和上面说到的读不一样，更新之前的读叫做“当前读”，总是当前版本的数据，也就是多版本中最新一次提交的那版。
假设事务A执行 update 操作， update 的时候要对所修改的行加行锁，这个行锁会在提交之后才释放。而在事务A提交之前，事务B也想 update 这行数据，于是申请行锁，但是由于已经被事务A占有，事务B是申请不到的，此时，事务B就会一直处于等待状态，直到事务A提交，事务B才能继续执行，如果事务A的时间太长，那么事务B很有可能出现超时异常。如下图所示。
加锁的过程要分有索引和无索引两种情况，比如下面这条语句
1 update user set age=11 where id = 1 id 是这张表的主键，是有索引的情况，那么 MySQL 直接就在索引数中找到了这行数据，然后干净利落的加上行锁就可以了。
而下面这条语句
1 update user set age=11 where age=10 表中并没有为 age 字段设置索引，所以， MySQL 无法直接定位到这行数据。那怎么办呢，当然也不是加表锁了。MySQL 会为这张表中所有行加行锁，没错，是所有行。但是呢，在加上行锁后，MySQL 会进行一遍过滤，发现不满足的行就释放锁，最终只留下符合条件的行。虽然最终只为符合条件的行加了锁，但是这一锁一释放的过程对性能也是影响极大的。所以，如果是大表的话，建议合理设计索引，如果真的出现这种情况，那很难保证并发度。...</p></div><footer class=entry-footer><span title='2022-06-08 11:52:57 +0800 +0800'>2022-06-08</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;Reid</footer><a class=entry-link aria-label="post link to MySql事务" href=https://reid00.github.io/posts/mysql%E4%BA%8B%E5%8A%A1/></a></article><article class=post-entry><header class=entry-header><h2>Python多线程多进程</h2></header><div class=entry-content><p>一、 python 的多线程不能利用多核CPU 因为GIL (全局解释器锁), Pyhton 只有一个GIL， 在运行Python 时， 就要拿到这个锁，才能运行，在遇到I/O 操作时，会释放这把锁。
如果是纯计算型的程序，没有I/O 操作，解释器会每隔100 次操作就释放这把锁，让别的线程有机会执行(这个次数可以通sys.setcheckinterval来调整), 同一时间内，有且仅会只有一个线程获得GIL 在运行，其他线程都处于等待状态。
如果是CPU 密集型的代码比如，循环，计算等，由于计算量多和大，计算很快就会达到100次，然后触发GIL 的释放与竞争，多个线程来回切换损耗资源，所以在多线程遇到CPU密集型的代码时，效率远远不如单线程高 如果是I/O 密集型代码(文件处理，网络爬虫), 开启多线程实际上是并发，IO操作会进行IO等待，在线程A等待时，自动切换到线程B，这样就提升了效率。 面向I/O的（会调用内建的操作系统C代码的）程序来说，GIL会在这个I/O调用之前被释放，以允许其他线程在这个线程等待I/O的时候运行。如果某线程并未使用很多I/O操作，它会在自己的时间片内一直占用处理器和GIL。 也就是说，I/O密集型的Python程序比计算密集型的Python程序更能充分利用多线程的好处。我们都知道，比方我有一个4核的CPU，那么这样一来，在单位时间内每个核只能跑一个线程，然后时间片轮转切换。 但是Python不一样，它不管你有几个核，单位时间多个核只能跑一个线程，然后时间片轮转。看起来很不可思议？但是这就是GIL搞的鬼。任何Python线程执行前，必须先获得GIL锁，然后，每执行100条字节码，解释器就自动释放GIL锁， 让别的线程有机会执行。这个GIL全局锁实际上把所有线程的执行代码都给上了锁，所以，多线程在Python中只能交替执行，即使100个线程跑在100核CPU上，也只能用到1个核。通常我们用的解释器是官方实现的CPython，要真正利用多核，除非重写一个不带GIL的解释器。
二、解决办法 就如此？我们没有办法在Python中利用多核？当然可以！刚才的多进程算是一种解决方案，还有一种就是调用C语言的链接库。对所有面向I/O的（会调用内建的操作系统C代码的）程序来说，GIL会在这个I/O调用之前被释放，以允许其他线程在这个线程等待I/O的时候运行。我们可以把一些 计算密集型任务用C语言编写，然后把.so链接库内容加载到Python中，因为执行C代码，GIL锁会释放，这样一来，就可以做到每个核都跑一个线程的目的！ 可能有的小伙伴不太理解什么是计算密集型任务，什么是I/O密集型任务？
计算密集型任务的特点是要进行大量的计算，消耗CPU资源，比如计算圆周率、对视频进行高清解码等等，全靠CPU的运算能力。这种计算密集型任务虽然也可以用多任务完成，但是任务越多，花在任务切换的时间就越多，CPU执行任务的效率就越低，所以，要最高效地利用CPU，计算密集型任务同时进行的数量应当等于CPU的核心数。
计算密集型任务由于主要消耗CPU资源，因此，代码运行效率至关重要。Python这样的脚本语言运行效率很低，完全不适合计算密集型任务。对于计算密集型任务，最好用C语言编写。
第二种任务的类型是IO密集型，涉及到网络、磁盘IO的任务都是IO密集型任务，这类任务的特点是CPU消耗很少，任务的大部分时间都在等待IO操作完成（因为IO的速度远远低于CPU和内存的速度）。对于IO密集型任务，任务越多，CPU效率越高，但也有一个限度。常见的大部分任务都是IO密集型任务，比如Web应用。
IO密集型任务执行期间，99%的时间都花在IO上，花在CPU上的时间很少，因此，用运行速度极快的C语言替换用Python这样运行速度极低的脚本语言，完全无法提升运行效率。对于IO密集型任务，最合适的语言就是开发效率最高（代码量最少）的语言，脚本语言是首选，C语言最差。
综上，Python多线程相当于单核多线程，多线程有两个好处：CPU并行，IO并行，单核多线程相当于自断一臂。所以，在Python中，可以使用多线程，但不要指望能有效利用多核。如果一定要通过多线程利用多核，那只能通过C扩展来实现，不过这样就失去了Python简单易用的特点。不过，也不用过于担心，Python虽然不能利用多线程实现多核任务，但可以通过多进程实现多核任务。多个Python进程有各自独立的GIL锁，互不影响。
三、其他解释 在我们回过头看下那句经典的话"因为GIL的存在，python的多线程不能利用多核CPU"，这句话很容易让人理解成GIL会让python在一个核心上运行，有了今天的例子我们再来重新理解这句话，GIL的存在让python在同一时刻只能有一个线程在运行，这毋庸置疑，但是它并没有给线程锁死或者说指定只能在某个cpu上运行，另外我需要说明一点的是GIL是与进程对应的，每个进程都有一个GIL。python线程的执行流程我的理解是这样的 线程 ——>抢GIL——>CPU 这种执行流程导致了CPU密集型的多线程程序虽然能够利用多核cpu时跟单核cpu是差不多的，并且由于多个线程抢GIL这个环节导致运行效率&lt;=单线程。看到这可能会让人产生一种错觉，有了GIL后python是线程安全的，好像根本不需要线程锁，而实际情况是线程拿到CPU资源后并不是一直执行的，python解释器在执行了该线程100条字节码(注意是字节码不是代码)时会释放掉该线程的GIL，如果这时候没有加锁那么其他线程就可能修改该线程用到的资源; 另外一个问题是遇到IO也会释放GIL
最后结论是，因为GIL的存在，python的多线程虽然可以利用多核CPU，但并不能让多个核同时工作。</p></div><footer class=entry-footer><span title='2022-06-08 11:49:57 +0800 +0800'>2022-06-08</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;Reid</footer><a class=entry-link aria-label="post link to Python多线程多进程" href=https://reid00.github.io/posts/python%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%A4%9A%E8%BF%9B%E7%A8%8B/></a></article><article class=post-entry><header class=entry-header><h2>KG表示学习</h2></header><div class=entry-content><p>一、概述 网络表示学习（Representation Learning on Network），一般说的就是向量化（Embedding）技术，简单来说，就是将网络中的结构（节点、边或者子图），通过一系列过程，变成一个多维向量，通过这样一层转化，能够将复杂的网络信息变成结构化的多维特征，从而利用机器学习方法实现更方便的算法应用
主流的KG embedding的方法包括基于平移的模型（典型代表：TransE），基于矩阵分解的模型（典型代表：RESCAL），基于神经网络的模型（典型代表：NTN）和基于图神经网络的模型（典型代表：RGCN）。
我们开始介绍知识表示学习的几个代表模型，包括：结构向量模型、语义匹配能量模型、隐变量模型、神经张量网络模型、矩阵分解模型和平移模型，等等。
但是传统的KG embedding模型存在一些不足，例如大多数方法完全依赖于知识图谱中的三元组数据，知识图谱表示学习过程缺乏可解释性。针对完全依赖于三元组数据的问题，一类有效的方案是引入知识图谱图结构中存在的路径信息，经典的基于路径的KG embedding的方法是PTransE，对于由关系路径中的所有关系的向量表示，PTtransE通过求和、乘积和RNN三种策略进行路径的组合。然而，现有的基于路径的知识图谱表示学习模型的路径表示过程中完全基于数据驱动，缺乏可解释性。同时，PTransE，PathRNN等完全数据驱动的方法在表示路径的过程中会造成误差累积并进一步限制路径表示的精度。
目前提到图算法一般指：
经典数据结构与算法层面的：最小生成树(Prim,Kruskal,…)，最短路(Dijkstra,Floyed,…)，拓扑排序，关键路径等
概率图模型，涉及图的表示，推断和学习，详细可以参考Koller的书或者公开课
图神经网络，主要包括Graph Embedding(基于随机游走)和Graph CNN(基于邻居汇聚)两部分。
二、Trans 系列 现在主要介绍知识表示学习的一个最简单也是最有效的方案，叫TransE。在这个模型中，每个实体和关系都表示成低维向量。那么如何怎么学习这些低维向量呢？我们需要设计一个学习目标，这个目标就是，给定任何一个三元组，我们都将中间的relation看成是从head到tail的一个翻译过程，也就是说把head的向量加上relation的向量，要让它尽可能地等于tail向量。在学习过程中，通过不断调整、更新实体和关系向量的取值，使这些等式尽可能实现。
些实体和关系的表示可以用来做什么呢？一个直观的应用就是Entity Prediction（实体预测）。就是说，如果给一个head entity，再给一个relation，那么可以利用刚才学到的向量表示，去预测它的tail entity可能是什么。思想非常简单，直接把h r，然后去找跟h r向量最相近的tail向量就可以了。实际上，我们也用这个任务来判断不同表示模型的效果。我们可以看到，以TransE为代表的翻译模型，需要学习的参数数量要小很多，但同时能够达到非常好的预测准确率。
trans 系列详解: http://aiblog.top/2019/07/08/Trans%E7%B3%BB%E5%88%97%E6%A8%A1%E5%9E%8B%E8%AF%A6%E8%A7%A3/
这里举一些例子。首先，利用TransE学到的实体表示，我们可以很容易地计算出跟某个实体最相似的实体。大家可以看到
，关于中国、奥巴马、苹果，通过TransE向量得到的相似实体能够非常好地反映这些实体的关联。
如果已知head entity和relation，我们可以用TransE模型判断对应的tail entity是什么。比如说与中国相邻的国家或者地区，可以看到比较靠前的实体均比较相关。比如说奥巴马曾经入学的学校，虽然前面的有些并不准确，但是基本上也都是大学或教育机构。
很多情况下TransE关于h r=t的假设其实本身并不符合实际。为什么呢？假如头实体是美国，关系是总统，而美国总统其实有非常多，我们拿出任意两个实体来，比如奥巴马和布什，这两个人都可以跟USA构成同样的关系。在这种情况下，对这两个三元组学习TransE模型，就会发现，它倾向于让奥巴马和布什在空间中变得非常接近。而这其实不太符合常理，因为奥巴马和布什虽然都是美国总统，但是在其他方面有千差万别。这其实就是涉及到复杂关系的处理问题，即所谓的1对N，N对1、N对N这些关系。刚才例子就是典型的1对N关系，就是一个USA可能会对应多个tail entity。为了解决TransE在处理复杂关系时的不足，研究者提出很多扩展模型，基本思想是，首先把实体按照关系进行映射，然后与该关系构建翻译等式。
1 - 1 transE 效果很好，但是1-N, N-1, N-N 这些复杂情况比较难。
TransH和TransR均为代表扩展模型之一，其中TransH由MSRA研究者提出，TransR由我们实验室提出。可以看到，TransE在实体预测任务能够达到47.1的准确率，而采用TransH和TransR，特别是TransR可以达到20%的提升。对于知识图谱复杂关系的处理，还有很多工作需要做。这里只是简介了一些初步尝试。
对于TransH和TransR的效果我们给出一些例子。比如对于《泰坦尼克号》电影，想看它的电影风格是什么，TransE得到的效果比TransH和TransR都要差一些。再如剑桥大学的杰出校友有哪些？我们可以看到对这种典型的1对N关系，TransR和TransH均做得更好一些。
Trans 系列Github: https://github.com/thunlp/OpenKE
考虑知识图谱复杂关系： 按照知识图谱中关系两端连接实体的对应数目，我们可以将关系划分为一对一、一对多、多对一和多对多四种类型。类型关系指的是，该类型关系中的一个左侧实体会平均对应多个右侧实体。 现有知识表示学习算法在处理四种类型关系时的性能差异较大。针对这个问题，我们提出了基于空间转移的 TransR 模型对不同的知识/关系的结构类型进行精细建模。
考虑知识图谱复杂路径： 在知识图谱中，有些多步关系路径也能够反映实体之间的关系。为了突破现有知识表示学习模型孤立学习每个三元组的局限性，我们将借鉴循环神经网络（Recursive Neural Networks）的学术思想，提出考虑关系路径的表示学习方法。我们以平移模型 TransE 作为基础进行扩展，提出 Path-based TransE（PTransE）模型对知识图谱中的复杂关系路径进行建模。
考虑知识图谱复杂属性： 现有知识表示学习模型将所有关系都表示为向量，这在极大程度上限制了对关系的语义的表示能力。这种局限性在属性知识的表示上尤为突出。我们面向属性知识，研究利用分类模型表示属性关系，通 过学习分类器建立实体与属性之间的关系，在既有知识图谱关系表示方案的基础上，探索具有更强表示能力的表示方案。
二、DeepWalk DeepWalk的思想类似word2vec，使用图中节点与节点的共现关系来学习节点的向量表示。那么关键的问题就是如何来描述节点与节点的共现关系，DeepWalk给出的方法是使用随机游走(RandomWalk)的方式在图中进行节点采样。
RandomWalk是一种可重复访问已访问节点的深度优先遍历算法。给定当前访问起始节点，从其邻居中随机采样节点作为下一个访问节点，重复此过程，直到访问序列长度满足预设条件。
获取足够数量的节点访问序列后，使用skip-gram model 进行向量学习。...</p></div><footer class=entry-footer><span title='2022-06-08 11:45:57 +0800 +0800'>2022-06-08</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;Reid</footer><a class=entry-link aria-label="post link to KG表示学习" href=https://reid00.github.io/posts/ml/kg%E8%A1%A8%E7%A4%BA%E5%AD%A6%E4%B9%A0/></a></article><article class=post-entry><header class=entry-header><h2>编码那些事</h2></header><div class=entry-content><p>一直以来，编码问题像幽灵一般，不少开发人员都受过它的困扰。
试想你请求一个数据，却得到一堆乱码，丈二和尚摸不着头脑。有同事质疑你的数据是乱码，虽然你很确定传了 UTF-8 ，却也无法自证清白，更别说帮同事 debug 了。
有时，靠着百度和一手瞎调的手艺，乱码也能解决。尽管如此，还是很羡慕那些骨灰级程序员。为什么他们每次都能犀利地指出问题，并快速修复呢？原因在于，他们早就把编码问题背后的各种来龙去脉搞清楚了。
本文从 ASCII 码说起，带你扒一扒编码背后那些事。相信搞清编码的原理后，你将不再畏惧任何编码问题。
从 ASCII 码说起 现代计算机技术从英文国家兴起，最先遇到的也是英文文本。英文文本一般由 26 个字母、 10 个数字以及若干符号组成，总数也不过 100 左右。
计算机中最基本的存储单位为 字节 ( byte )，由 8 个比特位( bit )组成，也叫做 八位字节 ( octet )。8 个比特位可以表示 $ 2^8 = 256 $ 个字符，看上去用字节来存储英文字符即可？
计算机先驱们也是这么想的。他们为每个英文字符编号，再加上一些控制符，形成了我们所熟知的 ASCII 码表。实际上，由于英文字符不多，他们只用了字节的后 7 位而已。
根据 ASCII 码表，由 01000001 这 8 个比特位组成的八位字节，代表字母 A 。
顺便提一下，比特本身没有意义，比特 在 上下文 ( context )中才构成信息。举个例子，对于内存中一个字节 01000001 ，你将它看做一个整数，它就是 65 ；将它作为一个英文字符，它就是字母 A ；你看待比特的方式，就是所谓的上下文。
所以，猜猜下面这个程序输出啥？
1 2 3 4 5 6 7 8 9 10 11 12 13 14 #include &lt;stdio....</p></div><footer class=entry-footer><span title='2022-06-08 11:40:53 +0800 +0800'>2022-06-08</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;Reid</footer><a class=entry-link aria-label="post link to 编码那些事" href=https://reid00.github.io/posts/%E7%BC%96%E7%A0%81%E9%82%A3%E4%BA%9B%E4%BA%8B/></a></article><article class=post-entry><header class=entry-header><h2>TCP IP协议</h2></header><div class=entry-content><p>## TCP/IP 协议族 通常我说 TCP/IP 是指 TCP/IP 协议族。它是基于 TCP 和 IP 这两个最初的协议之上的不同的通信协议的大集合。 例如：http、https、ftp、icmp、arp、rarp、smtp（简单邮件传输协议）
当输入 xxxxHub 后，到网页显示，其间发生了什么？这问题被面试官问了五六十次，熬夜赶出这篇文章
https://mp.weixin.qq.com/s/ESJ8Zt0GBVXHKj3KICoqjg
一个网络请求是怎么传输的？ 我们拿访问浏览器举个栗子，如图所示：
TCP、UDP有什么区别？各有什么优劣？ TCP 面向连接，提供可靠交付。通过 TCP 连接传输的数据，无差错、不丢失、不重复、并且按序到达。相对 UDP 开销大 UDP 面向无连接，不保证可靠交付。无拥塞控制，支持一对一、一对多、多对多，开销小。
关于 TCP 协议 确认 ACK - ACKnowledgement 仅当ACK = 1 时，确认才有效。简单来说，就是确认收到数据。 复位 RST - ReSet 标明 TCP 出现严重差错时，必须释放连接，重新建立连接。 同步 SYN - SYNchronization 在建立连接时，用来同步序号。当 SYN = 1，ACK = 0 时，表名这是一个连接请求报文。SYN = 1，ACK = 1 表示这是一个同意请求报文。 终止 FNI - FINis（表示终、完）用来释放连接。当 FNI = 1 表示此段报文发送方已发送完毕。 关于 UDP 协议 解释三次握手 确认号 ack 期望收到对方下一个报文的序列号...</p></div><footer class=entry-footer><span title='2022-06-08 11:39:22 +0800 +0800'>2022-06-08</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;Reid</footer><a class=entry-link aria-label="post link to TCP IP协议" href=https://reid00.github.io/posts/tcp-ip%E5%8D%8F%E8%AE%AE/></a></article><article class=post-entry><header class=entry-header><h2>常用Normalization方法的总结与思考</h2></header><div class=entry-content><p>简介 常用的Normalization方法主要有：Batch Normalization（BN，2015年）、Layer Normalization（LN，2016年）、Instance Normalization（IN，2017年）、Group Normalization（GN，2018年）。它们都是从激活函数的输入来考虑、做文章的，以不同的方式对激活函数的输入进行 Norm 的。
我们将输入的 feature map shape 记为**[N, C, H, W]**，其中N表示batch size，即N个样本；C表示通道数；H、W分别表示特征图的高度、宽度。这几个方法主要的区别就是在：
BN是在batch上，对N、H、W做归一化，而保留通道 C 的维度。BN对较小的batch size效果不好。BN适用于固定深度的前向神经网络，如CNN，不适用于RNN；
LN在通道方向上，对C、H、W归一化，主要对RNN效果明显；
IN在图像像素上，对H、W做归一化，用在风格化迁移；
GN将channel分组，然后再做归一化。
每个子图表示一个特征图，其中N为批量，C为通道，（H，W）为特征图的高度和宽度。通过蓝色部分的值来计算均值和方差，从而进行归一化。
如果把特征图比喻成一摞书，这摞书总共有 N 本，每本有 C 页，每页有 H 行，每行 有W 个字符。
BN 求均值时，相当于把这些书按页码一一对应地加起来（例如第1本书第36页，第2本书第36页……），再除以每个页码下的字符总数：N×H×W，因此可以把 BN 看成求“平均书”的操作（注意这个“平均书”每页只有一个字），求标准差时也是同理。
LN 求均值时，相当于把每一本书的所有字加起来，再除以这本书的字符总数：C×H×W，即求整本书的“平均字”，求标准差时也是同理。
IN 求均值时，相当于把一页书中所有字加起来，再除以该页的总字数：H×W，即求每页书的“平均字”，求标准差时也是同理。
GN 相当于把一本 C 页的书平均分成 G 份，每份成为有 C/G 页的小册子，求每个小册子的“平均字”和字的“标准差”。
参考:
https://mp.weixin.qq.com/s/dDMPBYjPeilivSA8J8W7lA https://zhuanlan.zhihu.com/p/72589565</p></div><footer class=entry-footer><span title='2022-06-08 11:36:46 +0800 +0800'>2022-06-08</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;Reid</footer><a class=entry-link aria-label="post link to 常用Normalization方法的总结与思考" href=https://reid00.github.io/posts/ml/%E5%B8%B8%E7%94%A8normalization%E6%96%B9%E6%B3%95%E7%9A%84%E6%80%BB%E7%BB%93%E4%B8%8E%E6%80%9D%E8%80%83/></a></article><article class=post-entry><header class=entry-header><h2>Self Attention</h2></header><div class=entry-content><p>Refer ：https://blog.csdn.net/shenfuli/article/details/106523650
Multi-Head Attention: https://blog.csdn.net/qq_37394634/article/details/102679096</p></div><footer class=entry-footer><span title='2022-06-08 11:35:50 +0800 +0800'>2022-06-08</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;Reid</footer><a class=entry-link aria-label="post link to Self Attention" href=https://reid00.github.io/posts/ml/self-attention/></a></article><footer class=page-footer><nav class=pagination><a class=prev href=https://reid00.github.io/page/4/>« Prev</a>
<a class=next href=https://reid00.github.io/page/6/>Next »</a></nav></footer></main><footer class=footer><span>&copy; 2023 <a href=https://reid00.github.io/>Reid's Blog</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>